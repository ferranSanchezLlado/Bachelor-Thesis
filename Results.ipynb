{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9b52e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from enum import Enum\n",
    "\n",
    "metadata_file = \"./results/metadata.pkl\"\n",
    "dataset_types =  Enum(\"dataset_types\", \"train development test\")\n",
    "# Added to allow sorting\n",
    "dataset_types.__lt__ = lambda self, other: self.value < other.value\n",
    "\n",
    "def save_results(y_pred, index, name, task, lenguage, dataset_type, group=None, description=None, truth=False, filename=None):\n",
    "    \n",
    "    path = f\"./results/{task}/{lenguage}/{dataset_type.name}{'/' + group if group is not None else ''}/{name if filename is None else filename}.pkl\"\n",
    "    \n",
    "    directory = \"/\".join(path.split(\"/\")[:-1])\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    if os.path.exists(metadata_file):\n",
    "        metadata = pd.read_pickle(metadata_file)\n",
    "    else:\n",
    "        metadata = pd.DataFrame({\n",
    "            \"Path\": pd.Series([], dtype=str),\n",
    "            \"Name\": pd.Series([], dtype=str),\n",
    "            \"Description\": pd.Series([], dtype=str),\n",
    "            \"Dataset type\": pd.Categorical([], categories=dataset_types, ordered=False),\n",
    "            \"Groud Truth\": pd.Series([], dtype=bool),\n",
    "            \"Group\": pd.Series([], dtype=str),\n",
    "            \"Task\": pd.Series([], dtype=str),\n",
    "            \"Lenguage\": pd.Series([], dtype=str),\n",
    "        }).set_index(\"Path\")\n",
    "    \n",
    "    if path in metadata.index:\n",
    "        metadata = remove_results(path)\n",
    "\n",
    "    metadata.loc[path] = {\"Name\": name, \"Description\": description, \"Dataset type\": dataset_type, \"Groud Truth\": truth, \"Group\": group, \"Task\": task, \"Lenguage\": lenguage}\n",
    "    results = pd.DataFrame({\"id\": index, \"y_pred\": y_pred}).set_index(\"id\") \n",
    "    \n",
    "    results.to_pickle(path)\n",
    "    metadata.to_pickle(metadata_file)\n",
    "    \n",
    "    print(\"Results saved on: \" + path)\n",
    "\n",
    "def remove_results(path=None):\n",
    "    if os.path.exists(metadata_file):\n",
    "        metadata = pd.read_pickle(metadata_file)\n",
    "        if path is not None:\n",
    "            if os.path.exists(path):\n",
    "                metadata = metadata.drop(path)\n",
    "                os.remove(path)\n",
    "                metadata.to_pickle(metadata_file)\n",
    "        else:\n",
    "            if os.path.exists(metadata_file):\n",
    "                used_files = [os.path.normpath(f) for f in metadata.index]\n",
    "                all_files = set([os.path.normpath(os.path.join(dp, f)) for dp, dn, filenames in os.walk('./results') for f in filenames][1:])\n",
    "                for f in used_files:\n",
    "                    if f not in all_files:\n",
    "                        os.remove(f)\n",
    "        return metadata\n",
    "\n",
    "    \n",
    "def load_results():\n",
    "    if os.path.exists(metadata_file):\n",
    "        metadata = pd.read_pickle(metadata_file)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    metadata[\"Results\"] = [pd.read_pickle(path) for path in metadata.index]\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efe47969",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "\n",
    "def print_score(y_true, y_pred, name):\n",
    "    classification_report_results = classification_report(y_true, y_pred)\n",
    "    \n",
    "    acc, f1 = accuracy_score(y_true, y_pred), f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "    print(name)\n",
    "    print('F1 macro: ', f1)\n",
    "    print('Accuracy: ', acc)\n",
    "\n",
    "    print('\\nClassification Report')\n",
    "    print('======================================================')\n",
    "    print('\\n', classification_report_results)\n",
    "    \n",
    "    return {\"F1 macro\": f1, \"Accuracy\": acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2476560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Dataset type</th>\n",
       "      <th>Groud Truth</th>\n",
       "      <th>Group</th>\n",
       "      <th>Task</th>\n",
       "      <th>Lenguage</th>\n",
       "      <th>Results</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Path</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>./results/hateval2019/task1/english/train/train_truth_task1.pkl</th>\n",
       "      <td>English Train</td>\n",
       "      <td>None</td>\n",
       "      <td>dataset_types.train</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>hateval2019/task1</td>\n",
       "      <td>english</td>\n",
       "      <td>y_pred\n",
       "id          \n",
       "201        1\n",
       "202    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./results/hateval2019/task1/english/development/dev_truth_task1.pkl</th>\n",
       "      <td>English Development</td>\n",
       "      <td>None</td>\n",
       "      <td>dataset_types.development</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>hateval2019/task1</td>\n",
       "      <td>english</td>\n",
       "      <td>y_pred\n",
       "id           \n",
       "18201       0\n",
       "1820...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./results/hateval2019/task1/english/test/test_truth_task1.pkl</th>\n",
       "      <td>English Test</td>\n",
       "      <td>None</td>\n",
       "      <td>dataset_types.test</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>hateval2019/task1</td>\n",
       "      <td>english</td>\n",
       "      <td>y_pred\n",
       "id           \n",
       "34243       0\n",
       "3059...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./results/hateval2019/task1/spanish/train/train_truth_task1.pkl</th>\n",
       "      <td>Spanish Train</td>\n",
       "      <td>None</td>\n",
       "      <td>dataset_types.train</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>hateval2019/task1</td>\n",
       "      <td>spanish</td>\n",
       "      <td>y_pred\n",
       "id           \n",
       "20001       1\n",
       "2000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./results/hateval2019/task1/spanish/development/dev_truth_task1.pkl</th>\n",
       "      <td>Spanish Development</td>\n",
       "      <td>None</td>\n",
       "      <td>dataset_types.development</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>hateval2019/task1</td>\n",
       "      <td>spanish</td>\n",
       "      <td>y_pred\n",
       "id           \n",
       "20005       0\n",
       "2000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./results/hateval2019/task1/spanish/test/test_truth_task1.pkl</th>\n",
       "      <td>Spanish Test</td>\n",
       "      <td>None</td>\n",
       "      <td>dataset_types.test</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>hateval2019/task1</td>\n",
       "      <td>spanish</td>\n",
       "      <td>y_pred\n",
       "id           \n",
       "31494       0\n",
       "3246...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   Name  \\\n",
       "Path                                                                      \n",
       "./results/hateval2019/task1/english/train/train...        English Train   \n",
       "./results/hateval2019/task1/english/development...  English Development   \n",
       "./results/hateval2019/task1/english/test/test_t...         English Test   \n",
       "./results/hateval2019/task1/spanish/train/train...        Spanish Train   \n",
       "./results/hateval2019/task1/spanish/development...  Spanish Development   \n",
       "./results/hateval2019/task1/spanish/test/test_t...         Spanish Test   \n",
       "\n",
       "                                                   Description  \\\n",
       "Path                                                             \n",
       "./results/hateval2019/task1/english/train/train...        None   \n",
       "./results/hateval2019/task1/english/development...        None   \n",
       "./results/hateval2019/task1/english/test/test_t...        None   \n",
       "./results/hateval2019/task1/spanish/train/train...        None   \n",
       "./results/hateval2019/task1/spanish/development...        None   \n",
       "./results/hateval2019/task1/spanish/test/test_t...        None   \n",
       "\n",
       "                                                                 Dataset type  \\\n",
       "Path                                                                            \n",
       "./results/hateval2019/task1/english/train/train...        dataset_types.train   \n",
       "./results/hateval2019/task1/english/development...  dataset_types.development   \n",
       "./results/hateval2019/task1/english/test/test_t...         dataset_types.test   \n",
       "./results/hateval2019/task1/spanish/train/train...        dataset_types.train   \n",
       "./results/hateval2019/task1/spanish/development...  dataset_types.development   \n",
       "./results/hateval2019/task1/spanish/test/test_t...         dataset_types.test   \n",
       "\n",
       "                                                    Groud Truth Group  \\\n",
       "Path                                                                    \n",
       "./results/hateval2019/task1/english/train/train...         True  None   \n",
       "./results/hateval2019/task1/english/development...         True  None   \n",
       "./results/hateval2019/task1/english/test/test_t...         True  None   \n",
       "./results/hateval2019/task1/spanish/train/train...         True  None   \n",
       "./results/hateval2019/task1/spanish/development...         True  None   \n",
       "./results/hateval2019/task1/spanish/test/test_t...         True  None   \n",
       "\n",
       "                                                                 Task  \\\n",
       "Path                                                                    \n",
       "./results/hateval2019/task1/english/train/train...  hateval2019/task1   \n",
       "./results/hateval2019/task1/english/development...  hateval2019/task1   \n",
       "./results/hateval2019/task1/english/test/test_t...  hateval2019/task1   \n",
       "./results/hateval2019/task1/spanish/train/train...  hateval2019/task1   \n",
       "./results/hateval2019/task1/spanish/development...  hateval2019/task1   \n",
       "./results/hateval2019/task1/spanish/test/test_t...  hateval2019/task1   \n",
       "\n",
       "                                                   Lenguage  \\\n",
       "Path                                                          \n",
       "./results/hateval2019/task1/english/train/train...  english   \n",
       "./results/hateval2019/task1/english/development...  english   \n",
       "./results/hateval2019/task1/english/test/test_t...  english   \n",
       "./results/hateval2019/task1/spanish/train/train...  spanish   \n",
       "./results/hateval2019/task1/spanish/development...  spanish   \n",
       "./results/hateval2019/task1/spanish/test/test_t...  spanish   \n",
       "\n",
       "                                                                                              Results  \n",
       "Path                                                                                                   \n",
       "./results/hateval2019/task1/english/train/train...        y_pred\n",
       "id          \n",
       "201        1\n",
       "202    ...  \n",
       "./results/hateval2019/task1/english/development...         y_pred\n",
       "id           \n",
       "18201       0\n",
       "1820...  \n",
       "./results/hateval2019/task1/english/test/test_t...         y_pred\n",
       "id           \n",
       "34243       0\n",
       "3059...  \n",
       "./results/hateval2019/task1/spanish/train/train...         y_pred\n",
       "id           \n",
       "20001       1\n",
       "2000...  \n",
       "./results/hateval2019/task1/spanish/development...         y_pred\n",
       "id           \n",
       "20005       0\n",
       "2000...  \n",
       "./results/hateval2019/task1/spanish/test/test_t...         y_pred\n",
       "id           \n",
       "31494       0\n",
       "3246...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = load_results()\n",
    "\n",
    "mask = df_results[\"Groud Truth\"] == True\n",
    "\n",
    "df_truth = df_results[mask]\n",
    "df_pred = df_results[~mask]\n",
    "\n",
    "df_truth.sort_values(by=[\"Lenguage\", \"Dataset type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75930852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert base\n",
      "F1 macro:  0.9299943995519642\n",
      "Accuracy:  0.9315555555555556\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94      5217\n",
      "           1       0.91      0.93      0.92      3783\n",
      "\n",
      "    accuracy                           0.93      9000\n",
      "   macro avg       0.93      0.93      0.93      9000\n",
      "weighted avg       0.93      0.93      0.93      9000\n",
      "\n",
      "Bert base\n",
      "F1 macro:  0.7469041129594169\n",
      "Accuracy:  0.749\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.73      0.77       573\n",
      "           1       0.68      0.77      0.72       427\n",
      "\n",
      "    accuracy                           0.75      1000\n",
      "   macro avg       0.75      0.75      0.75      1000\n",
      "weighted avg       0.76      0.75      0.75      1000\n",
      "\n",
      "Bert base\n",
      "F1 macro:  0.5941497231031642\n",
      "Accuracy:  0.6053333333333333\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.38      0.53      1740\n",
      "           1       0.52      0.92      0.66      1260\n",
      "\n",
      "    accuracy                           0.61      3000\n",
      "   macro avg       0.69      0.65      0.59      3000\n",
      "weighted avg       0.72      0.61      0.58      3000\n",
      "\n",
      "CLS layers\n",
      "F1 macro:  0.9315993348092122\n",
      "Accuracy:  0.9331111111111111\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94      5217\n",
      "           1       0.91      0.93      0.92      3783\n",
      "\n",
      "    accuracy                           0.93      9000\n",
      "   macro avg       0.93      0.93      0.93      9000\n",
      "weighted avg       0.93      0.93      0.93      9000\n",
      "\n",
      "CLS layers\n",
      "F1 macro:  0.7503514788390029\n",
      "Accuracy:  0.753\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.75      0.78       573\n",
      "           1       0.69      0.76      0.72       427\n",
      "\n",
      "    accuracy                           0.75      1000\n",
      "   macro avg       0.75      0.75      0.75      1000\n",
      "weighted avg       0.76      0.75      0.75      1000\n",
      "\n",
      "CLS layers\n",
      "F1 macro:  0.5897659922431816\n",
      "Accuracy:  0.6026666666666667\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.37      0.52      1740\n",
      "           1       0.51      0.93      0.66      1260\n",
      "\n",
      "    accuracy                           0.60      3000\n",
      "   macro avg       0.70      0.65      0.59      3000\n",
      "weighted avg       0.72      0.60      0.58      3000\n",
      "\n",
      "Tokens\n",
      "F1 macro:  0.9361135549220875\n",
      "Accuracy:  0.9374444444444444\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95      5217\n",
      "           1       0.91      0.94      0.93      3783\n",
      "\n",
      "    accuracy                           0.94      9000\n",
      "   macro avg       0.93      0.94      0.94      9000\n",
      "weighted avg       0.94      0.94      0.94      9000\n",
      "\n",
      "Tokens\n",
      "F1 macro:  0.7482234647673988\n",
      "Accuracy:  0.75\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.73      0.77       573\n",
      "           1       0.68      0.78      0.73       427\n",
      "\n",
      "    accuracy                           0.75      1000\n",
      "   macro avg       0.75      0.75      0.75      1000\n",
      "weighted avg       0.76      0.75      0.75      1000\n",
      "\n",
      "Tokens\n",
      "F1 macro:  0.5865296894939933\n",
      "Accuracy:  0.599\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.37      0.51      1740\n",
      "           1       0.51      0.92      0.66      1260\n",
      "\n",
      "    accuracy                           0.60      3000\n",
      "   macro avg       0.69      0.64      0.59      3000\n",
      "weighted avg       0.72      0.60      0.58      3000\n",
      "\n",
      "Entire layer\n",
      "F1 macro:  0.9406446461420284\n",
      "Accuracy:  0.942\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95      5217\n",
      "           1       0.92      0.94      0.93      3783\n",
      "\n",
      "    accuracy                           0.94      9000\n",
      "   macro avg       0.94      0.94      0.94      9000\n",
      "weighted avg       0.94      0.94      0.94      9000\n",
      "\n",
      "Entire layer\n",
      "F1 macro:  0.7572461030948603\n",
      "Accuracy:  0.759\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.74      0.78       573\n",
      "           1       0.69      0.79      0.74       427\n",
      "\n",
      "    accuracy                           0.76      1000\n",
      "   macro avg       0.76      0.76      0.76      1000\n",
      "weighted avg       0.77      0.76      0.76      1000\n",
      "\n",
      "Entire layer\n",
      "F1 macro:  0.5866254652469632\n",
      "Accuracy:  0.5993333333333334\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.37      0.51      1740\n",
      "           1       0.51      0.92      0.66      1260\n",
      "\n",
      "    accuracy                           0.60      3000\n",
      "   macro avg       0.69      0.64      0.59      3000\n",
      "weighted avg       0.72      0.60      0.58      3000\n",
      "\n",
      "Dummy Classifier\n",
      "F1 macro:  0.3669550538088204\n",
      "Accuracy:  0.5796666666666667\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      1.00      0.73      5217\n",
      "           1       0.00      0.00      0.00      3783\n",
      "\n",
      "    accuracy                           0.58      9000\n",
      "   macro avg       0.29      0.50      0.37      9000\n",
      "weighted avg       0.34      0.58      0.43      9000\n",
      "\n",
      "Multinomial Naive Bayes classifier\n",
      "F1 macro:  0.8126298508371801\n",
      "Accuracy:  0.8204444444444444\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.88      0.85      5217\n",
      "           1       0.82      0.73      0.77      3783\n",
      "\n",
      "    accuracy                           0.82      9000\n",
      "   macro avg       0.82      0.81      0.81      9000\n",
      "weighted avg       0.82      0.82      0.82      9000\n",
      "\n",
      "Best Multinomial Naive Bayes classifier\n",
      "F1 macro:  0.8071309065220538\n",
      "Accuracy:  0.8162222222222222\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.89      0.85      5217\n",
      "           1       0.83      0.71      0.77      3783\n",
      "\n",
      "    accuracy                           0.82      9000\n",
      "   macro avg       0.82      0.80      0.81      9000\n",
      "weighted avg       0.82      0.82      0.81      9000\n",
      "\n",
      "Bernoulli Naive Bayes classifier\n",
      "F1 macro:  0.8210285714285713\n",
      "Accuracy:  0.826\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.85      5217\n",
      "           1       0.80      0.78      0.79      3783\n",
      "\n",
      "    accuracy                           0.83      9000\n",
      "   macro avg       0.82      0.82      0.82      9000\n",
      "weighted avg       0.83      0.83      0.83      9000\n",
      "\n",
      "Best Bernoulli Naive Bayes classifier\n",
      "F1 macro:  0.8151335065345999\n",
      "Accuracy:  0.8208888888888889\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.86      0.85      5217\n",
      "           1       0.80      0.77      0.78      3783\n",
      "\n",
      "    accuracy                           0.82      9000\n",
      "   macro avg       0.82      0.81      0.82      9000\n",
      "weighted avg       0.82      0.82      0.82      9000\n",
      "\n",
      "Ridge Classifier\n",
      "F1 macro:  0.8774313461768318\n",
      "Accuracy:  0.8816666666666667\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90      5217\n",
      "           1       0.88      0.83      0.85      3783\n",
      "\n",
      "    accuracy                           0.88      9000\n",
      "   macro avg       0.88      0.87      0.88      9000\n",
      "weighted avg       0.88      0.88      0.88      9000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Ridge Classifier\n",
      "F1 macro:  0.8271567865321129\n",
      "Accuracy:  0.8356666666666667\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.91      0.87      5217\n",
      "           1       0.86      0.73      0.79      3783\n",
      "\n",
      "    accuracy                           0.84      9000\n",
      "   macro avg       0.84      0.82      0.83      9000\n",
      "weighted avg       0.84      0.84      0.83      9000\n",
      "\n",
      "Random Forest classifier\n",
      "F1 macro:  0.9989737648560049\n",
      "Accuracy:  0.999\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5217\n",
      "           1       1.00      1.00      1.00      3783\n",
      "\n",
      "    accuracy                           1.00      9000\n",
      "   macro avg       1.00      1.00      1.00      9000\n",
      "weighted avg       1.00      1.00      1.00      9000\n",
      "\n",
      "Best Random Forest classifier\n",
      "F1 macro:  0.9965763219746517\n",
      "Accuracy:  0.9966666666666667\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      5217\n",
      "           1       1.00      0.99      1.00      3783\n",
      "\n",
      "    accuracy                           1.00      9000\n",
      "   macro avg       1.00      1.00      1.00      9000\n",
      "weighted avg       1.00      1.00      1.00      9000\n",
      "\n",
      "Support Vector Classification\n",
      "F1 macro:  0.9563093471055895\n",
      "Accuracy:  0.9575555555555556\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      5217\n",
      "           1       0.96      0.94      0.95      3783\n",
      "\n",
      "    accuracy                           0.96      9000\n",
      "   macro avg       0.96      0.95      0.96      9000\n",
      "weighted avg       0.96      0.96      0.96      9000\n",
      "\n",
      "Best Support Vector Classification\n",
      "F1 macro:  0.8078546622506662\n",
      "Accuracy:  0.8206666666666667\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.93      0.86      5217\n",
      "           1       0.87      0.67      0.76      3783\n",
      "\n",
      "    accuracy                           0.82      9000\n",
      "   macro avg       0.83      0.80      0.81      9000\n",
      "weighted avg       0.83      0.82      0.82      9000\n",
      "\n",
      "AdaBoost classifier\n",
      "F1 macro:  0.7679385989020957\n",
      "Accuracy:  0.7816666666666666\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.88      0.82      5217\n",
      "           1       0.80      0.64      0.71      3783\n",
      "\n",
      "    accuracy                           0.78      9000\n",
      "   macro avg       0.79      0.76      0.77      9000\n",
      "weighted avg       0.78      0.78      0.78      9000\n",
      "\n",
      "Best AdaBoost classifier\n",
      "F1 macro:  0.8148955676525538\n",
      "Accuracy:  0.824\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.90      0.86      5217\n",
      "           1       0.84      0.72      0.77      3783\n",
      "\n",
      "    accuracy                           0.82      9000\n",
      "   macro avg       0.83      0.81      0.81      9000\n",
      "weighted avg       0.83      0.82      0.82      9000\n",
      "\n",
      "Multi-layer Perceptron classifier\n",
      "F1 macro:  0.8880149007808582\n",
      "Accuracy:  0.8914444444444445\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91      5217\n",
      "           1       0.89      0.85      0.87      3783\n",
      "\n",
      "    accuracy                           0.89      9000\n",
      "   macro avg       0.89      0.89      0.89      9000\n",
      "weighted avg       0.89      0.89      0.89      9000\n",
      "\n",
      "Best Multi-layer Perceptron classifier\n",
      "F1 macro:  0.8173712296381446\n",
      "Accuracy:  0.8217777777777778\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.84      0.85      5217\n",
      "           1       0.79      0.79      0.79      3783\n",
      "\n",
      "    accuracy                           0.82      9000\n",
      "   macro avg       0.82      0.82      0.82      9000\n",
      "weighted avg       0.82      0.82      0.82      9000\n",
      "\n",
      "Dummy Classifier\n",
      "F1 macro:  0.3642720915448188\n",
      "Accuracy:  0.573\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      1.00      0.73       573\n",
      "           1       0.00      0.00      0.00       427\n",
      "\n",
      "    accuracy                           0.57      1000\n",
      "   macro avg       0.29      0.50      0.36      1000\n",
      "weighted avg       0.33      0.57      0.42      1000\n",
      "\n",
      "Multinomial Naive Bayes classifier\n",
      "F1 macro:  0.7302028627329833\n",
      "Accuracy:  0.738\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.79      0.78       573\n",
      "           1       0.70      0.67      0.68       427\n",
      "\n",
      "    accuracy                           0.74      1000\n",
      "   macro avg       0.73      0.73      0.73      1000\n",
      "weighted avg       0.74      0.74      0.74      1000\n",
      "\n",
      "Best Multinomial Naive Bayes classifier\n",
      "F1 macro:  0.7329590620031796\n",
      "Accuracy:  0.742\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.81      0.78       573\n",
      "           1       0.72      0.65      0.68       427\n",
      "\n",
      "    accuracy                           0.74      1000\n",
      "   macro avg       0.74      0.73      0.73      1000\n",
      "weighted avg       0.74      0.74      0.74      1000\n",
      "\n",
      "Bernoulli Naive Bayes classifier\n",
      "F1 macro:  0.734550214588796\n",
      "Accuracy:  0.738\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.74      0.76       573\n",
      "           1       0.68      0.73      0.70       427\n",
      "\n",
      "    accuracy                           0.74      1000\n",
      "   macro avg       0.73      0.74      0.73      1000\n",
      "weighted avg       0.74      0.74      0.74      1000\n",
      "\n",
      "Best Bernoulli Naive Bayes classifier\n",
      "F1 macro:  0.7344264422063284\n",
      "Accuracy:  0.738\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.75      0.77       573\n",
      "           1       0.68      0.73      0.70       427\n",
      "\n",
      "    accuracy                           0.74      1000\n",
      "   macro avg       0.73      0.74      0.73      1000\n",
      "weighted avg       0.74      0.74      0.74      1000\n",
      "\n",
      "Ridge Classifier\n",
      "F1 macro:  0.7098480444475885\n",
      "Accuracy:  0.717\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.76      0.76       573\n",
      "           1       0.67      0.66      0.66       427\n",
      "\n",
      "    accuracy                           0.72      1000\n",
      "   macro avg       0.71      0.71      0.71      1000\n",
      "weighted avg       0.72      0.72      0.72      1000\n",
      "\n",
      "Best Ridge Classifier\n",
      "F1 macro:  0.7335542612583733\n",
      "Accuracy:  0.744\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.79       573\n",
      "           1       0.73      0.64      0.68       427\n",
      "\n",
      "    accuracy                           0.74      1000\n",
      "   macro avg       0.74      0.73      0.73      1000\n",
      "weighted avg       0.74      0.74      0.74      1000\n",
      "\n",
      "Random Forest classifier\n",
      "F1 macro:  0.7314926119159448\n",
      "Accuracy:  0.74\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.80      0.78       573\n",
      "           1       0.71      0.66      0.68       427\n",
      "\n",
      "    accuracy                           0.74      1000\n",
      "   macro avg       0.74      0.73      0.73      1000\n",
      "weighted avg       0.74      0.74      0.74      1000\n",
      "\n",
      "Best Random Forest classifier\n",
      "F1 macro:  0.7506224134804043\n",
      "Accuracy:  0.758\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.79       573\n",
      "           1       0.73      0.69      0.71       427\n",
      "\n",
      "    accuracy                           0.76      1000\n",
      "   macro avg       0.75      0.75      0.75      1000\n",
      "weighted avg       0.76      0.76      0.76      1000\n",
      "\n",
      "Support Vector Classification\n",
      "F1 macro:  0.7344853545245258\n",
      "Accuracy:  0.745\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.79       573\n",
      "           1       0.73      0.64      0.68       427\n",
      "\n",
      "    accuracy                           0.74      1000\n",
      "   macro avg       0.74      0.73      0.73      1000\n",
      "weighted avg       0.74      0.74      0.74      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Support Vector Classification\n",
      "F1 macro:  0.7069521297684922\n",
      "Accuracy:  0.728\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.87      0.79       573\n",
      "           1       0.75      0.54      0.63       427\n",
      "\n",
      "    accuracy                           0.73      1000\n",
      "   macro avg       0.74      0.70      0.71      1000\n",
      "weighted avg       0.73      0.73      0.72      1000\n",
      "\n",
      "AdaBoost classifier\n",
      "F1 macro:  0.7258515670051333\n",
      "Accuracy:  0.739\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.84      0.79       573\n",
      "           1       0.73      0.61      0.67       427\n",
      "\n",
      "    accuracy                           0.74      1000\n",
      "   macro avg       0.74      0.72      0.73      1000\n",
      "weighted avg       0.74      0.74      0.73      1000\n",
      "\n",
      "Best AdaBoost classifier\n",
      "F1 macro:  0.7046539875871478\n",
      "Accuracy:  0.716\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.80      0.76       573\n",
      "           1       0.69      0.61      0.65       427\n",
      "\n",
      "    accuracy                           0.72      1000\n",
      "   macro avg       0.71      0.70      0.70      1000\n",
      "weighted avg       0.71      0.72      0.71      1000\n",
      "\n",
      "Multi-layer Perceptron classifier\n",
      "F1 macro:  0.6930946291560103\n",
      "Accuracy:  0.7\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.74      0.74       573\n",
      "           1       0.65      0.64      0.65       427\n",
      "\n",
      "    accuracy                           0.70      1000\n",
      "   macro avg       0.69      0.69      0.69      1000\n",
      "weighted avg       0.70      0.70      0.70      1000\n",
      "\n",
      "Best Multi-layer Perceptron classifier\n",
      "F1 macro:  0.7323991631392012\n",
      "Accuracy:  0.736\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.76       573\n",
      "           1       0.68      0.73      0.70       427\n",
      "\n",
      "    accuracy                           0.74      1000\n",
      "   macro avg       0.73      0.73      0.73      1000\n",
      "weighted avg       0.74      0.74      0.74      1000\n",
      "\n",
      "Dummy Classifier\n",
      "F1 macro:  0.36708860759493667\n",
      "Accuracy:  0.58\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      1.00      0.73      1740\n",
      "           1       0.00      0.00      0.00      1260\n",
      "\n",
      "    accuracy                           0.58      3000\n",
      "   macro avg       0.29      0.50      0.37      3000\n",
      "weighted avg       0.34      0.58      0.43      3000\n",
      "\n",
      "Multinomial Naive Bayes classifier\n",
      "F1 macro:  0.4784764572972561\n",
      "Accuracy:  0.5056666666666667\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.24      0.36      1740\n",
      "           1       0.45      0.87      0.60      1260\n",
      "\n",
      "    accuracy                           0.51      3000\n",
      "   macro avg       0.59      0.56      0.48      3000\n",
      "weighted avg       0.61      0.51      0.46      3000\n",
      "\n",
      "Best Multinomial Naive Bayes classifier\n",
      "F1 macro:  0.48378767377483683\n",
      "Accuracy:  0.509\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.25      0.37      1740\n",
      "           1       0.46      0.87      0.60      1260\n",
      "\n",
      "    accuracy                           0.51      3000\n",
      "   macro avg       0.59      0.56      0.48      3000\n",
      "weighted avg       0.61      0.51      0.47      3000\n",
      "\n",
      "Bernoulli Naive Bayes classifier\n",
      "F1 macro:  0.4181881304494295\n",
      "Accuracy:  0.4726666666666667\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.14      0.24      1740\n",
      "           1       0.44      0.93      0.60      1260\n",
      "\n",
      "    accuracy                           0.47      3000\n",
      "   macro avg       0.59      0.54      0.42      3000\n",
      "weighted avg       0.61      0.47      0.39      3000\n",
      "\n",
      "Best Bernoulli Naive Bayes classifier\n",
      "F1 macro:  0.4290866116789922\n",
      "Accuracy:  0.47933333333333333\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.16      0.26      1740\n",
      "           1       0.44      0.92      0.60      1260\n",
      "\n",
      "    accuracy                           0.48      3000\n",
      "   macro avg       0.59      0.54      0.43      3000\n",
      "weighted avg       0.62      0.48      0.40      3000\n",
      "\n",
      "Ridge Classifier\n",
      "F1 macro:  0.4877331577792407\n",
      "Accuracy:  0.5136666666666667\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.25      0.37      1740\n",
      "           1       0.46      0.88      0.60      1260\n",
      "\n",
      "    accuracy                           0.51      3000\n",
      "   macro avg       0.60      0.56      0.49      3000\n",
      "weighted avg       0.62      0.51      0.47      3000\n",
      "\n",
      "Best Ridge Classifier\n",
      "F1 macro:  0.4802516140527483\n",
      "Accuracy:  0.5076666666666667\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.24      0.36      1740\n",
      "           1       0.46      0.88      0.60      1260\n",
      "\n",
      "    accuracy                           0.51      3000\n",
      "   macro avg       0.59      0.56      0.48      3000\n",
      "weighted avg       0.61      0.51      0.46      3000\n",
      "\n",
      "Random Forest classifier\n",
      "F1 macro:  0.39359880393776636\n",
      "Accuracy:  0.451\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.12      0.21      1740\n",
      "           1       0.43      0.90      0.58      1260\n",
      "\n",
      "    accuracy                           0.45      3000\n",
      "   macro avg       0.53      0.51      0.39      3000\n",
      "weighted avg       0.55      0.45      0.36      3000\n",
      "\n",
      "Best Random Forest classifier\n",
      "F1 macro:  0.39131991130872873\n",
      "Accuracy:  0.4513333333333333\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.12      0.20      1740\n",
      "           1       0.43      0.91      0.58      1260\n",
      "\n",
      "    accuracy                           0.45      3000\n",
      "   macro avg       0.54      0.51      0.39      3000\n",
      "weighted avg       0.56      0.45      0.36      3000\n",
      "\n",
      "Support Vector Classification\n",
      "F1 macro:  0.44732629900735116\n",
      "Accuracy:  0.48633333333333334\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.19      0.30      1740\n",
      "           1       0.44      0.90      0.59      1260\n",
      "\n",
      "    accuracy                           0.49      3000\n",
      "   macro avg       0.58      0.54      0.45      3000\n",
      "weighted avg       0.60      0.49      0.42      3000\n",
      "\n",
      "Best Support Vector Classification\n",
      "F1 macro:  0.4456682057728456\n",
      "Accuracy:  0.47533333333333333\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.21      0.32      1740\n",
      "           1       0.44      0.84      0.57      1260\n",
      "\n",
      "    accuracy                           0.48      3000\n",
      "   macro avg       0.54      0.53      0.45      3000\n",
      "weighted avg       0.56      0.48      0.43      3000\n",
      "\n",
      "AdaBoost classifier\n",
      "F1 macro:  0.41955762522951046\n",
      "Accuracy:  0.46366666666666667\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.16      0.26      1740\n",
      "           1       0.43      0.88      0.58      1260\n",
      "\n",
      "    accuracy                           0.46      3000\n",
      "   macro avg       0.54      0.52      0.42      3000\n",
      "weighted avg       0.56      0.46      0.39      3000\n",
      "\n",
      "Best AdaBoost classifier\n",
      "F1 macro:  0.4428953278257908\n",
      "Accuracy:  0.48533333333333334\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.18      0.29      1740\n",
      "           1       0.44      0.91      0.60      1260\n",
      "\n",
      "    accuracy                           0.49      3000\n",
      "   macro avg       0.59      0.54      0.44      3000\n",
      "weighted avg       0.61      0.49      0.42      3000\n",
      "\n",
      "Multi-layer Perceptron classifier\n",
      "F1 macro:  0.4837036783119388\n",
      "Accuracy:  0.5113333333333333\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.24      0.36      1740\n",
      "           1       0.46      0.88      0.60      1260\n",
      "\n",
      "    accuracy                           0.51      3000\n",
      "   macro avg       0.60      0.56      0.48      3000\n",
      "weighted avg       0.62      0.51      0.46      3000\n",
      "\n",
      "Best Multi-layer Perceptron classifier\n",
      "F1 macro:  0.4883659271050003\n",
      "Accuracy:  0.518\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.24      0.37      1740\n",
      "           1       0.46      0.90      0.61      1260\n",
      "\n",
      "    accuracy                           0.52      3000\n",
      "   macro avg       0.62      0.57      0.49      3000\n",
      "weighted avg       0.64      0.52      0.47      3000\n",
      "\n",
      "Dummy Classifier\n",
      "F1 macro:  0.37001259974800504\n",
      "Accuracy:  0.5873333333333334\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      1.00      0.74      2643\n",
      "           1       0.00      0.00      0.00      1857\n",
      "\n",
      "    accuracy                           0.59      4500\n",
      "   macro avg       0.29      0.50      0.37      4500\n",
      "weighted avg       0.34      0.59      0.43      4500\n",
      "\n",
      "Multinomial Naive Bayes classifier\n",
      "F1 macro:  0.8514738322806575\n",
      "Accuracy:  0.8624444444444445\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.97      0.89      2643\n",
      "           1       0.94      0.72      0.81      1857\n",
      "\n",
      "    accuracy                           0.86      4500\n",
      "   macro avg       0.88      0.84      0.85      4500\n",
      "weighted avg       0.87      0.86      0.86      4500\n",
      "\n",
      "Best Multinomial Naive Bayes classifier\n",
      "F1 macro:  0.8195755730146153\n",
      "Accuracy:  0.8366666666666667\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.97      0.88      2643\n",
      "           1       0.95      0.64      0.76      1857\n",
      "\n",
      "    accuracy                           0.84      4500\n",
      "   macro avg       0.87      0.81      0.82      4500\n",
      "weighted avg       0.86      0.84      0.83      4500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes classifier\n",
      "F1 macro:  0.8776877260140155\n",
      "Accuracy:  0.8808888888888889\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90      2643\n",
      "           1       0.84      0.87      0.86      1857\n",
      "\n",
      "    accuracy                           0.88      4500\n",
      "   macro avg       0.88      0.88      0.88      4500\n",
      "weighted avg       0.88      0.88      0.88      4500\n",
      "\n",
      "Best Bernoulli Naive Bayes classifier\n",
      "F1 macro:  0.871494135645079\n",
      "Accuracy:  0.8755555555555555\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.89      2643\n",
      "           1       0.85      0.85      0.85      1857\n",
      "\n",
      "    accuracy                           0.88      4500\n",
      "   macro avg       0.87      0.87      0.87      4500\n",
      "weighted avg       0.88      0.88      0.88      4500\n",
      "\n",
      "Ridge Classifier\n",
      "F1 macro:  0.9337121832097052\n",
      "Accuracy:  0.936\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95      2643\n",
      "           1       0.93      0.91      0.92      1857\n",
      "\n",
      "    accuracy                           0.94      4500\n",
      "   macro avg       0.94      0.93      0.93      4500\n",
      "weighted avg       0.94      0.94      0.94      4500\n",
      "\n",
      "Best Ridge Classifier\n",
      "F1 macro:  0.8634846012673638\n",
      "Accuracy:  0.8713333333333333\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.95      0.90      2643\n",
      "           1       0.91      0.77      0.83      1857\n",
      "\n",
      "    accuracy                           0.87      4500\n",
      "   macro avg       0.88      0.86      0.86      4500\n",
      "weighted avg       0.88      0.87      0.87      4500\n",
      "\n",
      "Random Forest classifier\n",
      "F1 macro:  0.9997708031186054\n",
      "Accuracy:  0.9997777777777778\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2643\n",
      "           1       1.00      1.00      1.00      1857\n",
      "\n",
      "    accuracy                           1.00      4500\n",
      "   macro avg       1.00      1.00      1.00      4500\n",
      "weighted avg       1.00      1.00      1.00      4500\n",
      "\n",
      "Best Random Forest classifier\n",
      "F1 macro:  0.9995416428660481\n",
      "Accuracy:  0.9995555555555555\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2643\n",
      "           1       1.00      1.00      1.00      1857\n",
      "\n",
      "    accuracy                           1.00      4500\n",
      "   macro avg       1.00      1.00      1.00      4500\n",
      "weighted avg       1.00      1.00      1.00      4500\n",
      "\n",
      "Support Vector Classification\n",
      "F1 macro:  0.9763348654827293\n",
      "Accuracy:  0.9771111111111112\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      2643\n",
      "           1       0.98      0.96      0.97      1857\n",
      "\n",
      "    accuracy                           0.98      4500\n",
      "   macro avg       0.98      0.98      0.98      4500\n",
      "weighted avg       0.98      0.98      0.98      4500\n",
      "\n",
      "Best Support Vector Classification\n",
      "F1 macro:  0.8116820679589106\n",
      "Accuracy:  0.8291111111111111\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.96      0.87      2643\n",
      "           1       0.93      0.64      0.75      1857\n",
      "\n",
      "    accuracy                           0.83      4500\n",
      "   macro avg       0.86      0.80      0.81      4500\n",
      "weighted avg       0.85      0.83      0.82      4500\n",
      "\n",
      "AdaBoost classifier\n",
      "F1 macro:  0.7697403786836509\n",
      "Accuracy:  0.7824444444444445\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.87      0.82      2643\n",
      "           1       0.78      0.66      0.72      1857\n",
      "\n",
      "    accuracy                           0.78      4500\n",
      "   macro avg       0.78      0.76      0.77      4500\n",
      "weighted avg       0.78      0.78      0.78      4500\n",
      "\n",
      "Best AdaBoost classifier\n",
      "F1 macro:  0.8637300571496607\n",
      "Accuracy:  0.8697777777777778\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89      2643\n",
      "           1       0.87      0.80      0.84      1857\n",
      "\n",
      "    accuracy                           0.87      4500\n",
      "   macro avg       0.87      0.86      0.86      4500\n",
      "weighted avg       0.87      0.87      0.87      4500\n",
      "\n",
      "Multi-layer Perceptron classifier\n",
      "F1 macro:  0.9123738230327386\n",
      "Accuracy:  0.9153333333333333\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93      2643\n",
      "           1       0.91      0.89      0.90      1857\n",
      "\n",
      "    accuracy                           0.92      4500\n",
      "   macro avg       0.91      0.91      0.91      4500\n",
      "weighted avg       0.92      0.92      0.92      4500\n",
      "\n",
      "Best Multi-layer Perceptron classifier\n",
      "F1 macro:  0.8696649452350105\n",
      "Accuracy:  0.8766666666666667\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.94      0.90      2643\n",
      "           1       0.91      0.78      0.84      1857\n",
      "\n",
      "    accuracy                           0.88      4500\n",
      "   macro avg       0.88      0.86      0.87      4500\n",
      "weighted avg       0.88      0.88      0.87      4500\n",
      "\n",
      "Dummy Classifier\n",
      "F1 macro:  0.3573264781491003\n",
      "Accuracy:  0.556\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      1.00      0.71       278\n",
      "           1       0.00      0.00      0.00       222\n",
      "\n",
      "    accuracy                           0.56       500\n",
      "   macro avg       0.28      0.50      0.36       500\n",
      "weighted avg       0.31      0.56      0.40       500\n",
      "\n",
      "Multinomial Naive Bayes classifier\n",
      "F1 macro:  0.7094412231878817\n",
      "Accuracy:  0.73\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.90      0.79       278\n",
      "           1       0.80      0.52      0.63       222\n",
      "\n",
      "    accuracy                           0.73       500\n",
      "   macro avg       0.75      0.71      0.71       500\n",
      "weighted avg       0.75      0.73      0.72       500\n",
      "\n",
      "Best Multinomial Naive Bayes classifier\n",
      "F1 macro:  0.6898043108338061\n",
      "Accuracy:  0.72\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.93      0.79       278\n",
      "           1       0.84      0.46      0.59       222\n",
      "\n",
      "    accuracy                           0.72       500\n",
      "   macro avg       0.76      0.69      0.69       500\n",
      "weighted avg       0.75      0.72      0.70       500\n",
      "\n",
      "Bernoulli Naive Bayes classifier\n",
      "F1 macro:  0.7614195134575569\n",
      "Accuracy:  0.764\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.78      0.79       278\n",
      "           1       0.73      0.74      0.74       222\n",
      "\n",
      "    accuracy                           0.76       500\n",
      "   macro avg       0.76      0.76      0.76       500\n",
      "weighted avg       0.76      0.76      0.76       500\n",
      "\n",
      "Best Bernoulli Naive Bayes classifier\n",
      "F1 macro:  0.7669715624252791\n",
      "Accuracy:  0.77\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79       278\n",
      "           1       0.74      0.74      0.74       222\n",
      "\n",
      "    accuracy                           0.77       500\n",
      "   macro avg       0.77      0.77      0.77       500\n",
      "weighted avg       0.77      0.77      0.77       500\n",
      "\n",
      "Ridge Classifier\n",
      "F1 macro:  0.733850890985325\n",
      "Accuracy:  0.74\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.80      0.77       278\n",
      "           1       0.73      0.66      0.69       222\n",
      "\n",
      "    accuracy                           0.74       500\n",
      "   macro avg       0.74      0.73      0.73       500\n",
      "weighted avg       0.74      0.74      0.74       500\n",
      "\n",
      "Best Ridge Classifier\n",
      "F1 macro:  0.7356358685922922\n",
      "Accuracy:  0.746\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.85      0.79       278\n",
      "           1       0.77      0.62      0.68       222\n",
      "\n",
      "    accuracy                           0.75       500\n",
      "   macro avg       0.75      0.73      0.74       500\n",
      "weighted avg       0.75      0.75      0.74       500\n",
      "\n",
      "Random Forest classifier\n",
      "F1 macro:  0.7281131049483416\n",
      "Accuracy:  0.742\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.87      0.79       278\n",
      "           1       0.78      0.58      0.67       222\n",
      "\n",
      "    accuracy                           0.74       500\n",
      "   macro avg       0.75      0.73      0.73       500\n",
      "weighted avg       0.75      0.74      0.73       500\n",
      "\n",
      "Best Random Forest classifier\n",
      "F1 macro:  0.7259505691305623\n",
      "Accuracy:  0.742\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.88      0.79       278\n",
      "           1       0.80      0.56      0.66       222\n",
      "\n",
      "    accuracy                           0.74       500\n",
      "   macro avg       0.76      0.72      0.73       500\n",
      "weighted avg       0.75      0.74      0.73       500\n",
      "\n",
      "Support Vector Classification\n",
      "F1 macro:  0.7416666666666666\n",
      "Accuracy:  0.752\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.86      0.79       278\n",
      "           1       0.78      0.62      0.69       222\n",
      "\n",
      "    accuracy                           0.75       500\n",
      "   macro avg       0.76      0.74      0.74       500\n",
      "weighted avg       0.76      0.75      0.75       500\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Support Vector Classification\n",
      "F1 macro:  0.7173983389062669\n",
      "Accuracy:  0.738\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.91      0.79       278\n",
      "           1       0.82      0.53      0.64       222\n",
      "\n",
      "    accuracy                           0.74       500\n",
      "   macro avg       0.76      0.72      0.72       500\n",
      "weighted avg       0.76      0.74      0.73       500\n",
      "\n",
      "AdaBoost classifier\n",
      "F1 macro:  0.741819819149947\n",
      "Accuracy:  0.75\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.83      0.79       278\n",
      "           1       0.76      0.64      0.70       222\n",
      "\n",
      "    accuracy                           0.75       500\n",
      "   macro avg       0.75      0.74      0.74       500\n",
      "weighted avg       0.75      0.75      0.75       500\n",
      "\n",
      "Best AdaBoost classifier\n",
      "F1 macro:  0.74581413273422\n",
      "Accuracy:  0.752\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.82      0.79       278\n",
      "           1       0.74      0.67      0.71       222\n",
      "\n",
      "    accuracy                           0.75       500\n",
      "   macro avg       0.75      0.74      0.75       500\n",
      "weighted avg       0.75      0.75      0.75       500\n",
      "\n",
      "Multi-layer Perceptron classifier\n",
      "F1 macro:  0.7291363727083511\n",
      "Accuracy:  0.734\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.78      0.77       278\n",
      "           1       0.71      0.68      0.69       222\n",
      "\n",
      "    accuracy                           0.73       500\n",
      "   macro avg       0.73      0.73      0.73       500\n",
      "weighted avg       0.73      0.73      0.73       500\n",
      "\n",
      "Best Multi-layer Perceptron classifier\n",
      "F1 macro:  0.6998444264069263\n",
      "Accuracy:  0.716\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.85      0.77       278\n",
      "           1       0.75      0.55      0.63       222\n",
      "\n",
      "    accuracy                           0.72       500\n",
      "   macro avg       0.72      0.70      0.70       500\n",
      "weighted avg       0.72      0.72      0.71       500\n",
      "\n",
      "Dummy Classifier\n",
      "F1 macro:  0.3700787401574803\n",
      "Accuracy:  0.5875\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      1.00      0.74       940\n",
      "           1       0.00      0.00      0.00       660\n",
      "\n",
      "    accuracy                           0.59      1600\n",
      "   macro avg       0.29      0.50      0.37      1600\n",
      "weighted avg       0.35      0.59      0.43      1600\n",
      "\n",
      "Multinomial Naive Bayes classifier\n",
      "F1 macro:  0.6706079955783077\n",
      "Accuracy:  0.700625\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.85      0.77       940\n",
      "           1       0.70      0.48      0.57       660\n",
      "\n",
      "    accuracy                           0.70      1600\n",
      "   macro avg       0.70      0.67      0.67      1600\n",
      "weighted avg       0.70      0.70      0.69      1600\n",
      "\n",
      "Best Multinomial Naive Bayes classifier\n",
      "F1 macro:  0.6552706552706553\n",
      "Accuracy:  0.6975\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.89      0.78       940\n",
      "           1       0.73      0.42      0.53       660\n",
      "\n",
      "    accuracy                           0.70      1600\n",
      "   macro avg       0.71      0.66      0.66      1600\n",
      "weighted avg       0.71      0.70      0.68      1600\n",
      "\n",
      "Bernoulli Naive Bayes classifier\n",
      "F1 macro:  0.6993622127574062\n",
      "Accuracy:  0.703125\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.69      0.73       940\n",
      "           1       0.62      0.72      0.67       660\n",
      "\n",
      "    accuracy                           0.70      1600\n",
      "   macro avg       0.70      0.71      0.70      1600\n",
      "weighted avg       0.71      0.70      0.71      1600\n",
      "\n",
      "Best Bernoulli Naive Bayes classifier\n",
      "F1 macro:  0.6981534090909092\n",
      "Accuracy:  0.7025\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.70      0.73       940\n",
      "           1       0.62      0.71      0.66       660\n",
      "\n",
      "    accuracy                           0.70      1600\n",
      "   macro avg       0.70      0.70      0.70      1600\n",
      "weighted avg       0.71      0.70      0.70      1600\n",
      "\n",
      "Ridge Classifier\n",
      "F1 macro:  0.6991024071807426\n",
      "Accuracy:  0.705\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.72      0.74       940\n",
      "           1       0.63      0.68      0.66       660\n",
      "\n",
      "    accuracy                           0.70      1600\n",
      "   macro avg       0.70      0.70      0.70      1600\n",
      "weighted avg       0.71      0.70      0.71      1600\n",
      "\n",
      "Best Ridge Classifier\n",
      "F1 macro:  0.7120828860247476\n",
      "Accuracy:  0.725625\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.80      0.77       940\n",
      "           1       0.69      0.62      0.65       660\n",
      "\n",
      "    accuracy                           0.73      1600\n",
      "   macro avg       0.72      0.71      0.71      1600\n",
      "weighted avg       0.72      0.73      0.72      1600\n",
      "\n",
      "Random Forest classifier\n",
      "F1 macro:  0.6991758241758242\n",
      "Accuracy:  0.72625\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.87      0.79       940\n",
      "           1       0.74      0.52      0.61       660\n",
      "\n",
      "    accuracy                           0.73      1600\n",
      "   macro avg       0.73      0.70      0.70      1600\n",
      "weighted avg       0.73      0.73      0.71      1600\n",
      "\n",
      "Best Random Forest classifier\n",
      "F1 macro:  0.7115732925070568\n",
      "Accuracy:  0.73625\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.88      0.80       940\n",
      "           1       0.75      0.54      0.63       660\n",
      "\n",
      "    accuracy                           0.74      1600\n",
      "   macro avg       0.74      0.71      0.71      1600\n",
      "weighted avg       0.74      0.74      0.73      1600\n",
      "\n",
      "Support Vector Classification\n",
      "F1 macro:  0.7100327361232296\n",
      "Accuracy:  0.72375\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.80      0.77       940\n",
      "           1       0.68      0.61      0.65       660\n",
      "\n",
      "    accuracy                           0.72      1600\n",
      "   macro avg       0.72      0.71      0.71      1600\n",
      "weighted avg       0.72      0.72      0.72      1600\n",
      "\n",
      "Best Support Vector Classification\n",
      "F1 macro:  0.6827319661965332\n",
      "Accuracy:  0.725\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.93      0.80       940\n",
      "           1       0.81      0.44      0.57       660\n",
      "\n",
      "    accuracy                           0.73      1600\n",
      "   macro avg       0.75      0.68      0.68      1600\n",
      "weighted avg       0.75      0.72      0.70      1600\n",
      "\n",
      "AdaBoost classifier\n",
      "F1 macro:  0.6597154594400976\n",
      "Accuracy:  0.6675\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.70      0.71       940\n",
      "           1       0.59      0.63      0.61       660\n",
      "\n",
      "    accuracy                           0.67      1600\n",
      "   macro avg       0.66      0.66      0.66      1600\n",
      "weighted avg       0.67      0.67      0.67      1600\n",
      "\n",
      "Best AdaBoost classifier\n",
      "F1 macro:  0.6863158053805907\n",
      "Accuracy:  0.691875\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.70      0.73       940\n",
      "           1       0.61      0.68      0.64       660\n",
      "\n",
      "    accuracy                           0.69      1600\n",
      "   macro avg       0.69      0.69      0.69      1600\n",
      "weighted avg       0.70      0.69      0.69      1600\n",
      "\n",
      "Multi-layer Perceptron classifier\n",
      "F1 macro:  0.7067035528573992\n",
      "Accuracy:  0.71375\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.74      0.75       940\n",
      "           1       0.65      0.68      0.66       660\n",
      "\n",
      "    accuracy                           0.71      1600\n",
      "   macro avg       0.71      0.71      0.71      1600\n",
      "weighted avg       0.72      0.71      0.71      1600\n",
      "\n",
      "Best Multi-layer Perceptron classifier\n",
      "F1 macro:  0.6949705255236424\n",
      "Accuracy:  0.715\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.83      0.77       940\n",
      "           1       0.69      0.56      0.62       660\n",
      "\n",
      "    accuracy                           0.71      1600\n",
      "   macro avg       0.71      0.69      0.69      1600\n",
      "weighted avg       0.71      0.71      0.71      1600\n",
      "\n",
      "Bert base\n",
      "F1 macro:  0.9591979001127111\n",
      "Accuracy:  0.9602222222222222\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97      2643\n",
      "           1       0.93      0.97      0.95      1857\n",
      "\n",
      "    accuracy                           0.96      4500\n",
      "   macro avg       0.96      0.96      0.96      4500\n",
      "weighted avg       0.96      0.96      0.96      4500\n",
      "\n",
      "Bert base\n",
      "F1 macro:  0.8331825947140992\n",
      "Accuracy:  0.834\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.81      0.84       278\n",
      "           1       0.79      0.86      0.82       222\n",
      "\n",
      "    accuracy                           0.83       500\n",
      "   macro avg       0.83      0.84      0.83       500\n",
      "weighted avg       0.84      0.83      0.83       500\n",
      "\n",
      "Bert base\n",
      "F1 macro:  0.7413213956087423\n",
      "Accuracy:  0.7425\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.69      0.76       940\n",
      "           1       0.65      0.82      0.72       660\n",
      "\n",
      "    accuracy                           0.74      1600\n",
      "   macro avg       0.75      0.75      0.74      1600\n",
      "weighted avg       0.76      0.74      0.74      1600\n",
      "\n",
      "Bert Avarage\n",
      "F1 macro:  0.9393834282481186\n",
      "Accuracy:  0.9407777777777778\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95      5217\n",
      "           1       0.92      0.94      0.93      3783\n",
      "\n",
      "    accuracy                           0.94      9000\n",
      "   macro avg       0.94      0.94      0.94      9000\n",
      "weighted avg       0.94      0.94      0.94      9000\n",
      "\n",
      "Bert Avarage\n",
      "F1 macro:  0.7508450589145519\n",
      "Accuracy:  0.753\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.74      0.77       573\n",
      "           1       0.69      0.77      0.73       427\n",
      "\n",
      "    accuracy                           0.75      1000\n",
      "   macro avg       0.75      0.76      0.75      1000\n",
      "weighted avg       0.76      0.75      0.75      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Avarage\n",
      "F1 macro:  0.5939885574846252\n",
      "Accuracy:  0.606\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.37      0.52      1740\n",
      "           1       0.52      0.93      0.66      1260\n",
      "\n",
      "    accuracy                           0.61      3000\n",
      "   macro avg       0.70      0.65      0.59      3000\n",
      "weighted avg       0.72      0.61      0.58      3000\n",
      "\n",
      "Bert Avarage\n",
      "F1 macro:  0.9835327664403473\n",
      "Accuracy:  0.984\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      2643\n",
      "           1       0.97      0.99      0.98      1857\n",
      "\n",
      "    accuracy                           0.98      4500\n",
      "   macro avg       0.98      0.98      0.98      4500\n",
      "weighted avg       0.98      0.98      0.98      4500\n",
      "\n",
      "Bert Avarage\n",
      "F1 macro:  0.8312195592419347\n",
      "Accuracy:  0.832\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.81      0.84       278\n",
      "           1       0.78      0.86      0.82       222\n",
      "\n",
      "    accuracy                           0.83       500\n",
      "   macro avg       0.83      0.83      0.83       500\n",
      "weighted avg       0.84      0.83      0.83       500\n",
      "\n",
      "Bert Avarage\n",
      "F1 macro:  0.745737872226218\n",
      "Accuracy:  0.746875\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.69      0.76       940\n",
      "           1       0.65      0.82      0.73       660\n",
      "\n",
      "    accuracy                           0.75      1600\n",
      "   macro avg       0.75      0.76      0.75      1600\n",
      "weighted avg       0.77      0.75      0.75      1600\n",
      "\n",
      "GPT2 base\n",
      "F1 macro:  0.8054590613779311\n",
      "Accuracy:  0.8095555555555556\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83      5217\n",
      "           1       0.76      0.79      0.78      3783\n",
      "\n",
      "    accuracy                           0.81      9000\n",
      "   macro avg       0.80      0.81      0.81      9000\n",
      "weighted avg       0.81      0.81      0.81      9000\n",
      "\n",
      "GPT2 base\n",
      "F1 macro:  0.7356241852210881\n",
      "Accuracy:  0.739\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.74      0.77       573\n",
      "           1       0.68      0.73      0.71       427\n",
      "\n",
      "    accuracy                           0.74      1000\n",
      "   macro avg       0.73      0.74      0.74      1000\n",
      "weighted avg       0.74      0.74      0.74      1000\n",
      "\n",
      "GPT2 base\n",
      "F1 macro:  0.4359989192440023\n",
      "Accuracy:  0.49066666666666664\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.15      0.26      1740\n",
      "           1       0.45      0.95      0.61      1260\n",
      "\n",
      "    accuracy                           0.49      3000\n",
      "   macro avg       0.64      0.55      0.44      3000\n",
      "weighted avg       0.67      0.49      0.41      3000\n",
      "\n",
      "Atalaya\n",
      "F1 macro:  0.9015782362817413\n",
      "Accuracy:  0.9038888888888889\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.92      5217\n",
      "           1       0.88      0.89      0.89      3783\n",
      "\n",
      "    accuracy                           0.90      9000\n",
      "   macro avg       0.90      0.90      0.90      9000\n",
      "weighted avg       0.90      0.90      0.90      9000\n",
      "\n",
      "Atalaya\n",
      "F1 macro:  0.7400235293879628\n",
      "Accuracy:  0.743\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.74      0.77       573\n",
      "           1       0.68      0.74      0.71       427\n",
      "\n",
      "    accuracy                           0.74      1000\n",
      "   macro avg       0.74      0.74      0.74      1000\n",
      "weighted avg       0.75      0.74      0.74      1000\n",
      "\n",
      "Atalaya\n",
      "F1 macro:  0.4707390911055481\n",
      "Accuracy:  0.508\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.21      0.33      1740\n",
      "           1       0.46      0.92      0.61      1260\n",
      "\n",
      "    accuracy                           0.51      3000\n",
      "   macro avg       0.62      0.56      0.47      3000\n",
      "weighted avg       0.65      0.51      0.45      3000\n",
      "\n",
      "Atalaya\n",
      "F1 macro:  0.9465627517716503\n",
      "Accuracy:  0.948\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96      2643\n",
      "           1       0.93      0.95      0.94      1857\n",
      "\n",
      "    accuracy                           0.95      4500\n",
      "   macro avg       0.95      0.95      0.95      4500\n",
      "weighted avg       0.95      0.95      0.95      4500\n",
      "\n",
      "Atalaya\n",
      "F1 macro:  0.7396999891037204\n",
      "Accuracy:  0.742\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.75      0.76       278\n",
      "           1       0.70      0.73      0.72       222\n",
      "\n",
      "    accuracy                           0.74       500\n",
      "   macro avg       0.74      0.74      0.74       500\n",
      "weighted avg       0.74      0.74      0.74       500\n",
      "\n",
      "Atalaya\n",
      "F1 macro:  0.7082592009648918\n",
      "Accuracy:  0.71125\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.69      0.74       940\n",
      "           1       0.63      0.74      0.68       660\n",
      "\n",
      "    accuracy                           0.71      1600\n",
      "   macro avg       0.71      0.72      0.71      1600\n",
      "weighted avg       0.72      0.71      0.71      1600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for path, (name, desc, dataset_type, truth, group, task, lenguage, y_pred) in df_pred.iterrows():\n",
    "    y_true = df_truth[(df_truth[\"Dataset type\"] == dataset_type) & (df_truth[\"Task\"] == task) & (df_truth[\"Lenguage\"] == lenguage)][\"Results\"][0]\n",
    "    \n",
    "    result = print_score(y_true, y_pred, name)\n",
    "    result.update({\"Dataset type\": dataset_type, \"Name\": name, \"Group\": group, \"Lenguage\": lenguage, \"Description\": desc})\n",
    "    \n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a899896b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>F1 macro</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lenguage</th>\n",
       "      <th>Dataset type</th>\n",
       "      <th>Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">english</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">dataset_types.train</th>\n",
       "      <th>Random Forest classifier</th>\n",
       "      <td>0.998974</td>\n",
       "      <td>0.999000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best Random Forest classifier</th>\n",
       "      <td>0.996576</td>\n",
       "      <td>0.996667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Classification</th>\n",
       "      <td>0.956309</td>\n",
       "      <td>0.957556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entire layer</th>\n",
       "      <td>0.940645</td>\n",
       "      <td>0.942000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bert Avarage</th>\n",
       "      <td>0.939383</td>\n",
       "      <td>0.940778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">spanish</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">dataset_types.test</th>\n",
       "      <th>Best Support Vector Classification</th>\n",
       "      <td>0.682732</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial Naive Bayes classifier</th>\n",
       "      <td>0.670608</td>\n",
       "      <td>0.700625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost classifier</th>\n",
       "      <td>0.659715</td>\n",
       "      <td>0.667500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best Multinomial Naive Bayes classifier</th>\n",
       "      <td>0.655271</td>\n",
       "      <td>0.697500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dummy Classifier</th>\n",
       "      <td>0.370079</td>\n",
       "      <td>0.587500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                      F1 macro  \\\n",
       "Lenguage Dataset type        Name                                                \n",
       "english  dataset_types.train Random Forest classifier                 0.998974   \n",
       "                             Best Random Forest classifier            0.996576   \n",
       "                             Support Vector Classification            0.956309   \n",
       "                             Entire layer                             0.940645   \n",
       "                             Bert Avarage                             0.939383   \n",
       "...                                                                        ...   \n",
       "spanish  dataset_types.test  Best Support Vector Classification       0.682732   \n",
       "                             Multinomial Naive Bayes classifier       0.670608   \n",
       "                             AdaBoost classifier                      0.659715   \n",
       "                             Best Multinomial Naive Bayes classifier  0.655271   \n",
       "                             Dummy Classifier                         0.370079   \n",
       "\n",
       "                                                                      Accuracy  \n",
       "Lenguage Dataset type        Name                                               \n",
       "english  dataset_types.train Random Forest classifier                 0.999000  \n",
       "                             Best Random Forest classifier            0.996667  \n",
       "                             Support Vector Classification            0.957556  \n",
       "                             Entire layer                             0.942000  \n",
       "                             Bert Avarage                             0.940778  \n",
       "...                                                                        ...  \n",
       "spanish  dataset_types.test  Best Support Vector Classification       0.725000  \n",
       "                             Multinomial Naive Bayes classifier       0.700625  \n",
       "                             AdaBoost classifier                      0.667500  \n",
       "                             Best Multinomial Naive Bayes classifier  0.697500  \n",
       "                             Dummy Classifier                         0.587500  \n",
       "\n",
       "[120 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.DataFrame(results).set_index([\"Lenguage\", \"Dataset type\", \"Group\", \"Name\"]).groupby(level=[0, 1, 2, 3]).sum()\n",
    "df_results_index = df_results.sort_values(by=[\"Lenguage\", \"Dataset type\", \"F1 macro\", \"Accuracy\"], ascending=[True, True, False, False]).droplevel(\"Group\")\n",
    "df_results_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1ad2dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 3 1\n"
     ]
    }
   ],
   "source": [
    "a = [lambda x: 1, lambda x: 2, lambda x: 3] # Objective\n",
    "b = [(lambda x: i+1) for i in range(3)] # Problem\n",
    "c = [(lambda i: lambda x: i+1)(i) for i in range(3)] #First solution\n",
    "\n",
    "print(a[0](1), b[0](1), c[0](1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "888948a3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">F1 macro</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Development</th>\n",
       "      <th>Test</th>\n",
       "      <th>Train</th>\n",
       "      <th>Development</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lenguage</th>\n",
       "      <th>Group</th>\n",
       "      <th>Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"22\" valign=\"top\">English</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">traditional</th>\n",
       "      <th>Ridge Classifier</th>\n",
       "      <td>0.877431</td>\n",
       "      <td>0.709848</td>\n",
       "      <td>0.487733</td>\n",
       "      <td>0.881667</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.513667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multi-layer Perceptron classifier</th>\n",
       "      <td>0.888015</td>\n",
       "      <td>0.693095</td>\n",
       "      <td>0.483704</td>\n",
       "      <td>0.891444</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.511333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial Naive Bayes classifier</th>\n",
       "      <td>0.812630</td>\n",
       "      <td>0.730203</td>\n",
       "      <td>0.478476</td>\n",
       "      <td>0.820444</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.505667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Classification</th>\n",
       "      <td>0.956309</td>\n",
       "      <td>0.734485</td>\n",
       "      <td>0.447326</td>\n",
       "      <td>0.957556</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.486333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost classifier</th>\n",
       "      <td>0.767939</td>\n",
       "      <td>0.725852</td>\n",
       "      <td>0.419558</td>\n",
       "      <td>0.781667</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.463667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bernoulli Naive Bayes classifier</th>\n",
       "      <td>0.821029</td>\n",
       "      <td>0.734550</td>\n",
       "      <td>0.418188</td>\n",
       "      <td>0.826000</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.472667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest classifier</th>\n",
       "      <td>0.998974</td>\n",
       "      <td>0.731493</td>\n",
       "      <td>0.393599</td>\n",
       "      <td>0.999000</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.451000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dummy Classifier</th>\n",
       "      <td>0.366955</td>\n",
       "      <td>0.364272</td>\n",
       "      <td>0.367089</td>\n",
       "      <td>0.579667</td>\n",
       "      <td>0.573</td>\n",
       "      <td>0.580000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">deep_learning</th>\n",
       "      <th>Bert base</th>\n",
       "      <td>0.929994</td>\n",
       "      <td>0.746904</td>\n",
       "      <td>0.594150</td>\n",
       "      <td>0.931556</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.605333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bert Avarage</th>\n",
       "      <td>0.939383</td>\n",
       "      <td>0.750845</td>\n",
       "      <td>0.593989</td>\n",
       "      <td>0.940778</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.606000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atalaya</th>\n",
       "      <td>0.901578</td>\n",
       "      <td>0.740024</td>\n",
       "      <td>0.470739</td>\n",
       "      <td>0.903889</td>\n",
       "      <td>0.743</td>\n",
       "      <td>0.508000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPT2 base</th>\n",
       "      <td>0.805459</td>\n",
       "      <td>0.735624</td>\n",
       "      <td>0.435999</td>\n",
       "      <td>0.809556</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.490667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">best_traditional</th>\n",
       "      <th>Best Multi-layer Perceptron classifier</th>\n",
       "      <td>0.817371</td>\n",
       "      <td>0.732399</td>\n",
       "      <td>0.488366</td>\n",
       "      <td>0.821778</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.518000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best Multinomial Naive Bayes classifier</th>\n",
       "      <td>0.807131</td>\n",
       "      <td>0.732959</td>\n",
       "      <td>0.483788</td>\n",
       "      <td>0.816222</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.509000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best Ridge Classifier</th>\n",
       "      <td>0.827157</td>\n",
       "      <td>0.733554</td>\n",
       "      <td>0.480252</td>\n",
       "      <td>0.835667</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.507667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best Support Vector Classification</th>\n",
       "      <td>0.807855</td>\n",
       "      <td>0.706952</td>\n",
       "      <td>0.445668</td>\n",
       "      <td>0.820667</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.475333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best AdaBoost classifier</th>\n",
       "      <td>0.814896</td>\n",
       "      <td>0.704654</td>\n",
       "      <td>0.442895</td>\n",
       "      <td>0.824000</td>\n",
       "      <td>0.716</td>\n",
       "      <td>0.485333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best Bernoulli Naive Bayes classifier</th>\n",
       "      <td>0.815134</td>\n",
       "      <td>0.734426</td>\n",
       "      <td>0.429087</td>\n",
       "      <td>0.820889</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.479333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best Random Forest classifier</th>\n",
       "      <td>0.996576</td>\n",
       "      <td>0.750622</td>\n",
       "      <td>0.391320</td>\n",
       "      <td>0.996667</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.451333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">bert_avarage</th>\n",
       "      <th>CLS layers</th>\n",
       "      <td>0.931599</td>\n",
       "      <td>0.750351</td>\n",
       "      <td>0.589766</td>\n",
       "      <td>0.933111</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.602667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entire layer</th>\n",
       "      <td>0.940645</td>\n",
       "      <td>0.757246</td>\n",
       "      <td>0.586625</td>\n",
       "      <td>0.942000</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.599333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>0.936114</td>\n",
       "      <td>0.748223</td>\n",
       "      <td>0.586530</td>\n",
       "      <td>0.937444</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.599000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"18\" valign=\"top\">Spanish</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">traditional</th>\n",
       "      <th>Support Vector Classification</th>\n",
       "      <td>0.976335</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.710033</td>\n",
       "      <td>0.977111</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.723750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multi-layer Perceptron classifier</th>\n",
       "      <td>0.912374</td>\n",
       "      <td>0.729136</td>\n",
       "      <td>0.706704</td>\n",
       "      <td>0.915333</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.713750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bernoulli Naive Bayes classifier</th>\n",
       "      <td>0.877688</td>\n",
       "      <td>0.761420</td>\n",
       "      <td>0.699362</td>\n",
       "      <td>0.880889</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.703125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest classifier</th>\n",
       "      <td>0.999771</td>\n",
       "      <td>0.728113</td>\n",
       "      <td>0.699176</td>\n",
       "      <td>0.999778</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.726250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Classifier</th>\n",
       "      <td>0.933712</td>\n",
       "      <td>0.733851</td>\n",
       "      <td>0.699102</td>\n",
       "      <td>0.936000</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.705000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial Naive Bayes classifier</th>\n",
       "      <td>0.851474</td>\n",
       "      <td>0.709441</td>\n",
       "      <td>0.670608</td>\n",
       "      <td>0.862444</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.700625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost classifier</th>\n",
       "      <td>0.769740</td>\n",
       "      <td>0.741820</td>\n",
       "      <td>0.659715</td>\n",
       "      <td>0.782444</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.667500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dummy Classifier</th>\n",
       "      <td>0.370013</td>\n",
       "      <td>0.357326</td>\n",
       "      <td>0.370079</td>\n",
       "      <td>0.587333</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.587500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">deep_learning</th>\n",
       "      <th>Bert Avarage</th>\n",
       "      <td>0.983533</td>\n",
       "      <td>0.831220</td>\n",
       "      <td>0.745738</td>\n",
       "      <td>0.984000</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.746875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bert base</th>\n",
       "      <td>0.959198</td>\n",
       "      <td>0.833183</td>\n",
       "      <td>0.741321</td>\n",
       "      <td>0.960222</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.742500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atalaya</th>\n",
       "      <td>0.946563</td>\n",
       "      <td>0.739700</td>\n",
       "      <td>0.708259</td>\n",
       "      <td>0.948000</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.711250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">best_traditional</th>\n",
       "      <th>Best Ridge Classifier</th>\n",
       "      <td>0.863485</td>\n",
       "      <td>0.735636</td>\n",
       "      <td>0.712083</td>\n",
       "      <td>0.871333</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.725625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best Random Forest classifier</th>\n",
       "      <td>0.999542</td>\n",
       "      <td>0.725951</td>\n",
       "      <td>0.711573</td>\n",
       "      <td>0.999556</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.736250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best Bernoulli Naive Bayes classifier</th>\n",
       "      <td>0.871494</td>\n",
       "      <td>0.766972</td>\n",
       "      <td>0.698153</td>\n",
       "      <td>0.875556</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.702500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best Multi-layer Perceptron classifier</th>\n",
       "      <td>0.869665</td>\n",
       "      <td>0.699844</td>\n",
       "      <td>0.694971</td>\n",
       "      <td>0.876667</td>\n",
       "      <td>0.716</td>\n",
       "      <td>0.715000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best AdaBoost classifier</th>\n",
       "      <td>0.863730</td>\n",
       "      <td>0.745814</td>\n",
       "      <td>0.686316</td>\n",
       "      <td>0.869778</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.691875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best Support Vector Classification</th>\n",
       "      <td>0.811682</td>\n",
       "      <td>0.717398</td>\n",
       "      <td>0.682732</td>\n",
       "      <td>0.829111</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best Multinomial Naive Bayes classifier</th>\n",
       "      <td>0.819576</td>\n",
       "      <td>0.689804</td>\n",
       "      <td>0.655271</td>\n",
       "      <td>0.836667</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.697500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   F1 macro  \\\n",
       "                                                                      Train   \n",
       "Lenguage Group            Name                                                \n",
       "English  traditional      Ridge Classifier                         0.877431   \n",
       "                          Multi-layer Perceptron classifier        0.888015   \n",
       "                          Multinomial Naive Bayes classifier       0.812630   \n",
       "                          Support Vector Classification            0.956309   \n",
       "                          AdaBoost classifier                      0.767939   \n",
       "                          Bernoulli Naive Bayes classifier         0.821029   \n",
       "                          Random Forest classifier                 0.998974   \n",
       "                          Dummy Classifier                         0.366955   \n",
       "         deep_learning    Bert base                                0.929994   \n",
       "                          Bert Avarage                             0.939383   \n",
       "                          Atalaya                                  0.901578   \n",
       "                          GPT2 base                                0.805459   \n",
       "         best_traditional Best Multi-layer Perceptron classifier   0.817371   \n",
       "                          Best Multinomial Naive Bayes classifier  0.807131   \n",
       "                          Best Ridge Classifier                    0.827157   \n",
       "                          Best Support Vector Classification       0.807855   \n",
       "                          Best AdaBoost classifier                 0.814896   \n",
       "                          Best Bernoulli Naive Bayes classifier    0.815134   \n",
       "                          Best Random Forest classifier            0.996576   \n",
       "         bert_avarage     CLS layers                               0.931599   \n",
       "                          Entire layer                             0.940645   \n",
       "                          Tokens                                   0.936114   \n",
       "Spanish  traditional      Support Vector Classification            0.976335   \n",
       "                          Multi-layer Perceptron classifier        0.912374   \n",
       "                          Bernoulli Naive Bayes classifier         0.877688   \n",
       "                          Random Forest classifier                 0.999771   \n",
       "                          Ridge Classifier                         0.933712   \n",
       "                          Multinomial Naive Bayes classifier       0.851474   \n",
       "                          AdaBoost classifier                      0.769740   \n",
       "                          Dummy Classifier                         0.370013   \n",
       "         deep_learning    Bert Avarage                             0.983533   \n",
       "                          Bert base                                0.959198   \n",
       "                          Atalaya                                  0.946563   \n",
       "         best_traditional Best Ridge Classifier                    0.863485   \n",
       "                          Best Random Forest classifier            0.999542   \n",
       "                          Best Bernoulli Naive Bayes classifier    0.871494   \n",
       "                          Best Multi-layer Perceptron classifier   0.869665   \n",
       "                          Best AdaBoost classifier                 0.863730   \n",
       "                          Best Support Vector Classification       0.811682   \n",
       "                          Best Multinomial Naive Bayes classifier  0.819576   \n",
       "\n",
       "                                                                               \\\n",
       "                                                                  Development   \n",
       "Lenguage Group            Name                                                  \n",
       "English  traditional      Ridge Classifier                           0.709848   \n",
       "                          Multi-layer Perceptron classifier          0.693095   \n",
       "                          Multinomial Naive Bayes classifier         0.730203   \n",
       "                          Support Vector Classification              0.734485   \n",
       "                          AdaBoost classifier                        0.725852   \n",
       "                          Bernoulli Naive Bayes classifier           0.734550   \n",
       "                          Random Forest classifier                   0.731493   \n",
       "                          Dummy Classifier                           0.364272   \n",
       "         deep_learning    Bert base                                  0.746904   \n",
       "                          Bert Avarage                               0.750845   \n",
       "                          Atalaya                                    0.740024   \n",
       "                          GPT2 base                                  0.735624   \n",
       "         best_traditional Best Multi-layer Perceptron classifier     0.732399   \n",
       "                          Best Multinomial Naive Bayes classifier    0.732959   \n",
       "                          Best Ridge Classifier                      0.733554   \n",
       "                          Best Support Vector Classification         0.706952   \n",
       "                          Best AdaBoost classifier                   0.704654   \n",
       "                          Best Bernoulli Naive Bayes classifier      0.734426   \n",
       "                          Best Random Forest classifier              0.750622   \n",
       "         bert_avarage     CLS layers                                 0.750351   \n",
       "                          Entire layer                               0.757246   \n",
       "                          Tokens                                     0.748223   \n",
       "Spanish  traditional      Support Vector Classification              0.741667   \n",
       "                          Multi-layer Perceptron classifier          0.729136   \n",
       "                          Bernoulli Naive Bayes classifier           0.761420   \n",
       "                          Random Forest classifier                   0.728113   \n",
       "                          Ridge Classifier                           0.733851   \n",
       "                          Multinomial Naive Bayes classifier         0.709441   \n",
       "                          AdaBoost classifier                        0.741820   \n",
       "                          Dummy Classifier                           0.357326   \n",
       "         deep_learning    Bert Avarage                               0.831220   \n",
       "                          Bert base                                  0.833183   \n",
       "                          Atalaya                                    0.739700   \n",
       "         best_traditional Best Ridge Classifier                      0.735636   \n",
       "                          Best Random Forest classifier              0.725951   \n",
       "                          Best Bernoulli Naive Bayes classifier      0.766972   \n",
       "                          Best Multi-layer Perceptron classifier     0.699844   \n",
       "                          Best AdaBoost classifier                   0.745814   \n",
       "                          Best Support Vector Classification         0.717398   \n",
       "                          Best Multinomial Naive Bayes classifier    0.689804   \n",
       "\n",
       "                                                                             \\\n",
       "                                                                       Test   \n",
       "Lenguage Group            Name                                                \n",
       "English  traditional      Ridge Classifier                         0.487733   \n",
       "                          Multi-layer Perceptron classifier        0.483704   \n",
       "                          Multinomial Naive Bayes classifier       0.478476   \n",
       "                          Support Vector Classification            0.447326   \n",
       "                          AdaBoost classifier                      0.419558   \n",
       "                          Bernoulli Naive Bayes classifier         0.418188   \n",
       "                          Random Forest classifier                 0.393599   \n",
       "                          Dummy Classifier                         0.367089   \n",
       "         deep_learning    Bert base                                0.594150   \n",
       "                          Bert Avarage                             0.593989   \n",
       "                          Atalaya                                  0.470739   \n",
       "                          GPT2 base                                0.435999   \n",
       "         best_traditional Best Multi-layer Perceptron classifier   0.488366   \n",
       "                          Best Multinomial Naive Bayes classifier  0.483788   \n",
       "                          Best Ridge Classifier                    0.480252   \n",
       "                          Best Support Vector Classification       0.445668   \n",
       "                          Best AdaBoost classifier                 0.442895   \n",
       "                          Best Bernoulli Naive Bayes classifier    0.429087   \n",
       "                          Best Random Forest classifier            0.391320   \n",
       "         bert_avarage     CLS layers                               0.589766   \n",
       "                          Entire layer                             0.586625   \n",
       "                          Tokens                                   0.586530   \n",
       "Spanish  traditional      Support Vector Classification            0.710033   \n",
       "                          Multi-layer Perceptron classifier        0.706704   \n",
       "                          Bernoulli Naive Bayes classifier         0.699362   \n",
       "                          Random Forest classifier                 0.699176   \n",
       "                          Ridge Classifier                         0.699102   \n",
       "                          Multinomial Naive Bayes classifier       0.670608   \n",
       "                          AdaBoost classifier                      0.659715   \n",
       "                          Dummy Classifier                         0.370079   \n",
       "         deep_learning    Bert Avarage                             0.745738   \n",
       "                          Bert base                                0.741321   \n",
       "                          Atalaya                                  0.708259   \n",
       "         best_traditional Best Ridge Classifier                    0.712083   \n",
       "                          Best Random Forest classifier            0.711573   \n",
       "                          Best Bernoulli Naive Bayes classifier    0.698153   \n",
       "                          Best Multi-layer Perceptron classifier   0.694971   \n",
       "                          Best AdaBoost classifier                 0.686316   \n",
       "                          Best Support Vector Classification       0.682732   \n",
       "                          Best Multinomial Naive Bayes classifier  0.655271   \n",
       "\n",
       "                                                                   Accuracy  \\\n",
       "                                                                      Train   \n",
       "Lenguage Group            Name                                                \n",
       "English  traditional      Ridge Classifier                         0.881667   \n",
       "                          Multi-layer Perceptron classifier        0.891444   \n",
       "                          Multinomial Naive Bayes classifier       0.820444   \n",
       "                          Support Vector Classification            0.957556   \n",
       "                          AdaBoost classifier                      0.781667   \n",
       "                          Bernoulli Naive Bayes classifier         0.826000   \n",
       "                          Random Forest classifier                 0.999000   \n",
       "                          Dummy Classifier                         0.579667   \n",
       "         deep_learning    Bert base                                0.931556   \n",
       "                          Bert Avarage                             0.940778   \n",
       "                          Atalaya                                  0.903889   \n",
       "                          GPT2 base                                0.809556   \n",
       "         best_traditional Best Multi-layer Perceptron classifier   0.821778   \n",
       "                          Best Multinomial Naive Bayes classifier  0.816222   \n",
       "                          Best Ridge Classifier                    0.835667   \n",
       "                          Best Support Vector Classification       0.820667   \n",
       "                          Best AdaBoost classifier                 0.824000   \n",
       "                          Best Bernoulli Naive Bayes classifier    0.820889   \n",
       "                          Best Random Forest classifier            0.996667   \n",
       "         bert_avarage     CLS layers                               0.933111   \n",
       "                          Entire layer                             0.942000   \n",
       "                          Tokens                                   0.937444   \n",
       "Spanish  traditional      Support Vector Classification            0.977111   \n",
       "                          Multi-layer Perceptron classifier        0.915333   \n",
       "                          Bernoulli Naive Bayes classifier         0.880889   \n",
       "                          Random Forest classifier                 0.999778   \n",
       "                          Ridge Classifier                         0.936000   \n",
       "                          Multinomial Naive Bayes classifier       0.862444   \n",
       "                          AdaBoost classifier                      0.782444   \n",
       "                          Dummy Classifier                         0.587333   \n",
       "         deep_learning    Bert Avarage                             0.984000   \n",
       "                          Bert base                                0.960222   \n",
       "                          Atalaya                                  0.948000   \n",
       "         best_traditional Best Ridge Classifier                    0.871333   \n",
       "                          Best Random Forest classifier            0.999556   \n",
       "                          Best Bernoulli Naive Bayes classifier    0.875556   \n",
       "                          Best Multi-layer Perceptron classifier   0.876667   \n",
       "                          Best AdaBoost classifier                 0.869778   \n",
       "                          Best Support Vector Classification       0.829111   \n",
       "                          Best Multinomial Naive Bayes classifier  0.836667   \n",
       "\n",
       "                                                                               \\\n",
       "                                                                  Development   \n",
       "Lenguage Group            Name                                                  \n",
       "English  traditional      Ridge Classifier                              0.717   \n",
       "                          Multi-layer Perceptron classifier             0.700   \n",
       "                          Multinomial Naive Bayes classifier            0.738   \n",
       "                          Support Vector Classification                 0.745   \n",
       "                          AdaBoost classifier                           0.739   \n",
       "                          Bernoulli Naive Bayes classifier              0.738   \n",
       "                          Random Forest classifier                      0.740   \n",
       "                          Dummy Classifier                              0.573   \n",
       "         deep_learning    Bert base                                     0.749   \n",
       "                          Bert Avarage                                  0.753   \n",
       "                          Atalaya                                       0.743   \n",
       "                          GPT2 base                                     0.739   \n",
       "         best_traditional Best Multi-layer Perceptron classifier        0.736   \n",
       "                          Best Multinomial Naive Bayes classifier       0.742   \n",
       "                          Best Ridge Classifier                         0.744   \n",
       "                          Best Support Vector Classification            0.728   \n",
       "                          Best AdaBoost classifier                      0.716   \n",
       "                          Best Bernoulli Naive Bayes classifier         0.738   \n",
       "                          Best Random Forest classifier                 0.758   \n",
       "         bert_avarage     CLS layers                                    0.753   \n",
       "                          Entire layer                                  0.759   \n",
       "                          Tokens                                        0.750   \n",
       "Spanish  traditional      Support Vector Classification                 0.752   \n",
       "                          Multi-layer Perceptron classifier             0.734   \n",
       "                          Bernoulli Naive Bayes classifier              0.764   \n",
       "                          Random Forest classifier                      0.742   \n",
       "                          Ridge Classifier                              0.740   \n",
       "                          Multinomial Naive Bayes classifier            0.730   \n",
       "                          AdaBoost classifier                           0.750   \n",
       "                          Dummy Classifier                              0.556   \n",
       "         deep_learning    Bert Avarage                                  0.832   \n",
       "                          Bert base                                     0.834   \n",
       "                          Atalaya                                       0.742   \n",
       "         best_traditional Best Ridge Classifier                         0.746   \n",
       "                          Best Random Forest classifier                 0.742   \n",
       "                          Best Bernoulli Naive Bayes classifier         0.770   \n",
       "                          Best Multi-layer Perceptron classifier        0.716   \n",
       "                          Best AdaBoost classifier                      0.752   \n",
       "                          Best Support Vector Classification            0.738   \n",
       "                          Best Multinomial Naive Bayes classifier       0.720   \n",
       "\n",
       "                                                                             \n",
       "                                                                       Test  \n",
       "Lenguage Group            Name                                               \n",
       "English  traditional      Ridge Classifier                         0.513667  \n",
       "                          Multi-layer Perceptron classifier        0.511333  \n",
       "                          Multinomial Naive Bayes classifier       0.505667  \n",
       "                          Support Vector Classification            0.486333  \n",
       "                          AdaBoost classifier                      0.463667  \n",
       "                          Bernoulli Naive Bayes classifier         0.472667  \n",
       "                          Random Forest classifier                 0.451000  \n",
       "                          Dummy Classifier                         0.580000  \n",
       "         deep_learning    Bert base                                0.605333  \n",
       "                          Bert Avarage                             0.606000  \n",
       "                          Atalaya                                  0.508000  \n",
       "                          GPT2 base                                0.490667  \n",
       "         best_traditional Best Multi-layer Perceptron classifier   0.518000  \n",
       "                          Best Multinomial Naive Bayes classifier  0.509000  \n",
       "                          Best Ridge Classifier                    0.507667  \n",
       "                          Best Support Vector Classification       0.475333  \n",
       "                          Best AdaBoost classifier                 0.485333  \n",
       "                          Best Bernoulli Naive Bayes classifier    0.479333  \n",
       "                          Best Random Forest classifier            0.451333  \n",
       "         bert_avarage     CLS layers                               0.602667  \n",
       "                          Entire layer                             0.599333  \n",
       "                          Tokens                                   0.599000  \n",
       "Spanish  traditional      Support Vector Classification            0.723750  \n",
       "                          Multi-layer Perceptron classifier        0.713750  \n",
       "                          Bernoulli Naive Bayes classifier         0.703125  \n",
       "                          Random Forest classifier                 0.726250  \n",
       "                          Ridge Classifier                         0.705000  \n",
       "                          Multinomial Naive Bayes classifier       0.700625  \n",
       "                          AdaBoost classifier                      0.667500  \n",
       "                          Dummy Classifier                         0.587500  \n",
       "         deep_learning    Bert Avarage                             0.746875  \n",
       "                          Bert base                                0.742500  \n",
       "                          Atalaya                                  0.711250  \n",
       "         best_traditional Best Ridge Classifier                    0.725625  \n",
       "                          Best Random Forest classifier            0.736250  \n",
       "                          Best Bernoulli Naive Bayes classifier    0.702500  \n",
       "                          Best Multi-layer Perceptron classifier   0.715000  \n",
       "                          Best AdaBoost classifier                 0.691875  \n",
       "                          Best Support Vector Classification       0.725000  \n",
       "                          Best Multinomial Naive Bayes classifier  0.697500  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_aggregate = [(lambda t: lambda x: x[:, t])(t) for t in dataset_types]\n",
    "df_results_columns = df_results.groupby([\"Lenguage\",'Group','Name']).aggregate(list_aggregate)\n",
    "df_results_columns.columns = pd.MultiIndex.from_product([['F1 macro', 'Accuracy'], [t.name.capitalize() for t in dataset_types]])\n",
    "df_results_columns = df_results_columns.sort_values(by=['Lenguage', 'Group', (\"F1 macro\", dataset_types.test.name.capitalize())], ascending=[True, False, False])\n",
    "df_results_columns.index = df_results_columns.index.set_levels([' '.join(i.split('_')).title() for i in df_results_columns.index.levels[0]], level=0)\n",
    "\n",
    "df_results_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4669ff9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">F1 macro</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Development</th>\n",
       "      <th>Test</th>\n",
       "      <th>Train</th>\n",
       "      <th>Development</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lenguage</th>\n",
       "      <th>Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"22\" valign=\"top\">English</th>\n",
       "      <th>Bert base</th>\n",
       "      <td>0.929994</td>\n",
       "      <td>0.746904</td>\n",
       "      <td>0.594150</td>\n",
       "      <td>0.931556</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.605333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bert Avarage</th>\n",
       "      <td>0.939383</td>\n",
       "      <td>0.750845</td>\n",
       "      <td>0.593989</td>\n",
       "      <td>0.940778</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.606000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLS layers</th>\n",
       "      <td>0.931599</td>\n",
       "      <td>0.750351</td>\n",
       "      <td>0.589766</td>\n",
       "      <td>0.933111</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.602667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entire layer</th>\n",
       "      <td>0.940645</td>\n",
       "      <td>0.757246</td>\n",
       "      <td>0.586625</td>\n",
       "      <td>0.942000</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.599333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>0.936114</td>\n",
       "      <td>0.748223</td>\n",
       "      <td>0.586530</td>\n",
       "      <td>0.937444</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.599000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best Multi-layer Perceptron classifier</th>\n",
       "      <td>0.817371</td>\n",
       "      <td>0.732399</td>\n",
       "      <td>0.488366</td>\n",
       "      <td>0.821778</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.518000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Classifier</th>\n",
       "      <td>0.877431</td>\n",
       "      <td>0.709848</td>\n",
       "      <td>0.487733</td>\n",
       "      <td>0.881667</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.513667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best Multinomial Naive Bayes classifier</th>\n",
       "      <td>0.807131</td>\n",
       "      <td>0.732959</td>\n",
       "      <td>0.483788</td>\n",
       "      <td>0.816222</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.509000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multi-layer Perceptron classifier</th>\n",
       "      <td>0.888015</td>\n",
       "      <td>0.693095</td>\n",
       "      <td>0.483704</td>\n",
       "      <td>0.891444</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.511333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best Ridge Classifier</th>\n",
       "      <td>0.827157</td>\n",
       "      <td>0.733554</td>\n",
       "      <td>0.480252</td>\n",
       "      <td>0.835667</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.507667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial Naive Bayes classifier</th>\n",
       "      <td>0.812630</td>\n",
       "      <td>0.730203</td>\n",
       "      <td>0.478476</td>\n",
       "      <td>0.820444</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.505667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atalaya</th>\n",
       "      <td>0.901578</td>\n",
       "      <td>0.740024</td>\n",
       "      <td>0.470739</td>\n",
       "      <td>0.903889</td>\n",
       "      <td>0.743</td>\n",
       "      <td>0.508000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Classification</th>\n",
       "      <td>0.956309</td>\n",
       "      <td>0.734485</td>\n",
       "      <td>0.447326</td>\n",
       "      <td>0.957556</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.486333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best Support Vector Classification</th>\n",
       "      <td>0.807855</td>\n",
       "      <td>0.706952</td>\n",
       "      <td>0.445668</td>\n",
       "      <td>0.820667</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.475333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best AdaBoost classifier</th>\n",
       "      <td>0.814896</td>\n",
       "      <td>0.704654</td>\n",
       "      <td>0.442895</td>\n",
       "      <td>0.824000</td>\n",
       "      <td>0.716</td>\n",
       "      <td>0.485333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPT2 base</th>\n",
       "      <td>0.805459</td>\n",
       "      <td>0.735624</td>\n",
       "      <td>0.435999</td>\n",
       "      <td>0.809556</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.490667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best Bernoulli Naive Bayes classifier</th>\n",
       "      <td>0.815134</td>\n",
       "      <td>0.734426</td>\n",
       "      <td>0.429087</td>\n",
       "      <td>0.820889</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.479333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost classifier</th>\n",
       "      <td>0.767939</td>\n",
       "      <td>0.725852</td>\n",
       "      <td>0.419558</td>\n",
       "      <td>0.781667</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.463667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bernoulli Naive Bayes classifier</th>\n",
       "      <td>0.821029</td>\n",
       "      <td>0.734550</td>\n",
       "      <td>0.418188</td>\n",
       "      <td>0.826000</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.472667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest classifier</th>\n",
       "      <td>0.998974</td>\n",
       "      <td>0.731493</td>\n",
       "      <td>0.393599</td>\n",
       "      <td>0.999000</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.451000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best Random Forest classifier</th>\n",
       "      <td>0.996576</td>\n",
       "      <td>0.750622</td>\n",
       "      <td>0.391320</td>\n",
       "      <td>0.996667</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.451333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dummy Classifier</th>\n",
       "      <td>0.366955</td>\n",
       "      <td>0.364272</td>\n",
       "      <td>0.367089</td>\n",
       "      <td>0.579667</td>\n",
       "      <td>0.573</td>\n",
       "      <td>0.580000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"18\" valign=\"top\">Spanish</th>\n",
       "      <th>Bert Avarage</th>\n",
       "      <td>0.983533</td>\n",
       "      <td>0.831220</td>\n",
       "      <td>0.745738</td>\n",
       "      <td>0.984000</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.746875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bert base</th>\n",
       "      <td>0.959198</td>\n",
       "      <td>0.833183</td>\n",
       "      <td>0.741321</td>\n",
       "      <td>0.960222</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.742500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best Ridge Classifier</th>\n",
       "      <td>0.863485</td>\n",
       "      <td>0.735636</td>\n",
       "      <td>0.712083</td>\n",
       "      <td>0.871333</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.725625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best Random Forest classifier</th>\n",
       "      <td>0.999542</td>\n",
       "      <td>0.725951</td>\n",
       "      <td>0.711573</td>\n",
       "      <td>0.999556</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.736250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Classification</th>\n",
       "      <td>0.976335</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.710033</td>\n",
       "      <td>0.977111</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.723750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atalaya</th>\n",
       "      <td>0.946563</td>\n",
       "      <td>0.739700</td>\n",
       "      <td>0.708259</td>\n",
       "      <td>0.948000</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.711250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multi-layer Perceptron classifier</th>\n",
       "      <td>0.912374</td>\n",
       "      <td>0.729136</td>\n",
       "      <td>0.706704</td>\n",
       "      <td>0.915333</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.713750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bernoulli Naive Bayes classifier</th>\n",
       "      <td>0.877688</td>\n",
       "      <td>0.761420</td>\n",
       "      <td>0.699362</td>\n",
       "      <td>0.880889</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.703125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest classifier</th>\n",
       "      <td>0.999771</td>\n",
       "      <td>0.728113</td>\n",
       "      <td>0.699176</td>\n",
       "      <td>0.999778</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.726250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Classifier</th>\n",
       "      <td>0.933712</td>\n",
       "      <td>0.733851</td>\n",
       "      <td>0.699102</td>\n",
       "      <td>0.936000</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.705000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best Bernoulli Naive Bayes classifier</th>\n",
       "      <td>0.871494</td>\n",
       "      <td>0.766972</td>\n",
       "      <td>0.698153</td>\n",
       "      <td>0.875556</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.702500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best Multi-layer Perceptron classifier</th>\n",
       "      <td>0.869665</td>\n",
       "      <td>0.699844</td>\n",
       "      <td>0.694971</td>\n",
       "      <td>0.876667</td>\n",
       "      <td>0.716</td>\n",
       "      <td>0.715000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best AdaBoost classifier</th>\n",
       "      <td>0.863730</td>\n",
       "      <td>0.745814</td>\n",
       "      <td>0.686316</td>\n",
       "      <td>0.869778</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.691875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best Support Vector Classification</th>\n",
       "      <td>0.811682</td>\n",
       "      <td>0.717398</td>\n",
       "      <td>0.682732</td>\n",
       "      <td>0.829111</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial Naive Bayes classifier</th>\n",
       "      <td>0.851474</td>\n",
       "      <td>0.709441</td>\n",
       "      <td>0.670608</td>\n",
       "      <td>0.862444</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.700625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost classifier</th>\n",
       "      <td>0.769740</td>\n",
       "      <td>0.741820</td>\n",
       "      <td>0.659715</td>\n",
       "      <td>0.782444</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.667500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best Multinomial Naive Bayes classifier</th>\n",
       "      <td>0.819576</td>\n",
       "      <td>0.689804</td>\n",
       "      <td>0.655271</td>\n",
       "      <td>0.836667</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.697500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dummy Classifier</th>\n",
       "      <td>0.370013</td>\n",
       "      <td>0.357326</td>\n",
       "      <td>0.370079</td>\n",
       "      <td>0.587333</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.587500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  F1 macro              \\\n",
       "                                                     Train Development   \n",
       "Lenguage Name                                                            \n",
       "English  Bert base                                0.929994    0.746904   \n",
       "         Bert Avarage                             0.939383    0.750845   \n",
       "         CLS layers                               0.931599    0.750351   \n",
       "         Entire layer                             0.940645    0.757246   \n",
       "         Tokens                                   0.936114    0.748223   \n",
       "         Best Multi-layer Perceptron classifier   0.817371    0.732399   \n",
       "         Ridge Classifier                         0.877431    0.709848   \n",
       "         Best Multinomial Naive Bayes classifier  0.807131    0.732959   \n",
       "         Multi-layer Perceptron classifier        0.888015    0.693095   \n",
       "         Best Ridge Classifier                    0.827157    0.733554   \n",
       "         Multinomial Naive Bayes classifier       0.812630    0.730203   \n",
       "         Atalaya                                  0.901578    0.740024   \n",
       "         Support Vector Classification            0.956309    0.734485   \n",
       "         Best Support Vector Classification       0.807855    0.706952   \n",
       "         Best AdaBoost classifier                 0.814896    0.704654   \n",
       "         GPT2 base                                0.805459    0.735624   \n",
       "         Best Bernoulli Naive Bayes classifier    0.815134    0.734426   \n",
       "         AdaBoost classifier                      0.767939    0.725852   \n",
       "         Bernoulli Naive Bayes classifier         0.821029    0.734550   \n",
       "         Random Forest classifier                 0.998974    0.731493   \n",
       "         Best Random Forest classifier            0.996576    0.750622   \n",
       "         Dummy Classifier                         0.366955    0.364272   \n",
       "Spanish  Bert Avarage                             0.983533    0.831220   \n",
       "         Bert base                                0.959198    0.833183   \n",
       "         Best Ridge Classifier                    0.863485    0.735636   \n",
       "         Best Random Forest classifier            0.999542    0.725951   \n",
       "         Support Vector Classification            0.976335    0.741667   \n",
       "         Atalaya                                  0.946563    0.739700   \n",
       "         Multi-layer Perceptron classifier        0.912374    0.729136   \n",
       "         Bernoulli Naive Bayes classifier         0.877688    0.761420   \n",
       "         Random Forest classifier                 0.999771    0.728113   \n",
       "         Ridge Classifier                         0.933712    0.733851   \n",
       "         Best Bernoulli Naive Bayes classifier    0.871494    0.766972   \n",
       "         Best Multi-layer Perceptron classifier   0.869665    0.699844   \n",
       "         Best AdaBoost classifier                 0.863730    0.745814   \n",
       "         Best Support Vector Classification       0.811682    0.717398   \n",
       "         Multinomial Naive Bayes classifier       0.851474    0.709441   \n",
       "         AdaBoost classifier                      0.769740    0.741820   \n",
       "         Best Multinomial Naive Bayes classifier  0.819576    0.689804   \n",
       "         Dummy Classifier                         0.370013    0.357326   \n",
       "\n",
       "                                                            Accuracy  \\\n",
       "                                                      Test     Train   \n",
       "Lenguage Name                                                          \n",
       "English  Bert base                                0.594150  0.931556   \n",
       "         Bert Avarage                             0.593989  0.940778   \n",
       "         CLS layers                               0.589766  0.933111   \n",
       "         Entire layer                             0.586625  0.942000   \n",
       "         Tokens                                   0.586530  0.937444   \n",
       "         Best Multi-layer Perceptron classifier   0.488366  0.821778   \n",
       "         Ridge Classifier                         0.487733  0.881667   \n",
       "         Best Multinomial Naive Bayes classifier  0.483788  0.816222   \n",
       "         Multi-layer Perceptron classifier        0.483704  0.891444   \n",
       "         Best Ridge Classifier                    0.480252  0.835667   \n",
       "         Multinomial Naive Bayes classifier       0.478476  0.820444   \n",
       "         Atalaya                                  0.470739  0.903889   \n",
       "         Support Vector Classification            0.447326  0.957556   \n",
       "         Best Support Vector Classification       0.445668  0.820667   \n",
       "         Best AdaBoost classifier                 0.442895  0.824000   \n",
       "         GPT2 base                                0.435999  0.809556   \n",
       "         Best Bernoulli Naive Bayes classifier    0.429087  0.820889   \n",
       "         AdaBoost classifier                      0.419558  0.781667   \n",
       "         Bernoulli Naive Bayes classifier         0.418188  0.826000   \n",
       "         Random Forest classifier                 0.393599  0.999000   \n",
       "         Best Random Forest classifier            0.391320  0.996667   \n",
       "         Dummy Classifier                         0.367089  0.579667   \n",
       "Spanish  Bert Avarage                             0.745738  0.984000   \n",
       "         Bert base                                0.741321  0.960222   \n",
       "         Best Ridge Classifier                    0.712083  0.871333   \n",
       "         Best Random Forest classifier            0.711573  0.999556   \n",
       "         Support Vector Classification            0.710033  0.977111   \n",
       "         Atalaya                                  0.708259  0.948000   \n",
       "         Multi-layer Perceptron classifier        0.706704  0.915333   \n",
       "         Bernoulli Naive Bayes classifier         0.699362  0.880889   \n",
       "         Random Forest classifier                 0.699176  0.999778   \n",
       "         Ridge Classifier                         0.699102  0.936000   \n",
       "         Best Bernoulli Naive Bayes classifier    0.698153  0.875556   \n",
       "         Best Multi-layer Perceptron classifier   0.694971  0.876667   \n",
       "         Best AdaBoost classifier                 0.686316  0.869778   \n",
       "         Best Support Vector Classification       0.682732  0.829111   \n",
       "         Multinomial Naive Bayes classifier       0.670608  0.862444   \n",
       "         AdaBoost classifier                      0.659715  0.782444   \n",
       "         Best Multinomial Naive Bayes classifier  0.655271  0.836667   \n",
       "         Dummy Classifier                         0.370079  0.587333   \n",
       "\n",
       "                                                                        \n",
       "                                                 Development      Test  \n",
       "Lenguage Name                                                           \n",
       "English  Bert base                                     0.749  0.605333  \n",
       "         Bert Avarage                                  0.753  0.606000  \n",
       "         CLS layers                                    0.753  0.602667  \n",
       "         Entire layer                                  0.759  0.599333  \n",
       "         Tokens                                        0.750  0.599000  \n",
       "         Best Multi-layer Perceptron classifier        0.736  0.518000  \n",
       "         Ridge Classifier                              0.717  0.513667  \n",
       "         Best Multinomial Naive Bayes classifier       0.742  0.509000  \n",
       "         Multi-layer Perceptron classifier             0.700  0.511333  \n",
       "         Best Ridge Classifier                         0.744  0.507667  \n",
       "         Multinomial Naive Bayes classifier            0.738  0.505667  \n",
       "         Atalaya                                       0.743  0.508000  \n",
       "         Support Vector Classification                 0.745  0.486333  \n",
       "         Best Support Vector Classification            0.728  0.475333  \n",
       "         Best AdaBoost classifier                      0.716  0.485333  \n",
       "         GPT2 base                                     0.739  0.490667  \n",
       "         Best Bernoulli Naive Bayes classifier         0.738  0.479333  \n",
       "         AdaBoost classifier                           0.739  0.463667  \n",
       "         Bernoulli Naive Bayes classifier              0.738  0.472667  \n",
       "         Random Forest classifier                      0.740  0.451000  \n",
       "         Best Random Forest classifier                 0.758  0.451333  \n",
       "         Dummy Classifier                              0.573  0.580000  \n",
       "Spanish  Bert Avarage                                  0.832  0.746875  \n",
       "         Bert base                                     0.834  0.742500  \n",
       "         Best Ridge Classifier                         0.746  0.725625  \n",
       "         Best Random Forest classifier                 0.742  0.736250  \n",
       "         Support Vector Classification                 0.752  0.723750  \n",
       "         Atalaya                                       0.742  0.711250  \n",
       "         Multi-layer Perceptron classifier             0.734  0.713750  \n",
       "         Bernoulli Naive Bayes classifier              0.764  0.703125  \n",
       "         Random Forest classifier                      0.742  0.726250  \n",
       "         Ridge Classifier                              0.740  0.705000  \n",
       "         Best Bernoulli Naive Bayes classifier         0.770  0.702500  \n",
       "         Best Multi-layer Perceptron classifier        0.716  0.715000  \n",
       "         Best AdaBoost classifier                      0.752  0.691875  \n",
       "         Best Support Vector Classification            0.738  0.725000  \n",
       "         Multinomial Naive Bayes classifier            0.730  0.700625  \n",
       "         AdaBoost classifier                           0.750  0.667500  \n",
       "         Best Multinomial Naive Bayes classifier       0.720  0.697500  \n",
       "         Dummy Classifier                              0.556  0.587500  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_columns2 = df_results_columns.droplevel('Group')\n",
    "df_results_columns2 = df_results_columns2.sort_values(by=[\"Lenguage\", (\"F1 macro\", dataset_types.test.name.capitalize())], ascending=[True, False])\n",
    "df_results_columns2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ef0e38",
   "metadata": {},
   "source": [
    "Improvements:\n",
    "- Allow removal of all files with specific features (not just path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430e3fe5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
