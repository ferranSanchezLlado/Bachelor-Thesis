{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe885e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from enum import Enum\n",
    "\n",
    "metadata_file = \"./results/metadata.pkl\"\n",
    "dataset_types =  Enum(\"dataset_types\", \"train development test\")\n",
    "\n",
    "def save_results(y_pred, index, name, task, lenguage, dataset_type, group=None, description=None, truth=False, filename=None):\n",
    "    \n",
    "    path = f\"./results/{task}/{lenguage}/{dataset_type.name}{'/' + group if group is not None else ''}/{name if filename is None else filename}.pkl\"\n",
    "    \n",
    "    directory = \"/\".join(path.split(\"/\")[:-1])\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    if os.path.exists(metadata_file):\n",
    "        metadata = pd.read_pickle(metadata_file)\n",
    "    else:\n",
    "        metadata = pd.DataFrame({\n",
    "            \"Path\": pd.Series([], dtype=str),\n",
    "            \"Name\": pd.Series([], dtype=str),\n",
    "            \"Description\": pd.Series([], dtype=str),\n",
    "            \"Dataset type\": pd.Categorical([], categories=dataset_types, ordered=False),\n",
    "            \"Groud Truth\": pd.Series([], dtype=bool),\n",
    "            \"Group\": pd.Series([], dtype=str),\n",
    "            \"Task\": pd.Series([], dtype=str),\n",
    "            \"Lenguage\": pd.Series([], dtype=str),\n",
    "        }).set_index(\"Path\")\n",
    "    \n",
    "    if path in metadata.index:\n",
    "        metadata = remove_results(path)\n",
    "\n",
    "    metadata.loc[path] = {\"Name\": name, \"Description\": description, \"Dataset type\": dataset_type, \"Groud Truth\": truth, \"Group\": group, \"Task\": task, \"Lenguage\": lenguage}\n",
    "    results = pd.DataFrame({\"id\": index, \"y_pred\": y_pred}).set_index(\"id\") \n",
    "    \n",
    "    results.to_pickle(path)\n",
    "    metadata.to_pickle(metadata_file)\n",
    "    \n",
    "    print(\"Results saved on: \" + path)\n",
    "\n",
    "def remove_results(path=None):\n",
    "    if os.path.exists(metadata_file):\n",
    "        metadata = pd.read_pickle(metadata_file)\n",
    "        if path is not None:\n",
    "            if os.path.exists(path):\n",
    "                metadata = metadata.drop(path)\n",
    "                os.remove(path)\n",
    "                metadata.to_pickle(metadata_file)\n",
    "        else:\n",
    "            if os.path.exists(metadata_file):\n",
    "                used_files = [os.path.normpath(f) for f in metadata.index]\n",
    "                all_files = set([os.path.normpath(os.path.join(dp, f)) for dp, dn, filenames in os.walk('./results') for f in filenames][1:])\n",
    "                for f in used_files:\n",
    "                    if f not in all_files:\n",
    "                        os.remove(f)\n",
    "        return metadata\n",
    "\n",
    "    \n",
    "def load_results():\n",
    "    if os.path.exists(metadata_file):\n",
    "        metadata = pd.read_pickle(metadata_file)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    metadata[\"Results\"] = [pd.read_pickle(path) for path in metadata.index]\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "db9533f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "\n",
    "def print_score(y_true, y_pred, name):\n",
    "    classification_report_results = classification_report(y_true, y_pred)\n",
    "    \n",
    "    acc, f1 = accuracy_score(y_true, y_pred), f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "    print(name)\n",
    "    print('\\nAccuracy: ', acc)\n",
    "    print('F1 macro: ', f1)\n",
    "    print('\\nClassification Report')\n",
    "    print('======================================================')\n",
    "    print('\\n', classification_report_results)\n",
    "    \n",
    "    return {\"F1 macro\": f1, \"Accuracy\": acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b99202c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Dataset type</th>\n",
       "      <th>Groud Truth</th>\n",
       "      <th>Group</th>\n",
       "      <th>Task</th>\n",
       "      <th>Lenguage</th>\n",
       "      <th>Results</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Path</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>./results/hateval2019/task1/english/train/train_truth_task1.pkl</th>\n",
       "      <td>English Train</td>\n",
       "      <td>None</td>\n",
       "      <td>dataset_types.train</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>hateval2019/task1</td>\n",
       "      <td>english</td>\n",
       "      <td>y_pred\n",
       "id          \n",
       "201        1\n",
       "202    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./results/hateval2019/task1/english/development/dev_truth_task1.pkl</th>\n",
       "      <td>English Development</td>\n",
       "      <td>None</td>\n",
       "      <td>dataset_types.development</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>hateval2019/task1</td>\n",
       "      <td>english</td>\n",
       "      <td>y_pred\n",
       "id           \n",
       "18201       0\n",
       "1820...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./results/hateval2019/task1/english/test/test_truth_task1.pkl</th>\n",
       "      <td>English Test</td>\n",
       "      <td>None</td>\n",
       "      <td>dataset_types.test</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>hateval2019/task1</td>\n",
       "      <td>english</td>\n",
       "      <td>y_pred\n",
       "id           \n",
       "34243       0\n",
       "3059...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   Name  \\\n",
       "Path                                                                      \n",
       "./results/hateval2019/task1/english/train/train...        English Train   \n",
       "./results/hateval2019/task1/english/development...  English Development   \n",
       "./results/hateval2019/task1/english/test/test_t...         English Test   \n",
       "\n",
       "                                                   Description  \\\n",
       "Path                                                             \n",
       "./results/hateval2019/task1/english/train/train...        None   \n",
       "./results/hateval2019/task1/english/development...        None   \n",
       "./results/hateval2019/task1/english/test/test_t...        None   \n",
       "\n",
       "                                                                 Dataset type  \\\n",
       "Path                                                                            \n",
       "./results/hateval2019/task1/english/train/train...        dataset_types.train   \n",
       "./results/hateval2019/task1/english/development...  dataset_types.development   \n",
       "./results/hateval2019/task1/english/test/test_t...         dataset_types.test   \n",
       "\n",
       "                                                    Groud Truth Group  \\\n",
       "Path                                                                    \n",
       "./results/hateval2019/task1/english/train/train...         True  None   \n",
       "./results/hateval2019/task1/english/development...         True  None   \n",
       "./results/hateval2019/task1/english/test/test_t...         True  None   \n",
       "\n",
       "                                                                 Task  \\\n",
       "Path                                                                    \n",
       "./results/hateval2019/task1/english/train/train...  hateval2019/task1   \n",
       "./results/hateval2019/task1/english/development...  hateval2019/task1   \n",
       "./results/hateval2019/task1/english/test/test_t...  hateval2019/task1   \n",
       "\n",
       "                                                   Lenguage  \\\n",
       "Path                                                          \n",
       "./results/hateval2019/task1/english/train/train...  english   \n",
       "./results/hateval2019/task1/english/development...  english   \n",
       "./results/hateval2019/task1/english/test/test_t...  english   \n",
       "\n",
       "                                                                                              Results  \n",
       "Path                                                                                                   \n",
       "./results/hateval2019/task1/english/train/train...        y_pred\n",
       "id          \n",
       "201        1\n",
       "202    ...  \n",
       "./results/hateval2019/task1/english/development...         y_pred\n",
       "id           \n",
       "18201       0\n",
       "1820...  \n",
       "./results/hateval2019/task1/english/test/test_t...         y_pred\n",
       "id           \n",
       "34243       0\n",
       "3059...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = load_results()\n",
    "\n",
    "mask = df_results[\"Groud Truth\"] == True\n",
    "\n",
    "df_truth = df_results[mask]\n",
    "df_pred = df_results[~mask]\n",
    "\n",
    "df_truth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e84221ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Classifier\n",
      "\n",
      "Accuracy:  0.5796666666666667\n",
      "F1 macro:  0.3669550538088204\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      1.00      0.73      5217\n",
      "           1       0.00      0.00      0.00      3783\n",
      "\n",
      "    accuracy                           0.58      9000\n",
      "   macro avg       0.29      0.50      0.37      9000\n",
      "weighted avg       0.34      0.58      0.43      9000\n",
      "\n",
      "Multinomial Naive Bayes classifier\n",
      "\n",
      "Accuracy:  0.8204444444444444\n",
      "F1 macro:  0.8126298508371801\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.88      0.85      5217\n",
      "           1       0.82      0.73      0.77      3783\n",
      "\n",
      "    accuracy                           0.82      9000\n",
      "   macro avg       0.82      0.81      0.81      9000\n",
      "weighted avg       0.82      0.82      0.82      9000\n",
      "\n",
      "Best Multinomial Naive Bayes classifier\n",
      "\n",
      "Accuracy:  0.8162222222222222\n",
      "F1 macro:  0.8071309065220538\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.89      0.85      5217\n",
      "           1       0.83      0.71      0.77      3783\n",
      "\n",
      "    accuracy                           0.82      9000\n",
      "   macro avg       0.82      0.80      0.81      9000\n",
      "weighted avg       0.82      0.82      0.81      9000\n",
      "\n",
      "Bernoulli Naive Bayes classifier\n",
      "\n",
      "Accuracy:  0.826\n",
      "F1 macro:  0.8210285714285713\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.85      5217\n",
      "           1       0.80      0.78      0.79      3783\n",
      "\n",
      "    accuracy                           0.83      9000\n",
      "   macro avg       0.82      0.82      0.82      9000\n",
      "weighted avg       0.83      0.83      0.83      9000\n",
      "\n",
      "Best Bernoulli Naive Bayes classifier\n",
      "\n",
      "Accuracy:  0.8208888888888889\n",
      "F1 macro:  0.8151335065345999\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.86      0.85      5217\n",
      "           1       0.80      0.77      0.78      3783\n",
      "\n",
      "    accuracy                           0.82      9000\n",
      "   macro avg       0.82      0.81      0.82      9000\n",
      "weighted avg       0.82      0.82      0.82      9000\n",
      "\n",
      "Ridge Classifier\n",
      "\n",
      "Accuracy:  0.8816666666666667\n",
      "F1 macro:  0.8774313461768318\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90      5217\n",
      "           1       0.88      0.83      0.85      3783\n",
      "\n",
      "    accuracy                           0.88      9000\n",
      "   macro avg       0.88      0.87      0.88      9000\n",
      "weighted avg       0.88      0.88      0.88      9000\n",
      "\n",
      "Best Ridge Classifier\n",
      "\n",
      "Accuracy:  0.8356666666666667\n",
      "F1 macro:  0.8271567865321129\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.91      0.87      5217\n",
      "           1       0.86      0.73      0.79      3783\n",
      "\n",
      "    accuracy                           0.84      9000\n",
      "   macro avg       0.84      0.82      0.83      9000\n",
      "weighted avg       0.84      0.84      0.83      9000\n",
      "\n",
      "Random Forest classifier\n",
      "\n",
      "Accuracy:  0.999\n",
      "F1 macro:  0.9989737648560049\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5217\n",
      "           1       1.00      1.00      1.00      3783\n",
      "\n",
      "    accuracy                           1.00      9000\n",
      "   macro avg       1.00      1.00      1.00      9000\n",
      "weighted avg       1.00      1.00      1.00      9000\n",
      "\n",
      "Best Random Forest classifier\n",
      "\n",
      "Accuracy:  0.9966666666666667\n",
      "F1 macro:  0.9965763219746517\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      5217\n",
      "           1       1.00      0.99      1.00      3783\n",
      "\n",
      "    accuracy                           1.00      9000\n",
      "   macro avg       1.00      1.00      1.00      9000\n",
      "weighted avg       1.00      1.00      1.00      9000\n",
      "\n",
      "Support Vector Classification\n",
      "\n",
      "Accuracy:  0.9575555555555556\n",
      "F1 macro:  0.9563093471055895\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      5217\n",
      "           1       0.96      0.94      0.95      3783\n",
      "\n",
      "    accuracy                           0.96      9000\n",
      "   macro avg       0.96      0.95      0.96      9000\n",
      "weighted avg       0.96      0.96      0.96      9000\n",
      "\n",
      "Best Support Vector Classification\n",
      "\n",
      "Accuracy:  0.8206666666666667\n",
      "F1 macro:  0.8078546622506662\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.93      0.86      5217\n",
      "           1       0.87      0.67      0.76      3783\n",
      "\n",
      "    accuracy                           0.82      9000\n",
      "   macro avg       0.83      0.80      0.81      9000\n",
      "weighted avg       0.83      0.82      0.82      9000\n",
      "\n",
      "AdaBoost classifier\n",
      "\n",
      "Accuracy:  0.7816666666666666\n",
      "F1 macro:  0.7679385989020957\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.88      0.82      5217\n",
      "           1       0.80      0.64      0.71      3783\n",
      "\n",
      "    accuracy                           0.78      9000\n",
      "   macro avg       0.79      0.76      0.77      9000\n",
      "weighted avg       0.78      0.78      0.78      9000\n",
      "\n",
      "Best AdaBoost classifier\n",
      "\n",
      "Accuracy:  0.824\n",
      "F1 macro:  0.8148955676525538\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.90      0.86      5217\n",
      "           1       0.84      0.72      0.77      3783\n",
      "\n",
      "    accuracy                           0.82      9000\n",
      "   macro avg       0.83      0.81      0.81      9000\n",
      "weighted avg       0.83      0.82      0.82      9000\n",
      "\n",
      "Multi-layer Perceptron classifier\n",
      "\n",
      "Accuracy:  0.8914444444444445\n",
      "F1 macro:  0.8880149007808582\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91      5217\n",
      "           1       0.89      0.85      0.87      3783\n",
      "\n",
      "    accuracy                           0.89      9000\n",
      "   macro avg       0.89      0.89      0.89      9000\n",
      "weighted avg       0.89      0.89      0.89      9000\n",
      "\n",
      "Best Multi-layer Perceptron classifier\n",
      "\n",
      "Accuracy:  0.8217777777777778\n",
      "F1 macro:  0.8173712296381446\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.84      0.85      5217\n",
      "           1       0.79      0.79      0.79      3783\n",
      "\n",
      "    accuracy                           0.82      9000\n",
      "   macro avg       0.82      0.82      0.82      9000\n",
      "weighted avg       0.82      0.82      0.82      9000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Classifier\n",
      "\n",
      "Accuracy:  0.573\n",
      "F1 macro:  0.3642720915448188\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      1.00      0.73       573\n",
      "           1       0.00      0.00      0.00       427\n",
      "\n",
      "    accuracy                           0.57      1000\n",
      "   macro avg       0.29      0.50      0.36      1000\n",
      "weighted avg       0.33      0.57      0.42      1000\n",
      "\n",
      "Multinomial Naive Bayes classifier\n",
      "\n",
      "Accuracy:  0.738\n",
      "F1 macro:  0.7302028627329833\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.79      0.78       573\n",
      "           1       0.70      0.67      0.68       427\n",
      "\n",
      "    accuracy                           0.74      1000\n",
      "   macro avg       0.73      0.73      0.73      1000\n",
      "weighted avg       0.74      0.74      0.74      1000\n",
      "\n",
      "Best Multinomial Naive Bayes classifier\n",
      "\n",
      "Accuracy:  0.742\n",
      "F1 macro:  0.7329590620031796\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.81      0.78       573\n",
      "           1       0.72      0.65      0.68       427\n",
      "\n",
      "    accuracy                           0.74      1000\n",
      "   macro avg       0.74      0.73      0.73      1000\n",
      "weighted avg       0.74      0.74      0.74      1000\n",
      "\n",
      "Bernoulli Naive Bayes classifier\n",
      "\n",
      "Accuracy:  0.738\n",
      "F1 macro:  0.734550214588796\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.74      0.76       573\n",
      "           1       0.68      0.73      0.70       427\n",
      "\n",
      "    accuracy                           0.74      1000\n",
      "   macro avg       0.73      0.74      0.73      1000\n",
      "weighted avg       0.74      0.74      0.74      1000\n",
      "\n",
      "Best Bernoulli Naive Bayes classifier\n",
      "\n",
      "Accuracy:  0.738\n",
      "F1 macro:  0.7344264422063284\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.75      0.77       573\n",
      "           1       0.68      0.73      0.70       427\n",
      "\n",
      "    accuracy                           0.74      1000\n",
      "   macro avg       0.73      0.74      0.73      1000\n",
      "weighted avg       0.74      0.74      0.74      1000\n",
      "\n",
      "Ridge Classifier\n",
      "\n",
      "Accuracy:  0.717\n",
      "F1 macro:  0.7098480444475885\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.76      0.76       573\n",
      "           1       0.67      0.66      0.66       427\n",
      "\n",
      "    accuracy                           0.72      1000\n",
      "   macro avg       0.71      0.71      0.71      1000\n",
      "weighted avg       0.72      0.72      0.72      1000\n",
      "\n",
      "Best Ridge Classifier\n",
      "\n",
      "Accuracy:  0.744\n",
      "F1 macro:  0.7335542612583733\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.79       573\n",
      "           1       0.73      0.64      0.68       427\n",
      "\n",
      "    accuracy                           0.74      1000\n",
      "   macro avg       0.74      0.73      0.73      1000\n",
      "weighted avg       0.74      0.74      0.74      1000\n",
      "\n",
      "Random Forest classifier\n",
      "\n",
      "Accuracy:  0.74\n",
      "F1 macro:  0.7314926119159448\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.80      0.78       573\n",
      "           1       0.71      0.66      0.68       427\n",
      "\n",
      "    accuracy                           0.74      1000\n",
      "   macro avg       0.74      0.73      0.73      1000\n",
      "weighted avg       0.74      0.74      0.74      1000\n",
      "\n",
      "Best Random Forest classifier\n",
      "\n",
      "Accuracy:  0.758\n",
      "F1 macro:  0.7506224134804043\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.79       573\n",
      "           1       0.73      0.69      0.71       427\n",
      "\n",
      "    accuracy                           0.76      1000\n",
      "   macro avg       0.75      0.75      0.75      1000\n",
      "weighted avg       0.76      0.76      0.76      1000\n",
      "\n",
      "Support Vector Classification\n",
      "\n",
      "Accuracy:  0.745\n",
      "F1 macro:  0.7344853545245258\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.79       573\n",
      "           1       0.73      0.64      0.68       427\n",
      "\n",
      "    accuracy                           0.74      1000\n",
      "   macro avg       0.74      0.73      0.73      1000\n",
      "weighted avg       0.74      0.74      0.74      1000\n",
      "\n",
      "Best Support Vector Classification\n",
      "\n",
      "Accuracy:  0.728\n",
      "F1 macro:  0.7069521297684922\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.87      0.79       573\n",
      "           1       0.75      0.54      0.63       427\n",
      "\n",
      "    accuracy                           0.73      1000\n",
      "   macro avg       0.74      0.70      0.71      1000\n",
      "weighted avg       0.73      0.73      0.72      1000\n",
      "\n",
      "AdaBoost classifier\n",
      "\n",
      "Accuracy:  0.739\n",
      "F1 macro:  0.7258515670051333\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.84      0.79       573\n",
      "           1       0.73      0.61      0.67       427\n",
      "\n",
      "    accuracy                           0.74      1000\n",
      "   macro avg       0.74      0.72      0.73      1000\n",
      "weighted avg       0.74      0.74      0.73      1000\n",
      "\n",
      "Best AdaBoost classifier\n",
      "\n",
      "Accuracy:  0.716\n",
      "F1 macro:  0.7046539875871478\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.80      0.76       573\n",
      "           1       0.69      0.61      0.65       427\n",
      "\n",
      "    accuracy                           0.72      1000\n",
      "   macro avg       0.71      0.70      0.70      1000\n",
      "weighted avg       0.71      0.72      0.71      1000\n",
      "\n",
      "Multi-layer Perceptron classifier\n",
      "\n",
      "Accuracy:  0.7\n",
      "F1 macro:  0.6930946291560103\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.74      0.74       573\n",
      "           1       0.65      0.64      0.65       427\n",
      "\n",
      "    accuracy                           0.70      1000\n",
      "   macro avg       0.69      0.69      0.69      1000\n",
      "weighted avg       0.70      0.70      0.70      1000\n",
      "\n",
      "Best Multi-layer Perceptron classifier\n",
      "\n",
      "Accuracy:  0.736\n",
      "F1 macro:  0.7323991631392012\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.76       573\n",
      "           1       0.68      0.73      0.70       427\n",
      "\n",
      "    accuracy                           0.74      1000\n",
      "   macro avg       0.73      0.73      0.73      1000\n",
      "weighted avg       0.74      0.74      0.74      1000\n",
      "\n",
      "Dummy Classifier\n",
      "\n",
      "Accuracy:  0.58\n",
      "F1 macro:  0.36708860759493667\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      1.00      0.73      1740\n",
      "           1       0.00      0.00      0.00      1260\n",
      "\n",
      "    accuracy                           0.58      3000\n",
      "   macro avg       0.29      0.50      0.37      3000\n",
      "weighted avg       0.34      0.58      0.43      3000\n",
      "\n",
      "Multinomial Naive Bayes classifier\n",
      "\n",
      "Accuracy:  0.5056666666666667\n",
      "F1 macro:  0.4784764572972561\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.24      0.36      1740\n",
      "           1       0.45      0.87      0.60      1260\n",
      "\n",
      "    accuracy                           0.51      3000\n",
      "   macro avg       0.59      0.56      0.48      3000\n",
      "weighted avg       0.61      0.51      0.46      3000\n",
      "\n",
      "Best Multinomial Naive Bayes classifier\n",
      "\n",
      "Accuracy:  0.509\n",
      "F1 macro:  0.48378767377483683\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.25      0.37      1740\n",
      "           1       0.46      0.87      0.60      1260\n",
      "\n",
      "    accuracy                           0.51      3000\n",
      "   macro avg       0.59      0.56      0.48      3000\n",
      "weighted avg       0.61      0.51      0.47      3000\n",
      "\n",
      "Bernoulli Naive Bayes classifier\n",
      "\n",
      "Accuracy:  0.4726666666666667\n",
      "F1 macro:  0.4181881304494295\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.14      0.24      1740\n",
      "           1       0.44      0.93      0.60      1260\n",
      "\n",
      "    accuracy                           0.47      3000\n",
      "   macro avg       0.59      0.54      0.42      3000\n",
      "weighted avg       0.61      0.47      0.39      3000\n",
      "\n",
      "Best Bernoulli Naive Bayes classifier\n",
      "\n",
      "Accuracy:  0.47933333333333333\n",
      "F1 macro:  0.4290866116789922\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.16      0.26      1740\n",
      "           1       0.44      0.92      0.60      1260\n",
      "\n",
      "    accuracy                           0.48      3000\n",
      "   macro avg       0.59      0.54      0.43      3000\n",
      "weighted avg       0.62      0.48      0.40      3000\n",
      "\n",
      "Ridge Classifier\n",
      "\n",
      "Accuracy:  0.5136666666666667\n",
      "F1 macro:  0.4877331577792407\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.25      0.37      1740\n",
      "           1       0.46      0.88      0.60      1260\n",
      "\n",
      "    accuracy                           0.51      3000\n",
      "   macro avg       0.60      0.56      0.49      3000\n",
      "weighted avg       0.62      0.51      0.47      3000\n",
      "\n",
      "Best Ridge Classifier\n",
      "\n",
      "Accuracy:  0.5076666666666667\n",
      "F1 macro:  0.4802516140527483\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.24      0.36      1740\n",
      "           1       0.46      0.88      0.60      1260\n",
      "\n",
      "    accuracy                           0.51      3000\n",
      "   macro avg       0.59      0.56      0.48      3000\n",
      "weighted avg       0.61      0.51      0.46      3000\n",
      "\n",
      "Random Forest classifier\n",
      "\n",
      "Accuracy:  0.451\n",
      "F1 macro:  0.39359880393776636\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.12      0.21      1740\n",
      "           1       0.43      0.90      0.58      1260\n",
      "\n",
      "    accuracy                           0.45      3000\n",
      "   macro avg       0.53      0.51      0.39      3000\n",
      "weighted avg       0.55      0.45      0.36      3000\n",
      "\n",
      "Best Random Forest classifier\n",
      "\n",
      "Accuracy:  0.4513333333333333\n",
      "F1 macro:  0.39131991130872873\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.12      0.20      1740\n",
      "           1       0.43      0.91      0.58      1260\n",
      "\n",
      "    accuracy                           0.45      3000\n",
      "   macro avg       0.54      0.51      0.39      3000\n",
      "weighted avg       0.56      0.45      0.36      3000\n",
      "\n",
      "Support Vector Classification\n",
      "\n",
      "Accuracy:  0.48633333333333334\n",
      "F1 macro:  0.44732629900735116\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.19      0.30      1740\n",
      "           1       0.44      0.90      0.59      1260\n",
      "\n",
      "    accuracy                           0.49      3000\n",
      "   macro avg       0.58      0.54      0.45      3000\n",
      "weighted avg       0.60      0.49      0.42      3000\n",
      "\n",
      "Best Support Vector Classification\n",
      "\n",
      "Accuracy:  0.47533333333333333\n",
      "F1 macro:  0.4456682057728456\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.21      0.32      1740\n",
      "           1       0.44      0.84      0.57      1260\n",
      "\n",
      "    accuracy                           0.48      3000\n",
      "   macro avg       0.54      0.53      0.45      3000\n",
      "weighted avg       0.56      0.48      0.43      3000\n",
      "\n",
      "AdaBoost classifier\n",
      "\n",
      "Accuracy:  0.46366666666666667\n",
      "F1 macro:  0.41955762522951046\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.16      0.26      1740\n",
      "           1       0.43      0.88      0.58      1260\n",
      "\n",
      "    accuracy                           0.46      3000\n",
      "   macro avg       0.54      0.52      0.42      3000\n",
      "weighted avg       0.56      0.46      0.39      3000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best AdaBoost classifier\n",
      "\n",
      "Accuracy:  0.48533333333333334\n",
      "F1 macro:  0.4428953278257908\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.18      0.29      1740\n",
      "           1       0.44      0.91      0.60      1260\n",
      "\n",
      "    accuracy                           0.49      3000\n",
      "   macro avg       0.59      0.54      0.44      3000\n",
      "weighted avg       0.61      0.49      0.42      3000\n",
      "\n",
      "Multi-layer Perceptron classifier\n",
      "\n",
      "Accuracy:  0.5113333333333333\n",
      "F1 macro:  0.4837036783119388\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.24      0.36      1740\n",
      "           1       0.46      0.88      0.60      1260\n",
      "\n",
      "    accuracy                           0.51      3000\n",
      "   macro avg       0.60      0.56      0.48      3000\n",
      "weighted avg       0.62      0.51      0.46      3000\n",
      "\n",
      "Best Multi-layer Perceptron classifier\n",
      "\n",
      "Accuracy:  0.518\n",
      "F1 macro:  0.4883659271050003\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.24      0.37      1740\n",
      "           1       0.46      0.90      0.61      1260\n",
      "\n",
      "    accuracy                           0.52      3000\n",
      "   macro avg       0.62      0.57      0.49      3000\n",
      "weighted avg       0.64      0.52      0.47      3000\n",
      "\n",
      "Bert base\n",
      "\n",
      "Accuracy:  0.9315555555555556\n",
      "F1 macro:  0.9299943995519642\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94      5217\n",
      "           1       0.91      0.93      0.92      3783\n",
      "\n",
      "    accuracy                           0.93      9000\n",
      "   macro avg       0.93      0.93      0.93      9000\n",
      "weighted avg       0.93      0.93      0.93      9000\n",
      "\n",
      "Bert base\n",
      "\n",
      "Accuracy:  0.749\n",
      "F1 macro:  0.7469041129594169\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.73      0.77       573\n",
      "           1       0.68      0.77      0.72       427\n",
      "\n",
      "    accuracy                           0.75      1000\n",
      "   macro avg       0.75      0.75      0.75      1000\n",
      "weighted avg       0.76      0.75      0.75      1000\n",
      "\n",
      "Bert base\n",
      "\n",
      "Accuracy:  0.6053333333333333\n",
      "F1 macro:  0.5941497231031642\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.38      0.53      1740\n",
      "           1       0.52      0.92      0.66      1260\n",
      "\n",
      "    accuracy                           0.61      3000\n",
      "   macro avg       0.69      0.65      0.59      3000\n",
      "weighted avg       0.72      0.61      0.58      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = {dataset_type: [] for dataset_type in dataset_types}\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for path, (name, desc, dataset_type, truth, group, task, lenguage, y_pred) in df_pred.iterrows():\n",
    "    y_true = df_truth[(df_truth[\"Dataset type\"] == dataset_type) & (df_truth[\"Task\"] == task) & (df_truth[\"Lenguage\"] == lenguage)][\"Results\"][0]\n",
    "    \n",
    "    result = print_score(y_true, y_pred, name)\n",
    "    result_copy = result.copy()\n",
    "    result_copy.update({\"Dataset type\": dataset_type, \"Name\": name})\n",
    "    \n",
    "    all_results.append(result_copy)\n",
    "    results[dataset_type].append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d9d6eb21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "                                         F1 macro  Accuracy\n",
      "Name                                                       \n",
      "Dummy Classifier                         0.366955  0.579667\n",
      "Multinomial Naive Bayes classifier       0.812630  0.820444\n",
      "Best Multinomial Naive Bayes classifier  0.807131  0.816222\n",
      "Bernoulli Naive Bayes classifier         0.821029  0.826000\n",
      "Best Bernoulli Naive Bayes classifier    0.815134  0.820889\n",
      "Ridge Classifier                         0.877431  0.881667\n",
      "Best Ridge Classifier                    0.827157  0.835667\n",
      "Random Forest classifier                 0.998974  0.999000\n",
      "Best Random Forest classifier            0.996576  0.996667\n",
      "Support Vector Classification            0.956309  0.957556\n",
      "Best Support Vector Classification       0.807855  0.820667\n",
      "AdaBoost classifier                      0.767939  0.781667\n",
      "Best AdaBoost classifier                 0.814896  0.824000\n",
      "Multi-layer Perceptron classifier        0.888015  0.891444\n",
      "Best Multi-layer Perceptron classifier   0.817371  0.821778\n",
      "Bert base                                0.929994  0.931556 \n",
      "\n",
      "development\n",
      "                                         F1 macro  Accuracy\n",
      "Name                                                       \n",
      "Dummy Classifier                         0.364272     0.573\n",
      "Multinomial Naive Bayes classifier       0.730203     0.738\n",
      "Best Multinomial Naive Bayes classifier  0.732959     0.742\n",
      "Bernoulli Naive Bayes classifier         0.734550     0.738\n",
      "Best Bernoulli Naive Bayes classifier    0.734426     0.738\n",
      "Ridge Classifier                         0.709848     0.717\n",
      "Best Ridge Classifier                    0.733554     0.744\n",
      "Random Forest classifier                 0.731493     0.740\n",
      "Best Random Forest classifier            0.750622     0.758\n",
      "Support Vector Classification            0.734485     0.745\n",
      "Best Support Vector Classification       0.706952     0.728\n",
      "AdaBoost classifier                      0.725852     0.739\n",
      "Best AdaBoost classifier                 0.704654     0.716\n",
      "Multi-layer Perceptron classifier        0.693095     0.700\n",
      "Best Multi-layer Perceptron classifier   0.732399     0.736\n",
      "Bert base                                0.746904     0.749 \n",
      "\n",
      "test\n",
      "                                         F1 macro  Accuracy\n",
      "Name                                                       \n",
      "Dummy Classifier                         0.367089  0.580000\n",
      "Multinomial Naive Bayes classifier       0.478476  0.505667\n",
      "Best Multinomial Naive Bayes classifier  0.483788  0.509000\n",
      "Bernoulli Naive Bayes classifier         0.418188  0.472667\n",
      "Best Bernoulli Naive Bayes classifier    0.429087  0.479333\n",
      "Ridge Classifier                         0.487733  0.513667\n",
      "Best Ridge Classifier                    0.480252  0.507667\n",
      "Random Forest classifier                 0.393599  0.451000\n",
      "Best Random Forest classifier            0.391320  0.451333\n",
      "Support Vector Classification            0.447326  0.486333\n",
      "Best Support Vector Classification       0.445668  0.475333\n",
      "AdaBoost classifier                      0.419558  0.463667\n",
      "Best AdaBoost classifier                 0.442895  0.485333\n",
      "Multi-layer Perceptron classifier        0.483704  0.511333\n",
      "Best Multi-layer Perceptron classifier   0.488366  0.518000\n",
      "Bert base                                0.594150  0.605333 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset_type, scores in results.items():\n",
    "    print(dataset_type.name)\n",
    "    print(pd.DataFrame(scores, index=df_pred[df_pred[\"Dataset type\"] == dataset_type][\"Name\"]), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "9932558d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>F1 macro</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset type</th>\n",
       "      <th>Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">dataset_types.train</th>\n",
       "      <th>Random Forest classifier</th>\n",
       "      <td>0.998974</td>\n",
       "      <td>0.999000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best Random Forest classifier</th>\n",
       "      <td>0.996576</td>\n",
       "      <td>0.996667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Classification</th>\n",
       "      <td>0.956309</td>\n",
       "      <td>0.957556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bert base</th>\n",
       "      <td>0.929994</td>\n",
       "      <td>0.931556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multi-layer Perceptron classifier</th>\n",
       "      <td>0.888015</td>\n",
       "      <td>0.891444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Classifier</th>\n",
       "      <td>0.877431</td>\n",
       "      <td>0.881667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best Ridge Classifier</th>\n",
       "      <td>0.827157</td>\n",
       "      <td>0.835667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bernoulli Naive Bayes classifier</th>\n",
       "      <td>0.821029</td>\n",
       "      <td>0.826000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best Multi-layer Perceptron classifier</th>\n",
       "      <td>0.817371</td>\n",
       "      <td>0.821778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best Bernoulli Naive Bayes classifier</th>\n",
       "      <td>0.815134</td>\n",
       "      <td>0.820889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best AdaBoost classifier</th>\n",
       "      <td>0.814896</td>\n",
       "      <td>0.824000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial Naive Bayes classifier</th>\n",
       "      <td>0.812630</td>\n",
       "      <td>0.820444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best Support Vector Classification</th>\n",
       "      <td>0.807855</td>\n",
       "      <td>0.820667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best Multinomial Naive Bayes classifier</th>\n",
       "      <td>0.807131</td>\n",
       "      <td>0.816222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost classifier</th>\n",
       "      <td>0.767939</td>\n",
       "      <td>0.781667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">dataset_types.development</th>\n",
       "      <th>Best Random Forest classifier</th>\n",
       "      <td>0.750622</td>\n",
       "      <td>0.758000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bert base</th>\n",
       "      <td>0.746904</td>\n",
       "      <td>0.749000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bernoulli Naive Bayes classifier</th>\n",
       "      <td>0.734550</td>\n",
       "      <td>0.738000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Classification</th>\n",
       "      <td>0.734485</td>\n",
       "      <td>0.745000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best Bernoulli Naive Bayes classifier</th>\n",
       "      <td>0.734426</td>\n",
       "      <td>0.738000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best Ridge Classifier</th>\n",
       "      <td>0.733554</td>\n",
       "      <td>0.744000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best Multinomial Naive Bayes classifier</th>\n",
       "      <td>0.732959</td>\n",
       "      <td>0.742000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best Multi-layer Perceptron classifier</th>\n",
       "      <td>0.732399</td>\n",
       "      <td>0.736000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest classifier</th>\n",
       "      <td>0.731493</td>\n",
       "      <td>0.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial Naive Bayes classifier</th>\n",
       "      <td>0.730203</td>\n",
       "      <td>0.738000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost classifier</th>\n",
       "      <td>0.725852</td>\n",
       "      <td>0.739000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Classifier</th>\n",
       "      <td>0.709848</td>\n",
       "      <td>0.717000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best Support Vector Classification</th>\n",
       "      <td>0.706952</td>\n",
       "      <td>0.728000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best AdaBoost classifier</th>\n",
       "      <td>0.704654</td>\n",
       "      <td>0.716000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multi-layer Perceptron classifier</th>\n",
       "      <td>0.693095</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"16\" valign=\"top\">dataset_types.test</th>\n",
       "      <th>Bert base</th>\n",
       "      <td>0.594150</td>\n",
       "      <td>0.605333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best Multi-layer Perceptron classifier</th>\n",
       "      <td>0.488366</td>\n",
       "      <td>0.518000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Classifier</th>\n",
       "      <td>0.487733</td>\n",
       "      <td>0.513667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best Multinomial Naive Bayes classifier</th>\n",
       "      <td>0.483788</td>\n",
       "      <td>0.509000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multi-layer Perceptron classifier</th>\n",
       "      <td>0.483704</td>\n",
       "      <td>0.511333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best Ridge Classifier</th>\n",
       "      <td>0.480252</td>\n",
       "      <td>0.507667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial Naive Bayes classifier</th>\n",
       "      <td>0.478476</td>\n",
       "      <td>0.505667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Classification</th>\n",
       "      <td>0.447326</td>\n",
       "      <td>0.486333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best Support Vector Classification</th>\n",
       "      <td>0.445668</td>\n",
       "      <td>0.475333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best AdaBoost classifier</th>\n",
       "      <td>0.442895</td>\n",
       "      <td>0.485333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best Bernoulli Naive Bayes classifier</th>\n",
       "      <td>0.429087</td>\n",
       "      <td>0.479333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost classifier</th>\n",
       "      <td>0.419558</td>\n",
       "      <td>0.463667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bernoulli Naive Bayes classifier</th>\n",
       "      <td>0.418188</td>\n",
       "      <td>0.472667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest classifier</th>\n",
       "      <td>0.393599</td>\n",
       "      <td>0.451000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best Random Forest classifier</th>\n",
       "      <td>0.391320</td>\n",
       "      <td>0.451333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dummy Classifier</th>\n",
       "      <td>0.367089</td>\n",
       "      <td>0.580000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_types.train</th>\n",
       "      <th>Dummy Classifier</th>\n",
       "      <td>0.366955</td>\n",
       "      <td>0.579667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_types.development</th>\n",
       "      <th>Dummy Classifier</th>\n",
       "      <td>0.364272</td>\n",
       "      <td>0.573000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   F1 macro  \\\n",
       "Dataset type              Name                                                \n",
       "dataset_types.train       Random Forest classifier                 0.998974   \n",
       "                          Best Random Forest classifier            0.996576   \n",
       "                          Support Vector Classification            0.956309   \n",
       "                          Bert base                                0.929994   \n",
       "                          Multi-layer Perceptron classifier        0.888015   \n",
       "                          Ridge Classifier                         0.877431   \n",
       "                          Best Ridge Classifier                    0.827157   \n",
       "                          Bernoulli Naive Bayes classifier         0.821029   \n",
       "                          Best Multi-layer Perceptron classifier   0.817371   \n",
       "                          Best Bernoulli Naive Bayes classifier    0.815134   \n",
       "                          Best AdaBoost classifier                 0.814896   \n",
       "                          Multinomial Naive Bayes classifier       0.812630   \n",
       "                          Best Support Vector Classification       0.807855   \n",
       "                          Best Multinomial Naive Bayes classifier  0.807131   \n",
       "                          AdaBoost classifier                      0.767939   \n",
       "dataset_types.development Best Random Forest classifier            0.750622   \n",
       "                          Bert base                                0.746904   \n",
       "                          Bernoulli Naive Bayes classifier         0.734550   \n",
       "                          Support Vector Classification            0.734485   \n",
       "                          Best Bernoulli Naive Bayes classifier    0.734426   \n",
       "                          Best Ridge Classifier                    0.733554   \n",
       "                          Best Multinomial Naive Bayes classifier  0.732959   \n",
       "                          Best Multi-layer Perceptron classifier   0.732399   \n",
       "                          Random Forest classifier                 0.731493   \n",
       "                          Multinomial Naive Bayes classifier       0.730203   \n",
       "                          AdaBoost classifier                      0.725852   \n",
       "                          Ridge Classifier                         0.709848   \n",
       "                          Best Support Vector Classification       0.706952   \n",
       "                          Best AdaBoost classifier                 0.704654   \n",
       "                          Multi-layer Perceptron classifier        0.693095   \n",
       "dataset_types.test        Bert base                                0.594150   \n",
       "                          Best Multi-layer Perceptron classifier   0.488366   \n",
       "                          Ridge Classifier                         0.487733   \n",
       "                          Best Multinomial Naive Bayes classifier  0.483788   \n",
       "                          Multi-layer Perceptron classifier        0.483704   \n",
       "                          Best Ridge Classifier                    0.480252   \n",
       "                          Multinomial Naive Bayes classifier       0.478476   \n",
       "                          Support Vector Classification            0.447326   \n",
       "                          Best Support Vector Classification       0.445668   \n",
       "                          Best AdaBoost classifier                 0.442895   \n",
       "                          Best Bernoulli Naive Bayes classifier    0.429087   \n",
       "                          AdaBoost classifier                      0.419558   \n",
       "                          Bernoulli Naive Bayes classifier         0.418188   \n",
       "                          Random Forest classifier                 0.393599   \n",
       "                          Best Random Forest classifier            0.391320   \n",
       "                          Dummy Classifier                         0.367089   \n",
       "dataset_types.train       Dummy Classifier                         0.366955   \n",
       "dataset_types.development Dummy Classifier                         0.364272   \n",
       "\n",
       "                                                                   Accuracy  \n",
       "Dataset type              Name                                               \n",
       "dataset_types.train       Random Forest classifier                 0.999000  \n",
       "                          Best Random Forest classifier            0.996667  \n",
       "                          Support Vector Classification            0.957556  \n",
       "                          Bert base                                0.931556  \n",
       "                          Multi-layer Perceptron classifier        0.891444  \n",
       "                          Ridge Classifier                         0.881667  \n",
       "                          Best Ridge Classifier                    0.835667  \n",
       "                          Bernoulli Naive Bayes classifier         0.826000  \n",
       "                          Best Multi-layer Perceptron classifier   0.821778  \n",
       "                          Best Bernoulli Naive Bayes classifier    0.820889  \n",
       "                          Best AdaBoost classifier                 0.824000  \n",
       "                          Multinomial Naive Bayes classifier       0.820444  \n",
       "                          Best Support Vector Classification       0.820667  \n",
       "                          Best Multinomial Naive Bayes classifier  0.816222  \n",
       "                          AdaBoost classifier                      0.781667  \n",
       "dataset_types.development Best Random Forest classifier            0.758000  \n",
       "                          Bert base                                0.749000  \n",
       "                          Bernoulli Naive Bayes classifier         0.738000  \n",
       "                          Support Vector Classification            0.745000  \n",
       "                          Best Bernoulli Naive Bayes classifier    0.738000  \n",
       "                          Best Ridge Classifier                    0.744000  \n",
       "                          Best Multinomial Naive Bayes classifier  0.742000  \n",
       "                          Best Multi-layer Perceptron classifier   0.736000  \n",
       "                          Random Forest classifier                 0.740000  \n",
       "                          Multinomial Naive Bayes classifier       0.738000  \n",
       "                          AdaBoost classifier                      0.739000  \n",
       "                          Ridge Classifier                         0.717000  \n",
       "                          Best Support Vector Classification       0.728000  \n",
       "                          Best AdaBoost classifier                 0.716000  \n",
       "                          Multi-layer Perceptron classifier        0.700000  \n",
       "dataset_types.test        Bert base                                0.605333  \n",
       "                          Best Multi-layer Perceptron classifier   0.518000  \n",
       "                          Ridge Classifier                         0.513667  \n",
       "                          Best Multinomial Naive Bayes classifier  0.509000  \n",
       "                          Multi-layer Perceptron classifier        0.511333  \n",
       "                          Best Ridge Classifier                    0.507667  \n",
       "                          Multinomial Naive Bayes classifier       0.505667  \n",
       "                          Support Vector Classification            0.486333  \n",
       "                          Best Support Vector Classification       0.475333  \n",
       "                          Best AdaBoost classifier                 0.485333  \n",
       "                          Best Bernoulli Naive Bayes classifier    0.479333  \n",
       "                          AdaBoost classifier                      0.463667  \n",
       "                          Bernoulli Naive Bayes classifier         0.472667  \n",
       "                          Random Forest classifier                 0.451000  \n",
       "                          Best Random Forest classifier            0.451333  \n",
       "                          Dummy Classifier                         0.580000  \n",
       "dataset_types.train       Dummy Classifier                         0.579667  \n",
       "dataset_types.development Dummy Classifier                         0.573000  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = pd.DataFrame(all_results).set_index([\"Name\", \"Dataset type\"]).groupby(level=[1,0]).sum()\n",
    "tmp.sort_values(by=[\"F1 macro\", \"Accuracy\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cba0474",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
