{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbb73364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from enum import Enum\n",
    "\n",
    "pd.set_option(\"display.precision\", 5)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79940e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_file = \"./results/metadata.pkl\"\n",
    "\n",
    "class dataset_types(Enum):\n",
    "    train = 1\n",
    "    development = 2\n",
    "    test = 3\n",
    "    \n",
    "    def title(self):\n",
    "        return self._shorten_names[self.value - 1]\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        return self.value < other.value\n",
    "dataset_types._shorten_names = [\"Train\", \"Dev\", \"Test\"]\n",
    "\n",
    "def save_results(y_pred, index, name, task, lenguage, dataset_type, group=None, description=None, truth=False, filename=None):\n",
    "    \n",
    "    path = f\"./results/{task}/{lenguage}/{dataset_type.name}{'/' + group if group is not None else ''}/{name if filename is None else filename}.pkl\"\n",
    "    \n",
    "    directory = \"/\".join(path.split(\"/\")[:-1])\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    if os.path.exists(metadata_file):\n",
    "        metadata = pd.read_pickle(metadata_file)\n",
    "    else:\n",
    "        metadata = pd.DataFrame({\n",
    "            \"Path\": pd.Series([], dtype=str),\n",
    "            \"Name\": pd.Series([], dtype=str),\n",
    "            \"Description\": pd.Series([], dtype=str),\n",
    "            \"Dataset type\": pd.Categorical([], categories=dataset_types, ordered=False),\n",
    "            \"Groud Truth\": pd.Series([], dtype=bool),\n",
    "            \"Group\": pd.Series([], dtype=str),\n",
    "            \"Task\": pd.Series([], dtype=str),\n",
    "            \"Lenguage\": pd.Series([], dtype=str),\n",
    "        }).set_index(\"Path\")\n",
    "    \n",
    "    if path in metadata.index:\n",
    "        metadata = remove_results(path)\n",
    "\n",
    "    metadata.loc[path] = {\"Name\": name, \"Description\": description, \"Dataset type\": dataset_type, \"Groud Truth\": truth, \"Group\": group, \"Task\": task, \"Lenguage\": lenguage}\n",
    "    results = pd.DataFrame({\"id\": index, \"y_pred\": y_pred}).set_index(\"id\") \n",
    "    \n",
    "    results.to_pickle(path)\n",
    "    metadata.to_pickle(metadata_file)\n",
    "    \n",
    "    print(\"Results saved on: \" + path)\n",
    "\n",
    "def remove_results(path=None):\n",
    "    if os.path.exists(metadata_file):\n",
    "        metadata = pd.read_pickle(metadata_file)\n",
    "        if path is not None:\n",
    "            if os.path.exists(path):\n",
    "                metadata = metadata.drop(path)\n",
    "                os.remove(path)\n",
    "                metadata.to_pickle(metadata_file)\n",
    "        else:\n",
    "            if os.path.exists(metadata_file):\n",
    "                used_files = [os.path.normpath(f) for f in metadata.index]\n",
    "                all_files = set([os.path.normpath(os.path.join(dp, f)) for dp, dn, filenames in os.walk('./results') for f in filenames][1:])\n",
    "                for f in used_files:\n",
    "                    if f not in all_files:\n",
    "                        os.remove(f)\n",
    "        return metadata\n",
    "\n",
    "    \n",
    "def load_results():\n",
    "    if os.path.exists(metadata_file):\n",
    "        metadata = pd.read_pickle(metadata_file)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    metadata[\"Results\"] = [pd.read_pickle(path) for path in metadata.index]\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe57568d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "\n",
    "def print_score(y_true, y_pred, name, f1_average):\n",
    "    classification_report_results = acc = f1 = None\n",
    "    if y_true is not None:\n",
    "        classification_report_results = classification_report(y_true, y_pred)\n",
    "\n",
    "        acc, f1 = accuracy_score(y_true, y_pred), f1_score(y_true, y_pred, average=f1_average)   \n",
    "\n",
    "    print(name)\n",
    "    print('F1 macro: ', f1)\n",
    "    print('Accuracy: ', acc)\n",
    "\n",
    "    print('\\nClassification Report')\n",
    "    print('======================================================')\n",
    "    print('\\n', classification_report_results)\n",
    "    \n",
    "    return {\"F1\": f1, \"Accuracy\": acc}\n",
    "\n",
    "def print_score_hateval_task1(y_true, y_pred, name):\n",
    "    return print_score(y_true, y_pred, name, 'macro')\n",
    "    \n",
    "def print_score_detoxis_task1(y_true, y_pred, name):\n",
    "    return print_score(y_true, y_pred, name, 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7abd64d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Dataset type</th>\n",
       "      <th>Groud Truth</th>\n",
       "      <th>Group</th>\n",
       "      <th>Task</th>\n",
       "      <th>Lenguage</th>\n",
       "      <th>Results</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Path</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>./results/hateval2019/task1/english/train/train_truth_task1.pkl</th>\n",
       "      <td>English Train</td>\n",
       "      <td>None</td>\n",
       "      <td>dataset_types.train</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>hateval2019/task1</td>\n",
       "      <td>english</td>\n",
       "      <td>y_pred\n",
       "id          \n",
       "201        1\n",
       "202    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./results/hateval2019/task1/english/development/dev_truth_task1.pkl</th>\n",
       "      <td>English Development</td>\n",
       "      <td>None</td>\n",
       "      <td>dataset_types.development</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>hateval2019/task1</td>\n",
       "      <td>english</td>\n",
       "      <td>y_pred\n",
       "id           \n",
       "18201       0\n",
       "1820...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./results/hateval2019/task1/english/test/test_truth_task1.pkl</th>\n",
       "      <td>English Test</td>\n",
       "      <td>None</td>\n",
       "      <td>dataset_types.test</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>hateval2019/task1</td>\n",
       "      <td>english</td>\n",
       "      <td>y_pred\n",
       "id           \n",
       "34243       0\n",
       "3059...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./results/hateval2019/task1/spanish/train/train_truth_task1.pkl</th>\n",
       "      <td>Spanish Train</td>\n",
       "      <td>None</td>\n",
       "      <td>dataset_types.train</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>hateval2019/task1</td>\n",
       "      <td>spanish</td>\n",
       "      <td>y_pred\n",
       "id           \n",
       "20001       1\n",
       "2000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./results/detoxis/task1/spanish/train/train_truth_task1.pkl</th>\n",
       "      <td>Detoxis Train</td>\n",
       "      <td>None</td>\n",
       "      <td>dataset_types.train</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>detoxis/task1</td>\n",
       "      <td>spanish</td>\n",
       "      <td>y_pred\n",
       "id          \n",
       "0          0\n",
       "1      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./results/hateval2019/task1/spanish/development/dev_truth_task1.pkl</th>\n",
       "      <td>Spanish Development</td>\n",
       "      <td>None</td>\n",
       "      <td>dataset_types.development</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>hateval2019/task1</td>\n",
       "      <td>spanish</td>\n",
       "      <td>y_pred\n",
       "id           \n",
       "20005       0\n",
       "2000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./results/detoxis/task1/spanish/development/dev_truth_task1.pkl</th>\n",
       "      <td>Detoxis Development</td>\n",
       "      <td>None</td>\n",
       "      <td>dataset_types.development</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>detoxis/task1</td>\n",
       "      <td>spanish</td>\n",
       "      <td>y_pred\n",
       "id         \n",
       "0         0\n",
       "1         ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./results/hateval2019/task1/spanish/test/test_truth_task1.pkl</th>\n",
       "      <td>Spanish Test</td>\n",
       "      <td>None</td>\n",
       "      <td>dataset_types.test</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>hateval2019/task1</td>\n",
       "      <td>spanish</td>\n",
       "      <td>y_pred\n",
       "id           \n",
       "31494       0\n",
       "3246...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   Name  \\\n",
       "Path                                                                      \n",
       "./results/hateval2019/task1/english/train/train...        English Train   \n",
       "./results/hateval2019/task1/english/development...  English Development   \n",
       "./results/hateval2019/task1/english/test/test_t...         English Test   \n",
       "./results/hateval2019/task1/spanish/train/train...        Spanish Train   \n",
       "./results/detoxis/task1/spanish/train/train_tru...        Detoxis Train   \n",
       "./results/hateval2019/task1/spanish/development...  Spanish Development   \n",
       "./results/detoxis/task1/spanish/development/dev...  Detoxis Development   \n",
       "./results/hateval2019/task1/spanish/test/test_t...         Spanish Test   \n",
       "\n",
       "                                                   Description  \\\n",
       "Path                                                             \n",
       "./results/hateval2019/task1/english/train/train...        None   \n",
       "./results/hateval2019/task1/english/development...        None   \n",
       "./results/hateval2019/task1/english/test/test_t...        None   \n",
       "./results/hateval2019/task1/spanish/train/train...        None   \n",
       "./results/detoxis/task1/spanish/train/train_tru...        None   \n",
       "./results/hateval2019/task1/spanish/development...        None   \n",
       "./results/detoxis/task1/spanish/development/dev...        None   \n",
       "./results/hateval2019/task1/spanish/test/test_t...        None   \n",
       "\n",
       "                                                                 Dataset type  \\\n",
       "Path                                                                            \n",
       "./results/hateval2019/task1/english/train/train...        dataset_types.train   \n",
       "./results/hateval2019/task1/english/development...  dataset_types.development   \n",
       "./results/hateval2019/task1/english/test/test_t...         dataset_types.test   \n",
       "./results/hateval2019/task1/spanish/train/train...        dataset_types.train   \n",
       "./results/detoxis/task1/spanish/train/train_tru...        dataset_types.train   \n",
       "./results/hateval2019/task1/spanish/development...  dataset_types.development   \n",
       "./results/detoxis/task1/spanish/development/dev...  dataset_types.development   \n",
       "./results/hateval2019/task1/spanish/test/test_t...         dataset_types.test   \n",
       "\n",
       "                                                    Groud Truth Group  \\\n",
       "Path                                                                    \n",
       "./results/hateval2019/task1/english/train/train...         True  None   \n",
       "./results/hateval2019/task1/english/development...         True  None   \n",
       "./results/hateval2019/task1/english/test/test_t...         True  None   \n",
       "./results/hateval2019/task1/spanish/train/train...         True  None   \n",
       "./results/detoxis/task1/spanish/train/train_tru...         True  None   \n",
       "./results/hateval2019/task1/spanish/development...         True  None   \n",
       "./results/detoxis/task1/spanish/development/dev...         True  None   \n",
       "./results/hateval2019/task1/spanish/test/test_t...         True  None   \n",
       "\n",
       "                                                                 Task  \\\n",
       "Path                                                                    \n",
       "./results/hateval2019/task1/english/train/train...  hateval2019/task1   \n",
       "./results/hateval2019/task1/english/development...  hateval2019/task1   \n",
       "./results/hateval2019/task1/english/test/test_t...  hateval2019/task1   \n",
       "./results/hateval2019/task1/spanish/train/train...  hateval2019/task1   \n",
       "./results/detoxis/task1/spanish/train/train_tru...      detoxis/task1   \n",
       "./results/hateval2019/task1/spanish/development...  hateval2019/task1   \n",
       "./results/detoxis/task1/spanish/development/dev...      detoxis/task1   \n",
       "./results/hateval2019/task1/spanish/test/test_t...  hateval2019/task1   \n",
       "\n",
       "                                                   Lenguage  \\\n",
       "Path                                                          \n",
       "./results/hateval2019/task1/english/train/train...  english   \n",
       "./results/hateval2019/task1/english/development...  english   \n",
       "./results/hateval2019/task1/english/test/test_t...  english   \n",
       "./results/hateval2019/task1/spanish/train/train...  spanish   \n",
       "./results/detoxis/task1/spanish/train/train_tru...  spanish   \n",
       "./results/hateval2019/task1/spanish/development...  spanish   \n",
       "./results/detoxis/task1/spanish/development/dev...  spanish   \n",
       "./results/hateval2019/task1/spanish/test/test_t...  spanish   \n",
       "\n",
       "                                                                                              Results  \n",
       "Path                                                                                                   \n",
       "./results/hateval2019/task1/english/train/train...        y_pred\n",
       "id          \n",
       "201        1\n",
       "202    ...  \n",
       "./results/hateval2019/task1/english/development...         y_pred\n",
       "id           \n",
       "18201       0\n",
       "1820...  \n",
       "./results/hateval2019/task1/english/test/test_t...         y_pred\n",
       "id           \n",
       "34243       0\n",
       "3059...  \n",
       "./results/hateval2019/task1/spanish/train/train...         y_pred\n",
       "id           \n",
       "20001       1\n",
       "2000...  \n",
       "./results/detoxis/task1/spanish/train/train_tru...        y_pred\n",
       "id          \n",
       "0          0\n",
       "1      ...  \n",
       "./results/hateval2019/task1/spanish/development...         y_pred\n",
       "id           \n",
       "20005       0\n",
       "2000...  \n",
       "./results/detoxis/task1/spanish/development/dev...       y_pred\n",
       "id         \n",
       "0         0\n",
       "1         ...  \n",
       "./results/hateval2019/task1/spanish/test/test_t...         y_pred\n",
       "id           \n",
       "31494       0\n",
       "3246...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = load_results()\n",
    "\n",
    "mask = df_results[\"Groud Truth\"] == True\n",
    "\n",
    "df_truth = df_results[mask]\n",
    "df_pred = df_results[~mask]\n",
    "\n",
    "df_truth.sort_values(by=[\"Lenguage\", \"Dataset type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b6f5fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert base\n",
      "F1 macro:  0.9299943995519642\n",
      "Accuracy:  0.9315555555555556\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94      5217\n",
      "           1       0.91      0.93      0.92      3783\n",
      "\n",
      "    accuracy                           0.93      9000\n",
      "   macro avg       0.93      0.93      0.93      9000\n",
      "weighted avg       0.93      0.93      0.93      9000\n",
      "\n",
      "Bert base\n",
      "F1 macro:  0.7469041129594169\n",
      "Accuracy:  0.749\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.73      0.77       573\n",
      "           1       0.68      0.77      0.72       427\n",
      "\n",
      "    accuracy                           0.75      1000\n",
      "   macro avg       0.75      0.75      0.75      1000\n",
      "weighted avg       0.76      0.75      0.75      1000\n",
      "\n",
      "Bert base\n",
      "F1 macro:  0.5941497231031642\n",
      "Accuracy:  0.6053333333333333\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.38      0.53      1740\n",
      "           1       0.52      0.92      0.66      1260\n",
      "\n",
      "    accuracy                           0.61      3000\n",
      "   macro avg       0.69      0.65      0.59      3000\n",
      "weighted avg       0.72      0.61      0.58      3000\n",
      "\n",
      "CLS layers\n",
      "F1 macro:  0.9315993348092122\n",
      "Accuracy:  0.9331111111111111\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94      5217\n",
      "           1       0.91      0.93      0.92      3783\n",
      "\n",
      "    accuracy                           0.93      9000\n",
      "   macro avg       0.93      0.93      0.93      9000\n",
      "weighted avg       0.93      0.93      0.93      9000\n",
      "\n",
      "CLS layers\n",
      "F1 macro:  0.7503514788390029\n",
      "Accuracy:  0.753\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.75      0.78       573\n",
      "           1       0.69      0.76      0.72       427\n",
      "\n",
      "    accuracy                           0.75      1000\n",
      "   macro avg       0.75      0.75      0.75      1000\n",
      "weighted avg       0.76      0.75      0.75      1000\n",
      "\n",
      "CLS layers\n",
      "F1 macro:  0.5897659922431816\n",
      "Accuracy:  0.6026666666666667\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.37      0.52      1740\n",
      "           1       0.51      0.93      0.66      1260\n",
      "\n",
      "    accuracy                           0.60      3000\n",
      "   macro avg       0.70      0.65      0.59      3000\n",
      "weighted avg       0.72      0.60      0.58      3000\n",
      "\n",
      "Tokens\n",
      "F1 macro:  0.9361135549220875\n",
      "Accuracy:  0.9374444444444444\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95      5217\n",
      "           1       0.91      0.94      0.93      3783\n",
      "\n",
      "    accuracy                           0.94      9000\n",
      "   macro avg       0.93      0.94      0.94      9000\n",
      "weighted avg       0.94      0.94      0.94      9000\n",
      "\n",
      "Tokens\n",
      "F1 macro:  0.7482234647673988\n",
      "Accuracy:  0.75\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.73      0.77       573\n",
      "           1       0.68      0.78      0.73       427\n",
      "\n",
      "    accuracy                           0.75      1000\n",
      "   macro avg       0.75      0.75      0.75      1000\n",
      "weighted avg       0.76      0.75      0.75      1000\n",
      "\n",
      "Tokens\n",
      "F1 macro:  0.5865296894939933\n",
      "Accuracy:  0.599\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.37      0.51      1740\n",
      "           1       0.51      0.92      0.66      1260\n",
      "\n",
      "    accuracy                           0.60      3000\n",
      "   macro avg       0.69      0.64      0.59      3000\n",
      "weighted avg       0.72      0.60      0.58      3000\n",
      "\n",
      "Entire layer\n",
      "F1 macro:  0.9406446461420284\n",
      "Accuracy:  0.942\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95      5217\n",
      "           1       0.92      0.94      0.93      3783\n",
      "\n",
      "    accuracy                           0.94      9000\n",
      "   macro avg       0.94      0.94      0.94      9000\n",
      "weighted avg       0.94      0.94      0.94      9000\n",
      "\n",
      "Entire layer\n",
      "F1 macro:  0.7572461030948603\n",
      "Accuracy:  0.759\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.74      0.78       573\n",
      "           1       0.69      0.79      0.74       427\n",
      "\n",
      "    accuracy                           0.76      1000\n",
      "   macro avg       0.76      0.76      0.76      1000\n",
      "weighted avg       0.77      0.76      0.76      1000\n",
      "\n",
      "Entire layer\n",
      "F1 macro:  0.5866254652469632\n",
      "Accuracy:  0.5993333333333334\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.37      0.51      1740\n",
      "           1       0.51      0.92      0.66      1260\n",
      "\n",
      "    accuracy                           0.60      3000\n",
      "   macro avg       0.69      0.64      0.59      3000\n",
      "weighted avg       0.72      0.60      0.58      3000\n",
      "\n",
      "Bert base\n",
      "F1 macro:  0.9591979001127111\n",
      "Accuracy:  0.9602222222222222\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97      2643\n",
      "           1       0.93      0.97      0.95      1857\n",
      "\n",
      "    accuracy                           0.96      4500\n",
      "   macro avg       0.96      0.96      0.96      4500\n",
      "weighted avg       0.96      0.96      0.96      4500\n",
      "\n",
      "Bert base\n",
      "F1 macro:  0.8331825947140992\n",
      "Accuracy:  0.834\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.81      0.84       278\n",
      "           1       0.79      0.86      0.82       222\n",
      "\n",
      "    accuracy                           0.83       500\n",
      "   macro avg       0.83      0.84      0.83       500\n",
      "weighted avg       0.84      0.83      0.83       500\n",
      "\n",
      "Bert base\n",
      "F1 macro:  0.7413213956087423\n",
      "Accuracy:  0.7425\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.69      0.76       940\n",
      "           1       0.65      0.82      0.72       660\n",
      "\n",
      "    accuracy                           0.74      1600\n",
      "   macro avg       0.75      0.75      0.74      1600\n",
      "weighted avg       0.76      0.74      0.74      1600\n",
      "\n",
      "Bert Avarage\n",
      "F1 macro:  0.9393834282481186\n",
      "Accuracy:  0.9407777777777778\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95      5217\n",
      "           1       0.92      0.94      0.93      3783\n",
      "\n",
      "    accuracy                           0.94      9000\n",
      "   macro avg       0.94      0.94      0.94      9000\n",
      "weighted avg       0.94      0.94      0.94      9000\n",
      "\n",
      "Bert Avarage\n",
      "F1 macro:  0.7508450589145519\n",
      "Accuracy:  0.753\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.74      0.77       573\n",
      "           1       0.69      0.77      0.73       427\n",
      "\n",
      "    accuracy                           0.75      1000\n",
      "   macro avg       0.75      0.76      0.75      1000\n",
      "weighted avg       0.76      0.75      0.75      1000\n",
      "\n",
      "Bert Avarage\n",
      "F1 macro:  0.5939885574846252\n",
      "Accuracy:  0.606\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.37      0.52      1740\n",
      "           1       0.52      0.93      0.66      1260\n",
      "\n",
      "    accuracy                           0.61      3000\n",
      "   macro avg       0.70      0.65      0.59      3000\n",
      "weighted avg       0.72      0.61      0.58      3000\n",
      "\n",
      "Bert Avarage\n",
      "F1 macro:  0.9835327664403473\n",
      "Accuracy:  0.984\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      2643\n",
      "           1       0.97      0.99      0.98      1857\n",
      "\n",
      "    accuracy                           0.98      4500\n",
      "   macro avg       0.98      0.98      0.98      4500\n",
      "weighted avg       0.98      0.98      0.98      4500\n",
      "\n",
      "Bert Avarage\n",
      "F1 macro:  0.8312195592419347\n",
      "Accuracy:  0.832\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.81      0.84       278\n",
      "           1       0.78      0.86      0.82       222\n",
      "\n",
      "    accuracy                           0.83       500\n",
      "   macro avg       0.83      0.83      0.83       500\n",
      "weighted avg       0.84      0.83      0.83       500\n",
      "\n",
      "Bert Avarage\n",
      "F1 macro:  0.745737872226218\n",
      "Accuracy:  0.746875\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.69      0.76       940\n",
      "           1       0.65      0.82      0.73       660\n",
      "\n",
      "    accuracy                           0.75      1600\n",
      "   macro avg       0.75      0.76      0.75      1600\n",
      "weighted avg       0.77      0.75      0.75      1600\n",
      "\n",
      "GPT2 base\n",
      "F1 macro:  0.8054590613779311\n",
      "Accuracy:  0.8095555555555556\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83      5217\n",
      "           1       0.76      0.79      0.78      3783\n",
      "\n",
      "    accuracy                           0.81      9000\n",
      "   macro avg       0.80      0.81      0.81      9000\n",
      "weighted avg       0.81      0.81      0.81      9000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2 base\n",
      "F1 macro:  0.7356241852210881\n",
      "Accuracy:  0.739\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.74      0.77       573\n",
      "           1       0.68      0.73      0.71       427\n",
      "\n",
      "    accuracy                           0.74      1000\n",
      "   macro avg       0.73      0.74      0.74      1000\n",
      "weighted avg       0.74      0.74      0.74      1000\n",
      "\n",
      "GPT2 base\n",
      "F1 macro:  0.4359989192440023\n",
      "Accuracy:  0.49066666666666664\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.15      0.26      1740\n",
      "           1       0.45      0.95      0.61      1260\n",
      "\n",
      "    accuracy                           0.49      3000\n",
      "   macro avg       0.64      0.55      0.44      3000\n",
      "weighted avg       0.67      0.49      0.41      3000\n",
      "\n",
      "Atalaya\n",
      "F1 macro:  0.9015782362817413\n",
      "Accuracy:  0.9038888888888889\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.92      5217\n",
      "           1       0.88      0.89      0.89      3783\n",
      "\n",
      "    accuracy                           0.90      9000\n",
      "   macro avg       0.90      0.90      0.90      9000\n",
      "weighted avg       0.90      0.90      0.90      9000\n",
      "\n",
      "Atalaya\n",
      "F1 macro:  0.7400235293879628\n",
      "Accuracy:  0.743\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.74      0.77       573\n",
      "           1       0.68      0.74      0.71       427\n",
      "\n",
      "    accuracy                           0.74      1000\n",
      "   macro avg       0.74      0.74      0.74      1000\n",
      "weighted avg       0.75      0.74      0.74      1000\n",
      "\n",
      "Atalaya\n",
      "F1 macro:  0.4707390911055481\n",
      "Accuracy:  0.508\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.21      0.33      1740\n",
      "           1       0.46      0.92      0.61      1260\n",
      "\n",
      "    accuracy                           0.51      3000\n",
      "   macro avg       0.62      0.56      0.47      3000\n",
      "weighted avg       0.65      0.51      0.45      3000\n",
      "\n",
      "Atalaya\n",
      "F1 macro:  0.9465627517716503\n",
      "Accuracy:  0.948\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96      2643\n",
      "           1       0.93      0.95      0.94      1857\n",
      "\n",
      "    accuracy                           0.95      4500\n",
      "   macro avg       0.95      0.95      0.95      4500\n",
      "weighted avg       0.95      0.95      0.95      4500\n",
      "\n",
      "Atalaya\n",
      "F1 macro:  0.7396999891037204\n",
      "Accuracy:  0.742\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.75      0.76       278\n",
      "           1       0.70      0.73      0.72       222\n",
      "\n",
      "    accuracy                           0.74       500\n",
      "   macro avg       0.74      0.74      0.74       500\n",
      "weighted avg       0.74      0.74      0.74       500\n",
      "\n",
      "Atalaya\n",
      "F1 macro:  0.7082592009648918\n",
      "Accuracy:  0.71125\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.69      0.74       940\n",
      "           1       0.63      0.74      0.68       660\n",
      "\n",
      "    accuracy                           0.71      1600\n",
      "   macro avg       0.71      0.72      0.71      1600\n",
      "weighted avg       0.72      0.71      0.71      1600\n",
      "\n",
      "Bert base (4 epochs)\n",
      "F1 macro:  0.9583333333333333\n",
      "Accuracy:  0.9732851985559566\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      1869\n",
      "           1       0.97      0.94      0.96       901\n",
      "\n",
      "    accuracy                           0.97      2770\n",
      "   macro avg       0.97      0.97      0.97      2770\n",
      "weighted avg       0.97      0.97      0.97      2770\n",
      "\n",
      "Bert base (4 epochs)\n",
      "F1 macro:  0.6406926406926408\n",
      "Accuracy:  0.7604617604617605\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.85      0.82       447\n",
      "           1       0.69      0.60      0.64       246\n",
      "\n",
      "    accuracy                           0.76       693\n",
      "   macro avg       0.74      0.72      0.73       693\n",
      "weighted avg       0.76      0.76      0.76       693\n",
      "\n",
      "Bert base (4 epochs)\n",
      "F1 macro:  None\n",
      "Accuracy:  None\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      " None\n",
      "Bert Avarage\n",
      "F1 macro:  0.9804141018466703\n",
      "Accuracy:  0.9873646209386282\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1869\n",
      "           1       0.99      0.97      0.98       901\n",
      "\n",
      "    accuracy                           0.99      2770\n",
      "   macro avg       0.99      0.98      0.99      2770\n",
      "weighted avg       0.99      0.99      0.99      2770\n",
      "\n",
      "Bert Avarage\n",
      "F1 macro:  0.6481876332622601\n",
      "Accuracy:  0.7619047619047619\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82       447\n",
      "           1       0.68      0.62      0.65       246\n",
      "\n",
      "    accuracy                           0.76       693\n",
      "   macro avg       0.74      0.73      0.73       693\n",
      "weighted avg       0.76      0.76      0.76       693\n",
      "\n",
      "Bert Avarage\n",
      "F1 macro:  None\n",
      "Accuracy:  None\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      " None\n",
      "Atalaya\n",
      "F1 macro:  0.3424908424908425\n",
      "Accuracy:  0.7407942238267148\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.84      1869\n",
      "           1       0.98      0.21      0.34       901\n",
      "\n",
      "    accuracy                           0.74      2770\n",
      "   macro avg       0.85      0.60      0.59      2770\n",
      "weighted avg       0.81      0.74      0.68      2770\n",
      "\n",
      "Atalaya\n",
      "F1 macro:  0.06792452830188679\n",
      "Accuracy:  0.6435786435786436\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.98      0.78       447\n",
      "           1       0.47      0.04      0.07       246\n",
      "\n",
      "    accuracy                           0.64       693\n",
      "   macro avg       0.56      0.51      0.42       693\n",
      "weighted avg       0.59      0.64      0.53       693\n",
      "\n",
      "Atalaya\n",
      "F1 macro:  None\n",
      "Accuracy:  None\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      " None\n",
      "Ridge Classifier\n",
      "F1 macro:  0.6293888166449935\n",
      "Accuracy:  0.7942238267148014\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.92      0.86      1869\n",
      "           1       0.76      0.54      0.63       901\n",
      "\n",
      "    accuracy                           0.79      2770\n",
      "   macro avg       0.78      0.73      0.74      2770\n",
      "weighted avg       0.79      0.79      0.78      2770\n",
      "\n",
      "Ridge Classifier (best)\n",
      "F1 macro:  0.6540880503144654\n",
      "Accuracy:  0.8014440433212996\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.91      0.86      1869\n",
      "           1       0.75      0.58      0.65       901\n",
      "\n",
      "    accuracy                           0.80      2770\n",
      "   macro avg       0.79      0.74      0.76      2770\n",
      "weighted avg       0.80      0.80      0.79      2770\n",
      "\n",
      "Random Forest classifier\n",
      "F1 macro:  0.9994447529150472\n",
      "Accuracy:  0.9996389891696751\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1869\n",
      "           1       1.00      1.00      1.00       901\n",
      "\n",
      "    accuracy                           1.00      2770\n",
      "   macro avg       1.00      1.00      1.00      2770\n",
      "weighted avg       1.00      1.00      1.00      2770\n",
      "\n",
      "Random Forest classifier (best)\n",
      "F1 macro:  0.8696172248803828\n",
      "Accuracy:  0.9212996389891697\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94      1869\n",
      "           1       0.94      0.81      0.87       901\n",
      "\n",
      "    accuracy                           0.92      2770\n",
      "   macro avg       0.93      0.89      0.91      2770\n",
      "weighted avg       0.92      0.92      0.92      2770\n",
      "\n",
      "Support Vector Classification\n",
      "F1 macro:  0.8231511254019293\n",
      "Accuracy:  0.9007220216606499\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93      1869\n",
      "           1       0.98      0.71      0.82       901\n",
      "\n",
      "    accuracy                           0.90      2770\n",
      "   macro avg       0.93      0.85      0.88      2770\n",
      "weighted avg       0.91      0.90      0.90      2770\n",
      "\n",
      "Support Vector Classification (best)\n",
      "F1 macro:  0.9977753058954394\n",
      "Accuracy:  0.9985559566787003\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1869\n",
      "           1       1.00      1.00      1.00       901\n",
      "\n",
      "    accuracy                           1.00      2770\n",
      "   macro avg       1.00      1.00      1.00      2770\n",
      "weighted avg       1.00      1.00      1.00      2770\n",
      "\n",
      "AdaBoost classifier\n",
      "F1 macro:  0.6402966625463535\n",
      "Accuracy:  0.7898916967509025\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.89      0.85      1869\n",
      "           1       0.72      0.57      0.64       901\n",
      "\n",
      "    accuracy                           0.79      2770\n",
      "   macro avg       0.77      0.73      0.75      2770\n",
      "weighted avg       0.78      0.79      0.78      2770\n",
      "\n",
      "AdaBoost classifier (best)\n",
      "F1 macro:  0.8895348837209303\n",
      "Accuracy:  0.9314079422382672\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95      1869\n",
      "           1       0.93      0.85      0.89       901\n",
      "\n",
      "    accuracy                           0.93      2770\n",
      "   macro avg       0.93      0.91      0.92      2770\n",
      "weighted avg       0.93      0.93      0.93      2770\n",
      "\n",
      "Multi-layer Perceptron classifier\n",
      "F1 macro:  0.6539173349784083\n",
      "Accuracy:  0.7974729241877256\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86      1869\n",
      "           1       0.74      0.59      0.65       901\n",
      "\n",
      "    accuracy                           0.80      2770\n",
      "   macro avg       0.78      0.74      0.76      2770\n",
      "weighted avg       0.79      0.80      0.79      2770\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-layer Perceptron classifier (best)\n",
      "F1 macro:  0.5484764542936288\n",
      "Accuracy:  0.7646209386281588\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.92      0.84      1869\n",
      "           1       0.73      0.44      0.55       901\n",
      "\n",
      "    accuracy                           0.76      2770\n",
      "   macro avg       0.75      0.68      0.69      2770\n",
      "weighted avg       0.76      0.76      0.75      2770\n",
      "\n",
      "Ridge Classifier\n",
      "F1 macro:  0.5798525798525799\n",
      "Accuracy:  0.7532467532467533\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.90      0.83       447\n",
      "           1       0.73      0.48      0.58       246\n",
      "\n",
      "    accuracy                           0.75       693\n",
      "   macro avg       0.75      0.69      0.70       693\n",
      "weighted avg       0.75      0.75      0.74       693\n",
      "\n",
      "Ridge Classifier (best)\n",
      "F1 macro:  0.5795724465558194\n",
      "Accuracy:  0.7445887445887446\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.88      0.82       447\n",
      "           1       0.70      0.50      0.58       246\n",
      "\n",
      "    accuracy                           0.74       693\n",
      "   macro avg       0.73      0.69      0.70       693\n",
      "weighted avg       0.74      0.74      0.73       693\n",
      "\n",
      "Random Forest classifier\n",
      "F1 macro:  0.2935153583617748\n",
      "Accuracy:  0.7012987012987013\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.99      0.81       447\n",
      "           1       0.91      0.17      0.29       246\n",
      "\n",
      "    accuracy                           0.70       693\n",
      "   macro avg       0.80      0.58      0.55       693\n",
      "weighted avg       0.77      0.70      0.63       693\n",
      "\n",
      "Random Forest classifier (best)\n",
      "F1 macro:  0.3678756476683938\n",
      "Accuracy:  0.6479076479076479\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.85      0.76       447\n",
      "           1       0.51      0.29      0.37       246\n",
      "\n",
      "    accuracy                           0.65       693\n",
      "   macro avg       0.60      0.57      0.56       693\n",
      "weighted avg       0.62      0.65      0.62       693\n",
      "\n",
      "Support Vector Classification\n",
      "F1 macro:  0.5599999999999999\n",
      "Accuracy:  0.7619047619047619\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.95      0.84       447\n",
      "           1       0.81      0.43      0.56       246\n",
      "\n",
      "    accuracy                           0.76       693\n",
      "   macro avg       0.78      0.69      0.70       693\n",
      "weighted avg       0.77      0.76      0.74       693\n",
      "\n",
      "Support Vector Classification (best)\n",
      "F1 macro:  0.5972222222222222\n",
      "Accuracy:  0.7489177489177489\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.87      0.82       447\n",
      "           1       0.69      0.52      0.60       246\n",
      "\n",
      "    accuracy                           0.75       693\n",
      "   macro avg       0.73      0.70      0.71       693\n",
      "weighted avg       0.74      0.75      0.74       693\n",
      "\n",
      "AdaBoost classifier\n",
      "F1 macro:  0.5057471264367815\n",
      "Accuracy:  0.6897546897546898\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.82      0.77       447\n",
      "           1       0.58      0.45      0.51       246\n",
      "\n",
      "    accuracy                           0.69       693\n",
      "   macro avg       0.66      0.64      0.64       693\n",
      "weighted avg       0.68      0.69      0.68       693\n",
      "\n",
      "AdaBoost classifier (best)\n",
      "F1 macro:  0.545045045045045\n",
      "Accuracy:  0.7085137085137085\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.83      0.79       447\n",
      "           1       0.61      0.49      0.55       246\n",
      "\n",
      "    accuracy                           0.71       693\n",
      "   macro avg       0.68      0.66      0.67       693\n",
      "weighted avg       0.70      0.71      0.70       693\n",
      "\n",
      "Multi-layer Perceptron classifier\n",
      "F1 macro:  0.6107226107226107\n",
      "Accuracy:  0.759018759018759\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.88      0.83       447\n",
      "           1       0.72      0.53      0.61       246\n",
      "\n",
      "    accuracy                           0.76       693\n",
      "   macro avg       0.75      0.71      0.72       693\n",
      "weighted avg       0.75      0.76      0.75       693\n",
      "\n",
      "Multi-layer Perceptron classifier (best)\n",
      "F1 macro:  0.5520833333333333\n",
      "Accuracy:  0.7518037518037518\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.93      0.83       447\n",
      "           1       0.77      0.43      0.55       246\n",
      "\n",
      "    accuracy                           0.75       693\n",
      "   macro avg       0.76      0.68      0.69       693\n",
      "weighted avg       0.75      0.75      0.73       693\n",
      "\n",
      "Ridge Classifier\n",
      "F1 macro:  None\n",
      "Accuracy:  None\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      " None\n",
      "Ridge Classifier (best)\n",
      "F1 macro:  None\n",
      "Accuracy:  None\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      " None\n",
      "Random Forest classifier\n",
      "F1 macro:  None\n",
      "Accuracy:  None\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      " None\n",
      "Random Forest classifier (best)\n",
      "F1 macro:  None\n",
      "Accuracy:  None\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      " None\n",
      "Support Vector Classification\n",
      "F1 macro:  None\n",
      "Accuracy:  None\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      " None\n",
      "Support Vector Classification (best)\n",
      "F1 macro:  None\n",
      "Accuracy:  None\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      " None\n",
      "AdaBoost classifier\n",
      "F1 macro:  None\n",
      "Accuracy:  None\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      " None\n",
      "AdaBoost classifier (best)\n",
      "F1 macro:  None\n",
      "Accuracy:  None\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      " None\n",
      "Multi-layer Perceptron classifier\n",
      "F1 macro:  None\n",
      "Accuracy:  None\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      " None\n",
      "Multi-layer Perceptron classifier (best)\n",
      "F1 macro:  None\n",
      "Accuracy:  None\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      " None\n",
      "Dummy Classifier\n",
      "F1 macro:  0.3669550538088204\n",
      "Accuracy:  0.5796666666666667\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      1.00      0.73      5217\n",
      "           1       0.00      0.00      0.00      3783\n",
      "\n",
      "    accuracy                           0.58      9000\n",
      "   macro avg       0.29      0.50      0.37      9000\n",
      "weighted avg       0.34      0.58      0.43      9000\n",
      "\n",
      "Multinomial Naive Bayes classifier (best)\n",
      "F1 macro:  0.8162150596086619\n",
      "Accuracy:  0.8234444444444444\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.88      0.85      5217\n",
      "           1       0.82      0.74      0.78      3783\n",
      "\n",
      "    accuracy                           0.82      9000\n",
      "   macro avg       0.82      0.81      0.82      9000\n",
      "weighted avg       0.82      0.82      0.82      9000\n",
      "\n",
      "Multinomial Naive Bayes classifier\n",
      "F1 macro:  0.8128440083283514\n",
      "Accuracy:  0.8206666666666667\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.88      0.85      5217\n",
      "           1       0.82      0.73      0.77      3783\n",
      "\n",
      "    accuracy                           0.82      9000\n",
      "   macro avg       0.82      0.81      0.81      9000\n",
      "weighted avg       0.82      0.82      0.82      9000\n",
      "\n",
      "Bernoulli Naive Bayes classifier (best)\n",
      "F1 macro:  0.8136502672774464\n",
      "Accuracy:  0.8197777777777778\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.85      5217\n",
      "           1       0.80      0.76      0.78      3783\n",
      "\n",
      "    accuracy                           0.82      9000\n",
      "   macro avg       0.82      0.81      0.81      9000\n",
      "weighted avg       0.82      0.82      0.82      9000\n",
      "\n",
      "Bernoulli Naive Bayes classifier\n",
      "F1 macro:  0.8192899697037473\n",
      "Accuracy:  0.8244444444444444\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.86      0.85      5217\n",
      "           1       0.80      0.78      0.79      3783\n",
      "\n",
      "    accuracy                           0.82      9000\n",
      "   macro avg       0.82      0.82      0.82      9000\n",
      "weighted avg       0.82      0.82      0.82      9000\n",
      "\n",
      "Ridge Classifier (best)\n",
      "F1 macro:  0.8336837370167958\n",
      "Accuracy:  0.8415555555555555\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87      5217\n",
      "           1       0.86      0.74      0.80      3783\n",
      "\n",
      "    accuracy                           0.84      9000\n",
      "   macro avg       0.85      0.83      0.83      9000\n",
      "weighted avg       0.84      0.84      0.84      9000\n",
      "\n",
      "Ridge Classifier\n",
      "F1 macro:  0.8763584453858906\n",
      "Accuracy:  0.8806666666666667\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90      5217\n",
      "           1       0.88      0.83      0.85      3783\n",
      "\n",
      "    accuracy                           0.88      9000\n",
      "   macro avg       0.88      0.87      0.88      9000\n",
      "weighted avg       0.88      0.88      0.88      9000\n",
      "\n",
      "Random Forest classifier (best)\n",
      "F1 macro:  0.9977190608856654\n",
      "Accuracy:  0.9977777777777778\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5217\n",
      "           1       1.00      1.00      1.00      3783\n",
      "\n",
      "    accuracy                           1.00      9000\n",
      "   macro avg       1.00      1.00      1.00      9000\n",
      "weighted avg       1.00      1.00      1.00      9000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest classifier\n",
      "F1 macro:  0.9989737648560049\n",
      "Accuracy:  0.999\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5217\n",
      "           1       1.00      1.00      1.00      3783\n",
      "\n",
      "    accuracy                           1.00      9000\n",
      "   macro avg       1.00      1.00      1.00      9000\n",
      "weighted avg       1.00      1.00      1.00      9000\n",
      "\n",
      "Support Vector Classification (best)\n",
      "F1 macro:  0.9540676206890405\n",
      "Accuracy:  0.9553333333333334\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      5217\n",
      "           1       0.95      0.94      0.95      3783\n",
      "\n",
      "    accuracy                           0.96      9000\n",
      "   macro avg       0.96      0.95      0.95      9000\n",
      "weighted avg       0.96      0.96      0.96      9000\n",
      "\n",
      "Support Vector Classification\n",
      "F1 macro:  0.9555173113702441\n",
      "Accuracy:  0.9567777777777777\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      5217\n",
      "           1       0.96      0.94      0.95      3783\n",
      "\n",
      "    accuracy                           0.96      9000\n",
      "   macro avg       0.96      0.95      0.96      9000\n",
      "weighted avg       0.96      0.96      0.96      9000\n",
      "\n",
      "AdaBoost classifier (best)\n",
      "F1 macro:  0.7710255791554386\n",
      "Accuracy:  0.7852222222222223\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.89      0.83      5217\n",
      "           1       0.81      0.64      0.71      3783\n",
      "\n",
      "    accuracy                           0.79      9000\n",
      "   macro avg       0.79      0.76      0.77      9000\n",
      "weighted avg       0.79      0.79      0.78      9000\n",
      "\n",
      "AdaBoost classifier\n",
      "F1 macro:  0.7640156422637805\n",
      "Accuracy:  0.7787777777777778\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.89      0.82      5217\n",
      "           1       0.80      0.63      0.70      3783\n",
      "\n",
      "    accuracy                           0.78      9000\n",
      "   macro avg       0.78      0.76      0.76      9000\n",
      "weighted avg       0.78      0.78      0.77      9000\n",
      "\n",
      "Multi-layer Perceptron classifier (best)\n",
      "F1 macro:  0.8120036865391967\n",
      "Accuracy:  0.8201111111111111\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.89      0.85      5217\n",
      "           1       0.82      0.73      0.77      3783\n",
      "\n",
      "    accuracy                           0.82      9000\n",
      "   macro avg       0.82      0.81      0.81      9000\n",
      "weighted avg       0.82      0.82      0.82      9000\n",
      "\n",
      "Multi-layer Perceptron classifier\n",
      "F1 macro:  0.7867871963771212\n",
      "Accuracy:  0.7998888888888889\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.90      0.84      5217\n",
      "           1       0.83      0.66      0.73      3783\n",
      "\n",
      "    accuracy                           0.80      9000\n",
      "   macro avg       0.81      0.78      0.79      9000\n",
      "weighted avg       0.80      0.80      0.80      9000\n",
      "\n",
      "Dummy Classifier\n",
      "F1 macro:  0.3642720915448188\n",
      "Accuracy:  0.573\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      1.00      0.73       573\n",
      "           1       0.00      0.00      0.00       427\n",
      "\n",
      "    accuracy                           0.57      1000\n",
      "   macro avg       0.29      0.50      0.36      1000\n",
      "weighted avg       0.33      0.57      0.42      1000\n",
      "\n",
      "Multinomial Naive Bayes classifier (best)\n",
      "F1 macro:  0.734869037636265\n",
      "Accuracy:  0.742\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.79      0.78       573\n",
      "           1       0.71      0.68      0.69       427\n",
      "\n",
      "    accuracy                           0.74      1000\n",
      "   macro avg       0.74      0.73      0.73      1000\n",
      "weighted avg       0.74      0.74      0.74      1000\n",
      "\n",
      "Multinomial Naive Bayes classifier\n",
      "F1 macro:  0.734869037636265\n",
      "Accuracy:  0.742\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.79      0.78       573\n",
      "           1       0.71      0.68      0.69       427\n",
      "\n",
      "    accuracy                           0.74      1000\n",
      "   macro avg       0.74      0.73      0.73      1000\n",
      "weighted avg       0.74      0.74      0.74      1000\n",
      "\n",
      "Bernoulli Naive Bayes classifier (best)\n",
      "F1 macro:  0.7382305194805194\n",
      "Accuracy:  0.742\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.75      0.77       573\n",
      "           1       0.69      0.73      0.71       427\n",
      "\n",
      "    accuracy                           0.74      1000\n",
      "   macro avg       0.74      0.74      0.74      1000\n",
      "weighted avg       0.74      0.74      0.74      1000\n",
      "\n",
      "Bernoulli Naive Bayes classifier\n",
      "F1 macro:  0.7364537212734557\n",
      "Accuracy:  0.74\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.75      0.77       573\n",
      "           1       0.68      0.73      0.71       427\n",
      "\n",
      "    accuracy                           0.74      1000\n",
      "   macro avg       0.74      0.74      0.74      1000\n",
      "weighted avg       0.74      0.74      0.74      1000\n",
      "\n",
      "Ridge Classifier (best)\n",
      "F1 macro:  0.7312939231087225\n",
      "Accuracy:  0.74\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.80      0.78       573\n",
      "           1       0.71      0.66      0.68       427\n",
      "\n",
      "    accuracy                           0.74      1000\n",
      "   macro avg       0.74      0.73      0.73      1000\n",
      "weighted avg       0.74      0.74      0.74      1000\n",
      "\n",
      "Ridge Classifier\n",
      "F1 macro:  0.7109660702864922\n",
      "Accuracy:  0.718\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.76      0.76       573\n",
      "           1       0.67      0.66      0.67       427\n",
      "\n",
      "    accuracy                           0.72      1000\n",
      "   macro avg       0.71      0.71      0.71      1000\n",
      "weighted avg       0.72      0.72      0.72      1000\n",
      "\n",
      "Random Forest classifier (best)\n",
      "F1 macro:  0.7421994884910486\n",
      "Accuracy:  0.748\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.78      0.78       573\n",
      "           1       0.71      0.70      0.70       427\n",
      "\n",
      "    accuracy                           0.75      1000\n",
      "   macro avg       0.74      0.74      0.74      1000\n",
      "weighted avg       0.75      0.75      0.75      1000\n",
      "\n",
      "Random Forest classifier\n",
      "F1 macro:  0.7472007103043456\n",
      "Accuracy:  0.754\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.80      0.79       573\n",
      "           1       0.72      0.69      0.71       427\n",
      "\n",
      "    accuracy                           0.75      1000\n",
      "   macro avg       0.75      0.75      0.75      1000\n",
      "weighted avg       0.75      0.75      0.75      1000\n",
      "\n",
      "Support Vector Classification (best)\n",
      "F1 macro:  0.7335580533627453\n",
      "Accuracy:  0.742\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.80      0.78       573\n",
      "           1       0.71      0.66      0.69       427\n",
      "\n",
      "    accuracy                           0.74      1000\n",
      "   macro avg       0.74      0.73      0.73      1000\n",
      "weighted avg       0.74      0.74      0.74      1000\n",
      "\n",
      "Support Vector Classification\n",
      "F1 macro:  0.7319101712034116\n",
      "Accuracy:  0.742\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78       573\n",
      "           1       0.72      0.64      0.68       427\n",
      "\n",
      "    accuracy                           0.74      1000\n",
      "   macro avg       0.74      0.73      0.73      1000\n",
      "weighted avg       0.74      0.74      0.74      1000\n",
      "\n",
      "AdaBoost classifier (best)\n",
      "F1 macro:  0.7265219055953619\n",
      "Accuracy:  0.74\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.84      0.79       573\n",
      "           1       0.74      0.61      0.67       427\n",
      "\n",
      "    accuracy                           0.74      1000\n",
      "   macro avg       0.74      0.72      0.73      1000\n",
      "weighted avg       0.74      0.74      0.74      1000\n",
      "\n",
      "AdaBoost classifier\n",
      "F1 macro:  0.7217901539006285\n",
      "Accuracy:  0.736\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.84      0.78       573\n",
      "           1       0.73      0.60      0.66       427\n",
      "\n",
      "    accuracy                           0.74      1000\n",
      "   macro avg       0.74      0.72      0.72      1000\n",
      "weighted avg       0.74      0.74      0.73      1000\n",
      "\n",
      "Multi-layer Perceptron classifier (best)\n",
      "F1 macro:  0.7255274858009304\n",
      "Accuracy:  0.733\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.78      0.77       573\n",
      "           1       0.70      0.67      0.68       427\n",
      "\n",
      "    accuracy                           0.73      1000\n",
      "   macro avg       0.73      0.72      0.73      1000\n",
      "weighted avg       0.73      0.73      0.73      1000\n",
      "\n",
      "Multi-layer Perceptron classifier\n",
      "F1 macro:  0.7100596644494139\n",
      "Accuracy:  0.725\n",
      "\n",
      "Classification Report\n",
      "======================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.83      0.78       573\n",
      "           1       0.72      0.58      0.64       427\n",
      "\n",
      "    accuracy                           0.73      1000\n",
      "   macro avg       0.72      0.71      0.71      1000\n",
      "weighted avg       0.72      0.72      0.72      1000\n",
      "\n",
      "Dummy Classifier\n",
      "F1 macro:  0.36708860759493667\n",
      "Accuracy:  0.58\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      1.00      0.73      1740\n",
      "           1       0.00      0.00      0.00      1260\n",
      "\n",
      "    accuracy                           0.58      3000\n",
      "   macro avg       0.29      0.50      0.37      3000\n",
      "weighted avg       0.34      0.58      0.43      3000\n",
      "\n",
      "Multinomial Naive Bayes classifier (best)\n",
      "F1 macro:  0.4790122127839357\n",
      "Accuracy:  0.5063333333333333\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.24      0.36      1740\n",
      "           1       0.45      0.88      0.60      1260\n",
      "\n",
      "    accuracy                           0.51      3000\n",
      "   macro avg       0.59      0.56      0.48      3000\n",
      "weighted avg       0.61      0.51      0.46      3000\n",
      "\n",
      "Multinomial Naive Bayes classifier\n",
      "F1 macro:  0.4769695540977982\n",
      "Accuracy:  0.504\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.24      0.36      1740\n",
      "           1       0.45      0.87      0.60      1260\n",
      "\n",
      "    accuracy                           0.50      3000\n",
      "   macro avg       0.59      0.55      0.48      3000\n",
      "weighted avg       0.61      0.50      0.46      3000\n",
      "\n",
      "Bernoulli Naive Bayes classifier (best)\n",
      "F1 macro:  0.43152879323092086\n",
      "Accuracy:  0.481\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.16      0.26      1740\n",
      "           1       0.44      0.92      0.60      1260\n",
      "\n",
      "    accuracy                           0.48      3000\n",
      "   macro avg       0.59      0.54      0.43      3000\n",
      "weighted avg       0.62      0.48      0.40      3000\n",
      "\n",
      "Bernoulli Naive Bayes classifier\n",
      "F1 macro:  0.41992004846498143\n",
      "Accuracy:  0.474\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.15      0.24      1740\n",
      "           1       0.44      0.93      0.60      1260\n",
      "\n",
      "    accuracy                           0.47      3000\n",
      "   macro avg       0.59      0.54      0.42      3000\n",
      "weighted avg       0.61      0.47      0.39      3000\n",
      "\n",
      "Ridge Classifier (best)\n",
      "F1 macro:  0.4785058859114545\n",
      "Accuracy:  0.5063333333333333\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.24      0.36      1740\n",
      "           1       0.45      0.88      0.60      1260\n",
      "\n",
      "    accuracy                           0.51      3000\n",
      "   macro avg       0.59      0.56      0.48      3000\n",
      "weighted avg       0.61      0.51      0.46      3000\n",
      "\n",
      "Ridge Classifier\n",
      "F1 macro:  0.48697526236881566\n",
      "Accuracy:  0.5133333333333333\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.25      0.37      1740\n",
      "           1       0.46      0.88      0.60      1260\n",
      "\n",
      "    accuracy                           0.51      3000\n",
      "   macro avg       0.60      0.56      0.49      3000\n",
      "weighted avg       0.62      0.51      0.47      3000\n",
      "\n",
      "Random Forest classifier (best)\n",
      "F1 macro:  0.3934586620420424\n",
      "Accuracy:  0.457\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.11      0.20      1740\n",
      "           1       0.43      0.93      0.59      1260\n",
      "\n",
      "    accuracy                           0.46      3000\n",
      "   macro avg       0.56      0.52      0.39      3000\n",
      "weighted avg       0.58      0.46      0.36      3000\n",
      "\n",
      "Random Forest classifier\n",
      "F1 macro:  0.3962673573134772\n",
      "Accuracy:  0.45566666666666666\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.12      0.21      1740\n",
      "           1       0.43      0.92      0.59      1260\n",
      "\n",
      "    accuracy                           0.46      3000\n",
      "   macro avg       0.55      0.52      0.40      3000\n",
      "weighted avg       0.57      0.46      0.37      3000\n",
      "\n",
      "Support Vector Classification (best)\n",
      "F1 macro:  0.44850726430916865\n",
      "Accuracy:  0.48733333333333334\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.19      0.30      1740\n",
      "           1       0.45      0.90      0.59      1260\n",
      "\n",
      "    accuracy                           0.49      3000\n",
      "   macro avg       0.58      0.54      0.45      3000\n",
      "weighted avg       0.60      0.49      0.43      3000\n",
      "\n",
      "Support Vector Classification\n",
      "F1 macro:  0.44542732228205584\n",
      "Accuracy:  0.4846666666666667\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.19      0.30      1740\n",
      "           1       0.44      0.89      0.59      1260\n",
      "\n",
      "    accuracy                           0.48      3000\n",
      "   macro avg       0.58      0.54      0.45      3000\n",
      "weighted avg       0.60      0.48      0.42      3000\n",
      "\n",
      "AdaBoost classifier (best)\n",
      "F1 macro:  0.4253963328793964\n",
      "Accuracy:  0.4666666666666667\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.17      0.27      1740\n",
      "           1       0.43      0.87      0.58      1260\n",
      "\n",
      "    accuracy                           0.47      3000\n",
      "   macro avg       0.54      0.52      0.43      3000\n",
      "weighted avg       0.56      0.47      0.40      3000\n",
      "\n",
      "AdaBoost classifier\n",
      "F1 macro:  0.42942942942942947\n",
      "Accuracy:  0.468\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.18      0.28      1740\n",
      "           1       0.43      0.87      0.58      1260\n",
      "\n",
      "    accuracy                           0.47      3000\n",
      "   macro avg       0.54      0.52      0.43      3000\n",
      "weighted avg       0.56      0.47      0.41      3000\n",
      "\n",
      "Multi-layer Perceptron classifier (best)\n",
      "F1 macro:  0.500203827489348\n",
      "Accuracy:  0.5226666666666666\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.27      0.39      1740\n",
      "           1       0.46      0.87      0.61      1260\n",
      "\n",
      "    accuracy                           0.52      3000\n",
      "   macro avg       0.61      0.57      0.50      3000\n",
      "weighted avg       0.63      0.52      0.48      3000\n",
      "\n",
      "Multi-layer Perceptron classifier\n",
      "F1 macro:  0.5104903771082994\n",
      "Accuracy:  0.526\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.30      0.42      1740\n",
      "           1       0.46      0.84      0.60      1260\n",
      "\n",
      "    accuracy                           0.53      3000\n",
      "   macro avg       0.59      0.57      0.51      3000\n",
      "weighted avg       0.61      0.53      0.50      3000\n",
      "\n",
      "Dummy Classifier\n",
      "F1 macro:  0.37001259974800504\n",
      "Accuracy:  0.5873333333333334\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      1.00      0.74      2643\n",
      "           1       0.00      0.00      0.00      1857\n",
      "\n",
      "    accuracy                           0.59      4500\n",
      "   macro avg       0.29      0.50      0.37      4500\n",
      "weighted avg       0.34      0.59      0.43      4500\n",
      "\n",
      "Multinomial Naive Bayes classifier (best)\n",
      "F1 macro:  0.8836085766300149\n",
      "Accuracy:  0.8893333333333333\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91      2643\n",
      "           1       0.91      0.81      0.86      1857\n",
      "\n",
      "    accuracy                           0.89      4500\n",
      "   macro avg       0.89      0.88      0.88      4500\n",
      "weighted avg       0.89      0.89      0.89      4500\n",
      "\n",
      "Multinomial Naive Bayes classifier\n",
      "F1 macro:  0.8612343924272405\n",
      "Accuracy:  0.87\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.90      2643\n",
      "           1       0.92      0.75      0.83      1857\n",
      "\n",
      "    accuracy                           0.87      4500\n",
      "   macro avg       0.88      0.85      0.86      4500\n",
      "weighted avg       0.88      0.87      0.87      4500\n",
      "\n",
      "Bernoulli Naive Bayes classifier (best)\n",
      "F1 macro:  0.8896926671916394\n",
      "Accuracy:  0.8928888888888888\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91      2643\n",
      "           1       0.87      0.88      0.87      1857\n",
      "\n",
      "    accuracy                           0.89      4500\n",
      "   macro avg       0.89      0.89      0.89      4500\n",
      "weighted avg       0.89      0.89      0.89      4500\n",
      "\n",
      "Bernoulli Naive Bayes classifier\n",
      "F1 macro:  0.8758229258985661\n",
      "Accuracy:  0.8802222222222222\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90      2643\n",
      "           1       0.87      0.84      0.85      1857\n",
      "\n",
      "    accuracy                           0.88      4500\n",
      "   macro avg       0.88      0.87      0.88      4500\n",
      "weighted avg       0.88      0.88      0.88      4500\n",
      "\n",
      "Ridge Classifier (best)\n",
      "F1 macro:  0.9076624398645838\n",
      "Accuracy:  0.9115555555555556\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.93      2643\n",
      "           1       0.92      0.86      0.89      1857\n",
      "\n",
      "    accuracy                           0.91      4500\n",
      "   macro avg       0.91      0.90      0.91      4500\n",
      "weighted avg       0.91      0.91      0.91      4500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Classifier\n",
      "F1 macro:  0.9417928090882361\n",
      "Accuracy:  0.9437777777777778\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95      2643\n",
      "           1       0.94      0.92      0.93      1857\n",
      "\n",
      "    accuracy                           0.94      4500\n",
      "   macro avg       0.94      0.94      0.94      4500\n",
      "weighted avg       0.94      0.94      0.94      4500\n",
      "\n",
      "Random Forest classifier (best)\n",
      "F1 macro:  0.9956459547023461\n",
      "Accuracy:  0.9957777777777778\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2643\n",
      "           1       0.99      1.00      0.99      1857\n",
      "\n",
      "    accuracy                           1.00      4500\n",
      "   macro avg       1.00      1.00      1.00      4500\n",
      "weighted avg       1.00      1.00      1.00      4500\n",
      "\n",
      "Random Forest classifier\n",
      "F1 macro:  0.9977085798307364\n",
      "Accuracy:  0.9977777777777778\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2643\n",
      "           1       1.00      1.00      1.00      1857\n",
      "\n",
      "    accuracy                           1.00      4500\n",
      "   macro avg       1.00      1.00      1.00      4500\n",
      "weighted avg       1.00      1.00      1.00      4500\n",
      "\n",
      "Support Vector Classification (best)\n",
      "F1 macro:  0.9194830556563793\n",
      "Accuracy:  0.9222222222222223\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93      2643\n",
      "           1       0.92      0.89      0.90      1857\n",
      "\n",
      "    accuracy                           0.92      4500\n",
      "   macro avg       0.92      0.92      0.92      4500\n",
      "weighted avg       0.92      0.92      0.92      4500\n",
      "\n",
      "Support Vector Classification\n",
      "F1 macro:  0.9756835918383328\n",
      "Accuracy:  0.9764444444444444\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      2643\n",
      "           1       0.97      0.97      0.97      1857\n",
      "\n",
      "    accuracy                           0.98      4500\n",
      "   macro avg       0.98      0.98      0.98      4500\n",
      "weighted avg       0.98      0.98      0.98      4500\n",
      "\n",
      "AdaBoost classifier (best)\n",
      "F1 macro:  0.8543402557677213\n",
      "Accuracy:  0.8613333333333333\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89      2643\n",
      "           1       0.87      0.78      0.82      1857\n",
      "\n",
      "    accuracy                           0.86      4500\n",
      "   macro avg       0.86      0.85      0.85      4500\n",
      "weighted avg       0.86      0.86      0.86      4500\n",
      "\n",
      "AdaBoost classifier\n",
      "F1 macro:  0.7732658386776186\n",
      "Accuracy:  0.7871111111111111\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.88      0.83      2643\n",
      "           1       0.79      0.65      0.72      1857\n",
      "\n",
      "    accuracy                           0.79      4500\n",
      "   macro avg       0.79      0.77      0.77      4500\n",
      "weighted avg       0.79      0.79      0.78      4500\n",
      "\n",
      "Multi-layer Perceptron classifier (best)\n",
      "F1 macro:  0.9263084459601647\n",
      "Accuracy:  0.9286666666666666\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94      2643\n",
      "           1       0.92      0.91      0.91      1857\n",
      "\n",
      "    accuracy                           0.93      4500\n",
      "   macro avg       0.93      0.93      0.93      4500\n",
      "weighted avg       0.93      0.93      0.93      4500\n",
      "\n",
      "Multi-layer Perceptron classifier\n",
      "F1 macro:  0.8999999999999999\n",
      "Accuracy:  0.904\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92      2643\n",
      "           1       0.91      0.85      0.88      1857\n",
      "\n",
      "    accuracy                           0.90      4500\n",
      "   macro avg       0.90      0.90      0.90      4500\n",
      "weighted avg       0.90      0.90      0.90      4500\n",
      "\n",
      "Dummy Classifier\n",
      "F1 macro:  0.3573264781491003\n",
      "Accuracy:  0.556\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      1.00      0.71       278\n",
      "           1       0.00      0.00      0.00       222\n",
      "\n",
      "    accuracy                           0.56       500\n",
      "   macro avg       0.28      0.50      0.36       500\n",
      "weighted avg       0.31      0.56      0.40       500\n",
      "\n",
      "Multinomial Naive Bayes classifier (best)\n",
      "F1 macro:  0.7384663667747673\n",
      "Accuracy:  0.75\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.86      0.79       278\n",
      "           1       0.78      0.61      0.68       222\n",
      "\n",
      "    accuracy                           0.75       500\n",
      "   macro avg       0.76      0.74      0.74       500\n",
      "weighted avg       0.75      0.75      0.74       500\n",
      "\n",
      "Multinomial Naive Bayes classifier\n",
      "F1 macro:  0.7320471596998928\n",
      "Accuracy:  0.748\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.89      0.80       278\n",
      "           1       0.81      0.57      0.67       222\n",
      "\n",
      "    accuracy                           0.75       500\n",
      "   macro avg       0.76      0.73      0.73       500\n",
      "weighted avg       0.76      0.75      0.74       500\n",
      "\n",
      "Bernoulli Naive Bayes classifier (best)\n",
      "F1 macro:  0.7629188939457185\n",
      "Accuracy:  0.766\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79       278\n",
      "           1       0.74      0.73      0.74       222\n",
      "\n",
      "    accuracy                           0.77       500\n",
      "   macro avg       0.76      0.76      0.76       500\n",
      "weighted avg       0.77      0.77      0.77       500\n",
      "\n",
      "Bernoulli Naive Bayes classifier\n",
      "F1 macro:  0.7641355976315962\n",
      "Accuracy:  0.768\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.79       278\n",
      "           1       0.75      0.72      0.73       222\n",
      "\n",
      "    accuracy                           0.77       500\n",
      "   macro avg       0.77      0.76      0.76       500\n",
      "weighted avg       0.77      0.77      0.77       500\n",
      "\n",
      "Ridge Classifier (best)\n",
      "F1 macro:  0.7470291348396411\n",
      "Accuracy:  0.754\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.83      0.79       278\n",
      "           1       0.75      0.66      0.71       222\n",
      "\n",
      "    accuracy                           0.75       500\n",
      "   macro avg       0.75      0.74      0.75       500\n",
      "weighted avg       0.75      0.75      0.75       500\n",
      "\n",
      "Ridge Classifier\n",
      "F1 macro:  0.740153452685422\n",
      "Accuracy:  0.746\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.81      0.78       278\n",
      "           1       0.73      0.67      0.70       222\n",
      "\n",
      "    accuracy                           0.75       500\n",
      "   macro avg       0.74      0.74      0.74       500\n",
      "weighted avg       0.75      0.75      0.74       500\n",
      "\n",
      "Random Forest classifier (best)\n",
      "F1 macro:  0.7767857142857142\n",
      "Accuracy:  0.78\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80       278\n",
      "           1       0.76      0.74      0.75       222\n",
      "\n",
      "    accuracy                           0.78       500\n",
      "   macro avg       0.78      0.78      0.78       500\n",
      "weighted avg       0.78      0.78      0.78       500\n",
      "\n",
      "Random Forest classifier\n",
      "F1 macro:  0.7775137880216689\n",
      "Accuracy:  0.782\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81       278\n",
      "           1       0.77      0.72      0.75       222\n",
      "\n",
      "    accuracy                           0.78       500\n",
      "   macro avg       0.78      0.78      0.78       500\n",
      "weighted avg       0.78      0.78      0.78       500\n",
      "\n",
      "Support Vector Classification (best)\n",
      "F1 macro:  0.7473265519040166\n",
      "Accuracy:  0.752\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.80      0.78       278\n",
      "           1       0.73      0.69      0.71       222\n",
      "\n",
      "    accuracy                           0.75       500\n",
      "   macro avg       0.75      0.75      0.75       500\n",
      "weighted avg       0.75      0.75      0.75       500\n",
      "\n",
      "Support Vector Classification\n",
      "F1 macro:  0.7515898251192369\n",
      "Accuracy:  0.76\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.85      0.80       278\n",
      "           1       0.77      0.65      0.71       222\n",
      "\n",
      "    accuracy                           0.76       500\n",
      "   macro avg       0.76      0.75      0.75       500\n",
      "weighted avg       0.76      0.76      0.76       500\n",
      "\n",
      "AdaBoost classifier (best)\n",
      "F1 macro:  0.7369243164142785\n",
      "Accuracy:  0.744\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78       278\n",
      "           1       0.74      0.65      0.69       222\n",
      "\n",
      "    accuracy                           0.74       500\n",
      "   macro avg       0.74      0.73      0.74       500\n",
      "weighted avg       0.74      0.74      0.74       500\n",
      "\n",
      "AdaBoost classifier\n",
      "F1 macro:  0.7515898251192369\n",
      "Accuracy:  0.76\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.85      0.80       278\n",
      "           1       0.77      0.65      0.71       222\n",
      "\n",
      "    accuracy                           0.76       500\n",
      "   macro avg       0.76      0.75      0.75       500\n",
      "weighted avg       0.76      0.76      0.76       500\n",
      "\n",
      "Multi-layer Perceptron classifier (best)\n",
      "F1 macro:  0.7319693094629156\n",
      "Accuracy:  0.738\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.80      0.77       278\n",
      "           1       0.72      0.66      0.69       222\n",
      "\n",
      "    accuracy                           0.74       500\n",
      "   macro avg       0.74      0.73      0.73       500\n",
      "weighted avg       0.74      0.74      0.74       500\n",
      "\n",
      "Multi-layer Perceptron classifier\n",
      "F1 macro:  0.7486420540235663\n",
      "Accuracy:  0.754\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.81      0.79       278\n",
      "           1       0.74      0.68      0.71       222\n",
      "\n",
      "    accuracy                           0.75       500\n",
      "   macro avg       0.75      0.75      0.75       500\n",
      "weighted avg       0.75      0.75      0.75       500\n",
      "\n",
      "Dummy Classifier\n",
      "F1 macro:  0.3700787401574803\n",
      "Accuracy:  0.5875\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      1.00      0.74       940\n",
      "           1       0.00      0.00      0.00       660\n",
      "\n",
      "    accuracy                           0.59      1600\n",
      "   macro avg       0.29      0.50      0.37      1600\n",
      "weighted avg       0.35      0.59      0.43      1600\n",
      "\n",
      "Multinomial Naive Bayes classifier (best)\n",
      "F1 macro:  0.6931989718901717\n",
      "Accuracy:  0.70625\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.78      0.76       940\n",
      "           1       0.66      0.61      0.63       660\n",
      "\n",
      "    accuracy                           0.71      1600\n",
      "   macro avg       0.70      0.69      0.69      1600\n",
      "weighted avg       0.70      0.71      0.70      1600\n",
      "\n",
      "Multinomial Naive Bayes classifier\n",
      "F1 macro:  0.6850367540180241\n",
      "Accuracy:  0.70375\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.81      0.76       940\n",
      "           1       0.67      0.56      0.61       660\n",
      "\n",
      "    accuracy                           0.70      1600\n",
      "   macro avg       0.70      0.68      0.69      1600\n",
      "weighted avg       0.70      0.70      0.70      1600\n",
      "\n",
      "Bernoulli Naive Bayes classifier (best)\n",
      "F1 macro:  0.6909267811707096\n",
      "Accuracy:  0.694375\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.68      0.72       940\n",
      "           1       0.61      0.71      0.66       660\n",
      "\n",
      "    accuracy                           0.69      1600\n",
      "   macro avg       0.69      0.70      0.69      1600\n",
      "weighted avg       0.71      0.69      0.70      1600\n",
      "\n",
      "Bernoulli Naive Bayes classifier\n",
      "F1 macro:  0.6540403036686673\n",
      "Accuracy:  0.66\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.67      0.70       940\n",
      "           1       0.58      0.64      0.61       660\n",
      "\n",
      "    accuracy                           0.66      1600\n",
      "   macro avg       0.65      0.66      0.65      1600\n",
      "weighted avg       0.67      0.66      0.66      1600\n",
      "\n",
      "Ridge Classifier (best)\n",
      "F1 macro:  0.6986556515689941\n",
      "Accuracy:  0.70625\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.74      0.75       940\n",
      "           1       0.64      0.66      0.65       660\n",
      "\n",
      "    accuracy                           0.71      1600\n",
      "   macro avg       0.70      0.70      0.70      1600\n",
      "weighted avg       0.71      0.71      0.71      1600\n",
      "\n",
      "Ridge Classifier\n",
      "F1 macro:  0.6986573085138846\n",
      "Accuracy:  0.70375\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.71      0.74       940\n",
      "           1       0.63      0.70      0.66       660\n",
      "\n",
      "    accuracy                           0.70      1600\n",
      "   macro avg       0.70      0.70      0.70      1600\n",
      "weighted avg       0.71      0.70      0.71      1600\n",
      "\n",
      "Random Forest classifier (best)\n",
      "F1 macro:  0.6836164102588489\n",
      "Accuracy:  0.688125\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.69      0.72       940\n",
      "           1       0.61      0.69      0.65       660\n",
      "\n",
      "    accuracy                           0.69      1600\n",
      "   macro avg       0.68      0.69      0.68      1600\n",
      "weighted avg       0.70      0.69      0.69      1600\n",
      "\n",
      "Random Forest classifier\n",
      "F1 macro:  0.6899299299299299\n",
      "Accuracy:  0.6975\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.73      0.74       940\n",
      "           1       0.63      0.66      0.64       660\n",
      "\n",
      "    accuracy                           0.70      1600\n",
      "   macro avg       0.69      0.69      0.69      1600\n",
      "weighted avg       0.70      0.70      0.70      1600\n",
      "\n",
      "Support Vector Classification (best)\n",
      "F1 macro:  0.6940648906139171\n",
      "Accuracy:  0.69875\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.70      0.73       940\n",
      "           1       0.62      0.70      0.66       660\n",
      "\n",
      "    accuracy                           0.70      1600\n",
      "   macro avg       0.69      0.70      0.69      1600\n",
      "weighted avg       0.71      0.70      0.70      1600\n",
      "\n",
      "Support Vector Classification\n",
      "F1 macro:  0.697842099802884\n",
      "Accuracy:  0.70875\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.76      0.76       940\n",
      "           1       0.65      0.63      0.64       660\n",
      "\n",
      "    accuracy                           0.71      1600\n",
      "   macro avg       0.70      0.70      0.70      1600\n",
      "weighted avg       0.71      0.71      0.71      1600\n",
      "\n",
      "AdaBoost classifier (best)\n",
      "F1 macro:  0.6772945138869196\n",
      "Accuracy:  0.684375\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.71      0.73       940\n",
      "           1       0.61      0.65      0.63       660\n",
      "\n",
      "    accuracy                           0.68      1600\n",
      "   macro avg       0.68      0.68      0.68      1600\n",
      "weighted avg       0.69      0.68      0.69      1600\n",
      "\n",
      "AdaBoost classifier\n",
      "F1 macro:  0.6641874509546015\n",
      "Accuracy:  0.676875\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73       940\n",
      "           1       0.61      0.58      0.60       660\n",
      "\n",
      "    accuracy                           0.68      1600\n",
      "   macro avg       0.67      0.66      0.66      1600\n",
      "weighted avg       0.67      0.68      0.68      1600\n",
      "\n",
      "Multi-layer Perceptron classifier (best)\n",
      "F1 macro:  0.7001459541173549\n",
      "Accuracy:  0.708125\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.74      0.75       940\n",
      "           1       0.64      0.66      0.65       660\n",
      "\n",
      "    accuracy                           0.71      1600\n",
      "   macro avg       0.70      0.70      0.70      1600\n",
      "weighted avg       0.71      0.71      0.71      1600\n",
      "\n",
      "Multi-layer Perceptron classifier\n",
      "F1 macro:  0.6975079806405107\n",
      "Accuracy:  0.70625\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75       940\n",
      "           1       0.64      0.65      0.65       660\n",
      "\n",
      "    accuracy                           0.71      1600\n",
      "   macro avg       0.70      0.70      0.70      1600\n",
      "weighted avg       0.71      0.71      0.71      1600\n",
      "\n",
      "Dummy Classifier\n",
      "F1 macro:  0.0\n",
      "Accuracy:  0.6747292418772564\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.81      1869\n",
      "           1       0.00      0.00      0.00       901\n",
      "\n",
      "    accuracy                           0.67      2770\n",
      "   macro avg       0.34      0.50      0.40      2770\n",
      "weighted avg       0.46      0.67      0.54      2770\n",
      "\n",
      "Dummy Classifier (best)\n",
      "F1 macro:  0.49087442113865437\n",
      "Accuracy:  0.3252707581227437\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1869\n",
      "           1       0.33      1.00      0.49       901\n",
      "\n",
      "    accuracy                           0.33      2770\n",
      "   macro avg       0.16      0.50      0.25      2770\n",
      "weighted avg       0.11      0.33      0.16      2770\n",
      "\n",
      "Multinomial Naive Bayes classifier\n",
      "F1 macro:  0.27011494252873564\n",
      "Accuracy:  0.7249097472924187\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83      1869\n",
      "           1       0.99      0.16      0.27       901\n",
      "\n",
      "    accuracy                           0.72      2770\n",
      "   macro avg       0.85      0.58      0.55      2770\n",
      "weighted avg       0.80      0.72      0.65      2770\n",
      "\n",
      "Multinomial Naive Bayes classifier (best)\n",
      "F1 macro:  0.7724867724867724\n",
      "Accuracy:  0.8758122743682311\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.99      0.91      1869\n",
      "           1       0.96      0.65      0.77       901\n",
      "\n",
      "    accuracy                           0.88      2770\n",
      "   macro avg       0.90      0.82      0.84      2770\n",
      "weighted avg       0.89      0.88      0.87      2770\n",
      "\n",
      "Bernoulli Naive Bayes classifier\n",
      "F1 macro:  0.6634549208534066\n",
      "Accuracy:  0.8234657039711192\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.96      0.88      1869\n",
      "           1       0.87      0.53      0.66       901\n",
      "\n",
      "    accuracy                           0.82      2770\n",
      "   macro avg       0.84      0.75      0.77      2770\n",
      "weighted avg       0.83      0.82      0.81      2770\n",
      "\n",
      "Bernoulli Naive Bayes classifier (best)\n",
      "F1 macro:  0.7614068441064639\n",
      "Accuracy:  0.8187725631768953\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.78      0.85      1869\n",
      "           1       0.67      0.89      0.76       901\n",
      "\n",
      "    accuracy                           0.82      2770\n",
      "   macro avg       0.80      0.84      0.81      2770\n",
      "weighted avg       0.85      0.82      0.82      2770\n",
      "\n",
      "Ridge Classifier\n",
      "F1 macro:  0.8249522597071928\n",
      "Accuracy:  0.9007220216606499\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93      1869\n",
      "           1       0.97      0.72      0.82       901\n",
      "\n",
      "    accuracy                           0.90      2770\n",
      "   macro avg       0.92      0.85      0.88      2770\n",
      "weighted avg       0.91      0.90      0.90      2770\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Classifier (best)\n",
      "F1 macro:  0.9572162007986309\n",
      "Accuracy:  0.9729241877256317\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      1869\n",
      "           1       0.98      0.93      0.96       901\n",
      "\n",
      "    accuracy                           0.97      2770\n",
      "   macro avg       0.98      0.96      0.97      2770\n",
      "weighted avg       0.97      0.97      0.97      2770\n",
      "\n",
      "Random Forest classifier\n",
      "F1 macro:  0.9779785431959345\n",
      "Accuracy:  0.9859205776173285\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1869\n",
      "           1       1.00      0.96      0.98       901\n",
      "\n",
      "    accuracy                           0.99      2770\n",
      "   macro avg       0.99      0.98      0.98      2770\n",
      "weighted avg       0.99      0.99      0.99      2770\n",
      "\n",
      "Random Forest classifier (best)\n",
      "F1 macro:  0.7264094955489615\n",
      "Accuracy:  0.8335740072202166\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88      1869\n",
      "           1       0.78      0.68      0.73       901\n",
      "\n",
      "    accuracy                           0.83      2770\n",
      "   macro avg       0.82      0.79      0.80      2770\n",
      "weighted avg       0.83      0.83      0.83      2770\n",
      "\n",
      "Support Vector Classification\n",
      "F1 macro:  0.8661219358893777\n",
      "Accuracy:  0.9231046931407942\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      1869\n",
      "           1       1.00      0.76      0.87       901\n",
      "\n",
      "    accuracy                           0.92      2770\n",
      "   macro avg       0.95      0.88      0.91      2770\n",
      "weighted avg       0.93      0.92      0.92      2770\n",
      "\n",
      "Support Vector Classification (best)\n",
      "F1 macro:  0.8866213151927437\n",
      "Accuracy:  0.927797833935018\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95      1869\n",
      "           1       0.91      0.87      0.89       901\n",
      "\n",
      "    accuracy                           0.93      2770\n",
      "   macro avg       0.92      0.91      0.92      2770\n",
      "weighted avg       0.93      0.93      0.93      2770\n",
      "\n",
      "AdaBoost classifier\n",
      "F1 macro:  0.3043478260869565\n",
      "Accuracy:  0.7111913357400722\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.96      0.82      1869\n",
      "           1       0.70      0.19      0.30       901\n",
      "\n",
      "    accuracy                           0.71      2770\n",
      "   macro avg       0.71      0.58      0.56      2770\n",
      "weighted avg       0.71      0.71      0.65      2770\n",
      "\n",
      "AdaBoost classifier (best)\n",
      "F1 macro:  0.4926189174412247\n",
      "Accuracy:  0.32996389891696754\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.01      0.01      1869\n",
      "           1       0.33      1.00      0.49       901\n",
      "\n",
      "    accuracy                           0.33      2770\n",
      "   macro avg       0.66      0.50      0.25      2770\n",
      "weighted avg       0.78      0.33      0.17      2770\n",
      "\n",
      "Multi-layer Perceptron classifier\n",
      "F1 macro:  0.037037037037037035\n",
      "Accuracy:  0.6808664259927798\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      1.00      0.81      1869\n",
      "           1       1.00      0.02      0.04       901\n",
      "\n",
      "    accuracy                           0.68      2770\n",
      "   macro avg       0.84      0.51      0.42      2770\n",
      "weighted avg       0.78      0.68      0.56      2770\n",
      "\n",
      "Multi-layer Perceptron classifier (best)\n",
      "F1 macro:  0.0\n",
      "Accuracy:  0.6747292418772564\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.81      1869\n",
      "           1       0.00      0.00      0.00       901\n",
      "\n",
      "    accuracy                           0.67      2770\n",
      "   macro avg       0.34      0.50      0.40      2770\n",
      "weighted avg       0.46      0.67      0.54      2770\n",
      "\n",
      "Dummy Classifier\n",
      "F1 macro:  0.0\n",
      "Accuracy:  0.645021645021645\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      1.00      0.78       447\n",
      "           1       0.00      0.00      0.00       246\n",
      "\n",
      "    accuracy                           0.65       693\n",
      "   macro avg       0.32      0.50      0.39       693\n",
      "weighted avg       0.42      0.65      0.51       693\n",
      "\n",
      "Dummy Classifier (best)\n",
      "F1 macro:  0.5239616613418531\n",
      "Accuracy:  0.354978354978355\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       447\n",
      "           1       0.35      1.00      0.52       246\n",
      "\n",
      "    accuracy                           0.35       693\n",
      "   macro avg       0.18      0.50      0.26       693\n",
      "weighted avg       0.13      0.35      0.19       693\n",
      "\n",
      "Multinomial Naive Bayes classifier\n",
      "F1 macro:  0.0316205533596838\n",
      "Accuracy:  0.6464646464646465\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.99      0.78       447\n",
      "           1       0.57      0.02      0.03       246\n",
      "\n",
      "    accuracy                           0.65       693\n",
      "   macro avg       0.61      0.50      0.41       693\n",
      "weighted avg       0.62      0.65      0.52       693\n",
      "\n",
      "Multinomial Naive Bayes classifier (best)\n",
      "F1 macro:  0.19692307692307695\n",
      "Accuracy:  0.6233766233766234\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.89      0.75       447\n",
      "           1       0.41      0.13      0.20       246\n",
      "\n",
      "    accuracy                           0.62       693\n",
      "   macro avg       0.53      0.51      0.48       693\n",
      "weighted avg       0.56      0.62      0.56       693\n",
      "\n",
      "Bernoulli Naive Bayes classifier\n",
      "F1 macro:  0.21604938271604937\n",
      "Accuracy:  0.6334776334776335\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.90      0.76       447\n",
      "           1       0.45      0.14      0.22       246\n",
      "\n",
      "    accuracy                           0.63       693\n",
      "   macro avg       0.55      0.52      0.49       693\n",
      "weighted avg       0.58      0.63      0.57       693\n",
      "\n",
      "Bernoulli Naive Bayes classifier (best)\n",
      "F1 macro:  0.3614457831325302\n",
      "Accuracy:  0.5411255411255411\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.64      0.64       447\n",
      "           1       0.36      0.37      0.36       246\n",
      "\n",
      "    accuracy                           0.54       693\n",
      "   macro avg       0.50      0.50      0.50       693\n",
      "weighted avg       0.54      0.54      0.54       693\n",
      "\n",
      "Ridge Classifier\n",
      "F1 macro:  0.26038781163434904\n",
      "Accuracy:  0.6147186147186147\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.85      0.74       447\n",
      "           1       0.41      0.19      0.26       246\n",
      "\n",
      "    accuracy                           0.61       693\n",
      "   macro avg       0.53      0.52      0.50       693\n",
      "weighted avg       0.57      0.61      0.57       693\n",
      "\n",
      "Ridge Classifier (best)\n",
      "F1 macro:  0.3584070796460177\n",
      "Accuracy:  0.5815295815295816\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.72      0.69       447\n",
      "           1       0.39      0.33      0.36       246\n",
      "\n",
      "    accuracy                           0.58       693\n",
      "   macro avg       0.53      0.52      0.52       693\n",
      "weighted avg       0.57      0.58      0.57       693\n",
      "\n",
      "Random Forest classifier\n",
      "F1 macro:  0.15384615384615385\n",
      "Accuracy:  0.6190476190476191\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.91      0.75       447\n",
      "           1       0.36      0.10      0.15       246\n",
      "\n",
      "    accuracy                           0.62       693\n",
      "   macro avg       0.50      0.50      0.45       693\n",
      "weighted avg       0.55      0.62      0.54       693\n",
      "\n",
      "Random Forest classifier (best)\n",
      "F1 macro:  0.37168141592920356\n",
      "Accuracy:  0.5901875901875901\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.73      0.70       447\n",
      "           1       0.41      0.34      0.37       246\n",
      "\n",
      "    accuracy                           0.59       693\n",
      "   macro avg       0.54      0.53      0.53       693\n",
      "weighted avg       0.58      0.59      0.58       693\n",
      "\n",
      "Support Vector Classification\n",
      "F1 macro:  0.023809523809523808\n",
      "Accuracy:  0.645021645021645\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.99      0.78       447\n",
      "           1       0.50      0.01      0.02       246\n",
      "\n",
      "    accuracy                           0.65       693\n",
      "   macro avg       0.57      0.50      0.40       693\n",
      "weighted avg       0.59      0.65      0.51       693\n",
      "\n",
      "Support Vector Classification (best)\n",
      "F1 macro:  0.35528942115768464\n",
      "Accuracy:  0.5339105339105339\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.63      0.64       447\n",
      "           1       0.35      0.36      0.36       246\n",
      "\n",
      "    accuracy                           0.53       693\n",
      "   macro avg       0.50      0.50      0.50       693\n",
      "weighted avg       0.54      0.53      0.54       693\n",
      "\n",
      "AdaBoost classifier\n",
      "F1 macro:  0.169811320754717\n",
      "Accuracy:  0.6190476190476191\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.90      0.75       447\n",
      "           1       0.38      0.11      0.17       246\n",
      "\n",
      "    accuracy                           0.62       693\n",
      "   macro avg       0.51      0.50      0.46       693\n",
      "weighted avg       0.55      0.62      0.55       693\n",
      "\n",
      "AdaBoost classifier (best)\n",
      "F1 macro:  0.5208110992529349\n",
      "Accuracy:  0.35209235209235207\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       447\n",
      "           1       0.35      0.99      0.52       246\n",
      "\n",
      "    accuracy                           0.35       693\n",
      "   macro avg       0.18      0.50      0.26       693\n",
      "weighted avg       0.13      0.35      0.18       693\n",
      "\n",
      "Multi-layer Perceptron classifier\n",
      "F1 macro:  0.0\n",
      "Accuracy:  0.6421356421356421\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      1.00      0.78       447\n",
      "           1       0.00      0.00      0.00       246\n",
      "\n",
      "    accuracy                           0.64       693\n",
      "   macro avg       0.32      0.50      0.39       693\n",
      "weighted avg       0.42      0.64      0.50       693\n",
      "\n",
      "Multi-layer Perceptron classifier (best)\n",
      "F1 macro:  0.0\n",
      "Accuracy:  0.645021645021645\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      1.00      0.78       447\n",
      "           1       0.00      0.00      0.00       246\n",
      "\n",
      "    accuracy                           0.65       693\n",
      "   macro avg       0.32      0.50      0.39       693\n",
      "weighted avg       0.42      0.65      0.51       693\n",
      "\n",
      "Dummy Classifier\n",
      "F1 macro:  None\n",
      "Accuracy:  None\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      " None\n",
      "Dummy Classifier (best)\n",
      "F1 macro:  None\n",
      "Accuracy:  None\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      " None\n",
      "Multinomial Naive Bayes classifier\n",
      "F1 macro:  None\n",
      "Accuracy:  None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Ferran\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      " None\n",
      "Multinomial Naive Bayes classifier (best)\n",
      "F1 macro:  None\n",
      "Accuracy:  None\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      " None\n",
      "Bernoulli Naive Bayes classifier\n",
      "F1 macro:  None\n",
      "Accuracy:  None\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      " None\n",
      "Bernoulli Naive Bayes classifier (best)\n",
      "F1 macro:  None\n",
      "Accuracy:  None\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      " None\n",
      "Ridge Classifier\n",
      "F1 macro:  None\n",
      "Accuracy:  None\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      " None\n",
      "Ridge Classifier (best)\n",
      "F1 macro:  None\n",
      "Accuracy:  None\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      " None\n",
      "Random Forest classifier\n",
      "F1 macro:  None\n",
      "Accuracy:  None\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      " None\n",
      "Random Forest classifier (best)\n",
      "F1 macro:  None\n",
      "Accuracy:  None\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      " None\n",
      "Support Vector Classification\n",
      "F1 macro:  None\n",
      "Accuracy:  None\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      " None\n",
      "Support Vector Classification (best)\n",
      "F1 macro:  None\n",
      "Accuracy:  None\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      " None\n",
      "AdaBoost classifier\n",
      "F1 macro:  None\n",
      "Accuracy:  None\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      " None\n",
      "AdaBoost classifier (best)\n",
      "F1 macro:  None\n",
      "Accuracy:  None\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      " None\n",
      "Multi-layer Perceptron classifier\n",
      "F1 macro:  None\n",
      "Accuracy:  None\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      " None\n",
      "Multi-layer Perceptron classifier (best)\n",
      "F1 macro:  None\n",
      "Accuracy:  None\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      " None\n",
      "Bert base (3 epochs)\n",
      "F1 macro:  0.8589894242068155\n",
      "Accuracy:  0.9133574007220217\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.94      1869\n",
      "           1       0.91      0.81      0.86       901\n",
      "\n",
      "    accuracy                           0.91      2770\n",
      "   macro avg       0.91      0.89      0.90      2770\n",
      "weighted avg       0.91      0.91      0.91      2770\n",
      "\n",
      "Bert base (3 epochs)\n",
      "F1 macro:  0.6547085201793722\n",
      "Accuracy:  0.7777777777777778\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.88      0.84       447\n",
      "           1       0.73      0.59      0.65       246\n",
      "\n",
      "    accuracy                           0.78       693\n",
      "   macro avg       0.76      0.74      0.75       693\n",
      "weighted avg       0.77      0.78      0.77       693\n",
      "\n",
      "Bert base (3 epochs)\n",
      "F1 macro:  None\n",
      "Accuracy:  None\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      " None\n",
      "Bert base (2 epochs)\n",
      "F1 macro:  0.6709429121231558\n",
      "Accuracy:  0.8148014440433213\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87      1869\n",
      "           1       0.79      0.58      0.67       901\n",
      "\n",
      "    accuracy                           0.81      2770\n",
      "   macro avg       0.81      0.75      0.77      2770\n",
      "weighted avg       0.81      0.81      0.81      2770\n",
      "\n",
      "Bert base (2 epochs)\n",
      "F1 macro:  0.6128266033254156\n",
      "Accuracy:  0.7647907647907648\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.90      0.83       447\n",
      "           1       0.74      0.52      0.61       246\n",
      "\n",
      "    accuracy                           0.76       693\n",
      "   macro avg       0.76      0.71      0.72       693\n",
      "weighted avg       0.76      0.76      0.75       693\n",
      "\n",
      "Bert base (2 epochs)\n",
      "F1 macro:  None\n",
      "Accuracy:  None\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      " None\n",
      "MLP polynom_fit_SMOTE\n",
      "F1 macro:  0.9195784803105935\n",
      "Accuracy:  0.9476534296028881\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1869\n",
      "           1       0.92      0.92      0.92       901\n",
      "\n",
      "    accuracy                           0.95      2770\n",
      "   macro avg       0.94      0.94      0.94      2770\n",
      "weighted avg       0.95      0.95      0.95      2770\n",
      "\n",
      "MLP ProWSyn\n",
      "F1 macro:  0.9267480577136515\n",
      "Accuracy:  0.9523465703971119\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1869\n",
      "           1       0.93      0.93      0.93       901\n",
      "\n",
      "    accuracy                           0.95      2770\n",
      "   macro avg       0.95      0.95      0.95      2770\n",
      "weighted avg       0.95      0.95      0.95      2770\n",
      "\n",
      "MLP SMOTE_IPF\n",
      "F1 macro:  0.8810572687224669\n",
      "Accuracy:  0.9220216606498195\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94      1869\n",
      "           1       0.87      0.89      0.88       901\n",
      "\n",
      "    accuracy                           0.92      2770\n",
      "   macro avg       0.91      0.91      0.91      2770\n",
      "weighted avg       0.92      0.92      0.92      2770\n",
      "\n",
      "MLP SMOBD\n",
      "F1 macro:  0.9523287671232876\n",
      "Accuracy:  0.9685920577617328\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98      1869\n",
      "           1       0.94      0.96      0.95       901\n",
      "\n",
      "    accuracy                           0.97      2770\n",
      "   macro avg       0.96      0.97      0.96      2770\n",
      "weighted avg       0.97      0.97      0.97      2770\n",
      "\n",
      "MLP G_SMOTE\n",
      "F1 macro:  0.9238521836506158\n",
      "Accuracy:  0.9509025270758122\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      1869\n",
      "           1       0.93      0.92      0.92       901\n",
      "\n",
      "    accuracy                           0.95      2770\n",
      "   macro avg       0.95      0.94      0.94      2770\n",
      "weighted avg       0.95      0.95      0.95      2770\n",
      "\n",
      "MLP CCR\n",
      "F1 macro:  0.11921891058581706\n",
      "Accuracy:  0.6906137184115524\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.99      0.81      1869\n",
      "           1       0.81      0.06      0.12       901\n",
      "\n",
      "    accuracy                           0.69      2770\n",
      "   macro avg       0.75      0.53      0.47      2770\n",
      "weighted avg       0.73      0.69      0.59      2770\n",
      "\n",
      "MLP LVQ_SMOTE\n",
      "F1 macro:  0.6957507082152974\n",
      "Accuracy:  0.8061371841155235\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86      1869\n",
      "           1       0.71      0.68      0.70       901\n",
      "\n",
      "    accuracy                           0.81      2770\n",
      "   macro avg       0.78      0.77      0.78      2770\n",
      "weighted avg       0.80      0.81      0.81      2770\n",
      "\n",
      "MLP Assembled_SMOTE\n",
      "F1 macro:  0.7293419099455716\n",
      "Accuracy:  0.8025270758122743\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.80      0.84      1869\n",
      "           1       0.66      0.82      0.73       901\n",
      "\n",
      "    accuracy                           0.80      2770\n",
      "   macro avg       0.78      0.81      0.79      2770\n",
      "weighted avg       0.82      0.80      0.81      2770\n",
      "\n",
      "MLP SMOTE_TomekLinks\n",
      "F1 macro:  0.7434827945776851\n",
      "Accuracy:  0.8223826714801444\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.84      0.86      1869\n",
      "           1       0.70      0.79      0.74       901\n",
      "\n",
      "    accuracy                           0.82      2770\n",
      "   macro avg       0.80      0.81      0.80      2770\n",
      "weighted avg       0.83      0.82      0.82      2770\n",
      "\n",
      "MLP polynom_fit_SMOTE\n",
      "F1 macro:  0.6\n",
      "Accuracy:  0.7229437229437229\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.80      0.79       447\n",
      "           1       0.62      0.59      0.60       246\n",
      "\n",
      "    accuracy                           0.72       693\n",
      "   macro avg       0.70      0.69      0.69       693\n",
      "weighted avg       0.72      0.72      0.72       693\n",
      "\n",
      "MLP ProWSyn\n",
      "F1 macro:  0.6004140786749482\n",
      "Accuracy:  0.7215007215007215\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.79      0.79       447\n",
      "           1       0.61      0.59      0.60       246\n",
      "\n",
      "    accuracy                           0.72       693\n",
      "   macro avg       0.70      0.69      0.69       693\n",
      "weighted avg       0.72      0.72      0.72       693\n",
      "\n",
      "MLP SMOTE_IPF\n",
      "F1 macro:  0.6198347107438016\n",
      "Accuracy:  0.7344877344877345\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80       447\n",
      "           1       0.63      0.61      0.62       246\n",
      "\n",
      "    accuracy                           0.73       693\n",
      "   macro avg       0.71      0.71      0.71       693\n",
      "weighted avg       0.73      0.73      0.73       693\n",
      "\n",
      "MLP SMOBD\n",
      "F1 macro:  0.6297872340425532\n",
      "Accuracy:  0.7489177489177489\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81       447\n",
      "           1       0.66      0.60      0.63       246\n",
      "\n",
      "    accuracy                           0.75       693\n",
      "   macro avg       0.73      0.72      0.72       693\n",
      "weighted avg       0.74      0.75      0.75       693\n",
      "\n",
      "MLP G_SMOTE\n",
      "F1 macro:  0.613390928725702\n",
      "Accuracy:  0.7417027417027418\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.83      0.81       447\n",
      "           1       0.65      0.58      0.61       246\n",
      "\n",
      "    accuracy                           0.74       693\n",
      "   macro avg       0.72      0.70      0.71       693\n",
      "weighted avg       0.74      0.74      0.74       693\n",
      "\n",
      "MLP CCR\n",
      "F1 macro:  0.09125475285171103\n",
      "Accuracy:  0.6551226551226551\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.99      0.79       447\n",
      "           1       0.71      0.05      0.09       246\n",
      "\n",
      "    accuracy                           0.66       693\n",
      "   macro avg       0.68      0.52      0.44       693\n",
      "weighted avg       0.67      0.66      0.54       693\n",
      "\n",
      "MLP LVQ_SMOTE\n",
      "F1 macro:  0.6234309623430963\n",
      "Accuracy:  0.7402597402597403\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80       447\n",
      "           1       0.64      0.61      0.62       246\n",
      "\n",
      "    accuracy                           0.74       693\n",
      "   macro avg       0.72      0.71      0.71       693\n",
      "weighted avg       0.74      0.74      0.74       693\n",
      "\n",
      "MLP Assembled_SMOTE\n",
      "F1 macro:  0.633147113594041\n",
      "Accuracy:  0.7157287157287158\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.73      0.77       447\n",
      "           1       0.58      0.69      0.63       246\n",
      "\n",
      "    accuracy                           0.72       693\n",
      "   macro avg       0.70      0.71      0.70       693\n",
      "weighted avg       0.73      0.72      0.72       693\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP SMOTE_TomekLinks\n",
      "F1 macro:  0.6601941747572816\n",
      "Accuracy:  0.7474747474747475\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.78      0.80       447\n",
      "           1       0.63      0.69      0.66       246\n",
      "\n",
      "    accuracy                           0.75       693\n",
      "   macro avg       0.73      0.73      0.73       693\n",
      "weighted avg       0.75      0.75      0.75       693\n",
      "\n",
      "MLP polynom_fit_SMOTE\n",
      "F1 macro:  None\n",
      "Accuracy:  None\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      " None\n",
      "MLP ProWSyn\n",
      "F1 macro:  None\n",
      "Accuracy:  None\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      " None\n",
      "MLP SMOTE_IPF\n",
      "F1 macro:  None\n",
      "Accuracy:  None\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      " None\n",
      "MLP SMOBD\n",
      "F1 macro:  None\n",
      "Accuracy:  None\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      " None\n",
      "MLP G_SMOTE\n",
      "F1 macro:  None\n",
      "Accuracy:  None\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      " None\n",
      "MLP CCR\n",
      "F1 macro:  None\n",
      "Accuracy:  None\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      " None\n",
      "MLP LVQ_SMOTE\n",
      "F1 macro:  None\n",
      "Accuracy:  None\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      " None\n",
      "MLP Assembled_SMOTE\n",
      "F1 macro:  None\n",
      "Accuracy:  None\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      " None\n",
      "MLP SMOTE_TomekLinks\n",
      "F1 macro:  None\n",
      "Accuracy:  None\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      " None\n",
      "SVC polynom_fit_SMOTE\n",
      "F1 macro:  0.8654680719156851\n",
      "Accuracy:  0.9216606498194946\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94      1869\n",
      "           1       0.98      0.77      0.87       901\n",
      "\n",
      "    accuracy                           0.92      2770\n",
      "   macro avg       0.94      0.88      0.91      2770\n",
      "weighted avg       0.93      0.92      0.92      2770\n",
      "\n",
      "SVC ProWSyn\n",
      "F1 macro:  0.903755868544601\n",
      "Accuracy:  0.9407942238267148\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96      1869\n",
      "           1       0.96      0.85      0.90       901\n",
      "\n",
      "    accuracy                           0.94      2770\n",
      "   macro avg       0.95      0.92      0.93      2770\n",
      "weighted avg       0.94      0.94      0.94      2770\n",
      "\n",
      "SVC SMOTE_IPF\n",
      "F1 macro:  0.913268236645606\n",
      "Accuracy:  0.9454873646209386\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96      1869\n",
      "           1       0.95      0.88      0.91       901\n",
      "\n",
      "    accuracy                           0.95      2770\n",
      "   macro avg       0.95      0.93      0.94      2770\n",
      "weighted avg       0.95      0.95      0.94      2770\n",
      "\n",
      "SVC SMOBD\n",
      "F1 macro:  0.9052268811028144\n",
      "Accuracy:  0.9404332129963899\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96      1869\n",
      "           1       0.94      0.87      0.91       901\n",
      "\n",
      "    accuracy                           0.94      2770\n",
      "   macro avg       0.94      0.92      0.93      2770\n",
      "weighted avg       0.94      0.94      0.94      2770\n",
      "\n",
      "SVC G_SMOTE\n",
      "F1 macro:  0.9073114565342544\n",
      "Accuracy:  0.9418772563176895\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96      1869\n",
      "           1       0.94      0.87      0.91       901\n",
      "\n",
      "    accuracy                           0.94      2770\n",
      "   macro avg       0.94      0.92      0.93      2770\n",
      "weighted avg       0.94      0.94      0.94      2770\n",
      "\n",
      "SVC CCR\n",
      "F1 macro:  0.04125950054288817\n",
      "Accuracy:  0.6812274368231047\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      1.00      0.81      1869\n",
      "           1       0.95      0.02      0.04       901\n",
      "\n",
      "    accuracy                           0.68      2770\n",
      "   macro avg       0.81      0.51      0.43      2770\n",
      "weighted avg       0.77      0.68      0.56      2770\n",
      "\n",
      "SVC LVQ_SMOTE\n",
      "F1 macro:  0.849502487562189\n",
      "Accuracy:  0.9126353790613718\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94      1869\n",
      "           1       0.97      0.76      0.85       901\n",
      "\n",
      "    accuracy                           0.91      2770\n",
      "   macro avg       0.93      0.87      0.89      2770\n",
      "weighted avg       0.92      0.91      0.91      2770\n",
      "\n",
      "SVC Assembled_SMOTE\n",
      "F1 macro:  0.9109707064905227\n",
      "Accuracy:  0.944043321299639\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96      1869\n",
      "           1       0.94      0.88      0.91       901\n",
      "\n",
      "    accuracy                           0.94      2770\n",
      "   macro avg       0.94      0.93      0.94      2770\n",
      "weighted avg       0.94      0.94      0.94      2770\n",
      "\n",
      "SVC SMOTE_TomekLinks\n",
      "F1 macro:  0.9094036697247706\n",
      "Accuracy:  0.9429602888086642\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96      1869\n",
      "           1       0.94      0.88      0.91       901\n",
      "\n",
      "    accuracy                           0.94      2770\n",
      "   macro avg       0.94      0.93      0.93      2770\n",
      "weighted avg       0.94      0.94      0.94      2770\n",
      "\n",
      "SVC polynom_fit_SMOTE\n",
      "F1 macro:  0.5638297872340425\n",
      "Accuracy:  0.7633477633477633\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.95      0.84       447\n",
      "           1       0.82      0.43      0.56       246\n",
      "\n",
      "    accuracy                           0.76       693\n",
      "   macro avg       0.78      0.69      0.70       693\n",
      "weighted avg       0.77      0.76      0.74       693\n",
      "\n",
      "SVC ProWSyn\n",
      "F1 macro:  0.6120481927710844\n",
      "Accuracy:  0.7676767676767676\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.91      0.83       447\n",
      "           1       0.75      0.52      0.61       246\n",
      "\n",
      "    accuracy                           0.77       693\n",
      "   macro avg       0.76      0.71      0.72       693\n",
      "weighted avg       0.77      0.77      0.76       693\n",
      "\n",
      "SVC SMOTE_IPF\n",
      "F1 macro:  0.6161137440758293\n",
      "Accuracy:  0.7662337662337663\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.90      0.83       447\n",
      "           1       0.74      0.53      0.62       246\n",
      "\n",
      "    accuracy                           0.77       693\n",
      "   macro avg       0.76      0.71      0.72       693\n",
      "weighted avg       0.76      0.77      0.76       693\n",
      "\n",
      "SVC SMOBD\n",
      "F1 macro:  0.6255924170616114\n",
      "Accuracy:  0.772005772005772\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.90      0.84       447\n",
      "           1       0.75      0.54      0.63       246\n",
      "\n",
      "    accuracy                           0.77       693\n",
      "   macro avg       0.76      0.72      0.73       693\n",
      "weighted avg       0.77      0.77      0.76       693\n",
      "\n",
      "SVC G_SMOTE\n",
      "F1 macro:  0.620525059665871\n",
      "Accuracy:  0.7705627705627706\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.90      0.84       447\n",
      "           1       0.75      0.53      0.62       246\n",
      "\n",
      "    accuracy                           0.77       693\n",
      "   macro avg       0.76      0.72      0.73       693\n",
      "weighted avg       0.77      0.77      0.76       693\n",
      "\n",
      "SVC CCR\n",
      "F1 macro:  0.032\n",
      "Accuracy:  0.6507936507936508\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      1.00      0.79       447\n",
      "           1       1.00      0.02      0.03       246\n",
      "\n",
      "    accuracy                           0.65       693\n",
      "   macro avg       0.82      0.51      0.41       693\n",
      "weighted avg       0.77      0.65      0.52       693\n",
      "\n",
      "SVC LVQ_SMOTE\n",
      "F1 macro:  0.5796344647519583\n",
      "Accuracy:  0.7676767676767676\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.94      0.84       447\n",
      "           1       0.81      0.45      0.58       246\n",
      "\n",
      "    accuracy                           0.77       693\n",
      "   macro avg       0.78      0.70      0.71       693\n",
      "weighted avg       0.78      0.77      0.75       693\n",
      "\n",
      "SVC Assembled_SMOTE\n",
      "F1 macro:  0.6076555023923446\n",
      "Accuracy:  0.7633477633477633\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.90      0.83       447\n",
      "           1       0.74      0.52      0.61       246\n",
      "\n",
      "    accuracy                           0.76       693\n",
      "   macro avg       0.75      0.71      0.72       693\n",
      "weighted avg       0.76      0.76      0.75       693\n",
      "\n",
      "SVC SMOTE_TomekLinks\n",
      "F1 macro:  0.6043165467625898\n",
      "Accuracy:  0.7619047619047619\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.90      0.83       447\n",
      "           1       0.74      0.51      0.60       246\n",
      "\n",
      "    accuracy                           0.76       693\n",
      "   macro avg       0.75      0.71      0.72       693\n",
      "weighted avg       0.76      0.76      0.75       693\n",
      "\n",
      "SVC polynom_fit_SMOTE\n",
      "F1 macro:  None\n",
      "Accuracy:  None\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      " None\n",
      "SVC ProWSyn\n",
      "F1 macro:  None\n",
      "Accuracy:  None\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      " None\n",
      "SVC SMOTE_IPF\n",
      "F1 macro:  None\n",
      "Accuracy:  None\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      " None\n",
      "SVC SMOBD\n",
      "F1 macro:  None\n",
      "Accuracy:  None\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      " None\n",
      "SVC G_SMOTE\n",
      "F1 macro:  None\n",
      "Accuracy:  None\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      " None\n",
      "SVC CCR\n",
      "F1 macro:  None\n",
      "Accuracy:  None\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      " None\n",
      "SVC LVQ_SMOTE\n",
      "F1 macro:  None\n",
      "Accuracy:  None\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      " None\n",
      "SVC Assembled_SMOTE\n",
      "F1 macro:  None\n",
      "Accuracy:  None\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      " None\n",
      "SVC SMOTE_TomekLinks\n",
      "F1 macro:  None\n",
      "Accuracy:  None\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      " None\n",
      "Ridge polynom_fit_SMOTE\n",
      "F1 macro:  0.6940222897669707\n",
      "Accuracy:  0.7819494584837545\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.79      0.83      1869\n",
      "           1       0.64      0.76      0.69       901\n",
      "\n",
      "    accuracy                           0.78      2770\n",
      "   macro avg       0.76      0.78      0.76      2770\n",
      "weighted avg       0.80      0.78      0.79      2770\n",
      "\n",
      "Ridge ProWSyn\n",
      "F1 macro:  0.6933603649265078\n",
      "Accuracy:  0.7815884476534296\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.79      0.83      1869\n",
      "           1       0.64      0.76      0.69       901\n",
      "\n",
      "    accuracy                           0.78      2770\n",
      "   macro avg       0.76      0.78      0.76      2770\n",
      "weighted avg       0.80      0.78      0.79      2770\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge SMOTE_IPF\n",
      "F1 macro:  0.6888552697932425\n",
      "Accuracy:  0.7772563176895307\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.79      0.83      1869\n",
      "           1       0.63      0.76      0.69       901\n",
      "\n",
      "    accuracy                           0.78      2770\n",
      "   macro avg       0.75      0.77      0.76      2770\n",
      "weighted avg       0.79      0.78      0.78      2770\n",
      "\n",
      "Ridge SMOBD\n",
      "F1 macro:  0.6927318295739348\n",
      "Accuracy:  0.7787003610108303\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.78      0.83      1869\n",
      "           1       0.63      0.77      0.69       901\n",
      "\n",
      "    accuracy                           0.78      2770\n",
      "   macro avg       0.75      0.78      0.76      2770\n",
      "weighted avg       0.80      0.78      0.78      2770\n",
      "\n",
      "Ridge G_SMOTE\n",
      "F1 macro:  0.694331983805668\n",
      "Accuracy:  0.7819494584837545\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.79      0.83      1869\n",
      "           1       0.64      0.76      0.69       901\n",
      "\n",
      "    accuracy                           0.78      2770\n",
      "   macro avg       0.76      0.78      0.76      2770\n",
      "weighted avg       0.80      0.78      0.79      2770\n",
      "\n",
      "Ridge CCR\n",
      "F1 macro:  0.39089481946624804\n",
      "Accuracy:  0.71985559566787\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.93      0.82      1869\n",
      "           1       0.67      0.28      0.39       901\n",
      "\n",
      "    accuracy                           0.72      2770\n",
      "   macro avg       0.70      0.61      0.60      2770\n",
      "weighted avg       0.71      0.72      0.68      2770\n",
      "\n",
      "Ridge LVQ_SMOTE\n",
      "F1 macro:  0.6485849056603773\n",
      "Accuracy:  0.7848375451263538\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.87      0.84      1869\n",
      "           1       0.69      0.61      0.65       901\n",
      "\n",
      "    accuracy                           0.78      2770\n",
      "   macro avg       0.76      0.74      0.75      2770\n",
      "weighted avg       0.78      0.78      0.78      2770\n",
      "\n",
      "Ridge Assembled_SMOTE\n",
      "F1 macro:  0.6983016983016983\n",
      "Accuracy:  0.7819494584837545\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.78      0.83      1869\n",
      "           1       0.63      0.78      0.70       901\n",
      "\n",
      "    accuracy                           0.78      2770\n",
      "   macro avg       0.76      0.78      0.76      2770\n",
      "weighted avg       0.80      0.78      0.79      2770\n",
      "\n",
      "Ridge SMOTE_TomekLinks\n",
      "F1 macro:  0.6872469635627532\n",
      "Accuracy:  0.7768953068592058\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.79      0.83      1869\n",
      "           1       0.63      0.75      0.69       901\n",
      "\n",
      "    accuracy                           0.78      2770\n",
      "   macro avg       0.75      0.77      0.76      2770\n",
      "weighted avg       0.79      0.78      0.78      2770\n",
      "\n",
      "Ridge polynom_fit_SMOTE\n",
      "F1 macro:  0.6405959031657354\n",
      "Accuracy:  0.7215007215007215\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.73      0.77       447\n",
      "           1       0.59      0.70      0.64       246\n",
      "\n",
      "    accuracy                           0.72       693\n",
      "   macro avg       0.70      0.72      0.71       693\n",
      "weighted avg       0.74      0.72      0.73       693\n",
      "\n",
      "Ridge ProWSyn\n",
      "F1 macro:  0.621973929236499\n",
      "Accuracy:  0.7070707070707071\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.72      0.76       447\n",
      "           1       0.57      0.68      0.62       246\n",
      "\n",
      "    accuracy                           0.71       693\n",
      "   macro avg       0.69      0.70      0.69       693\n",
      "weighted avg       0.72      0.71      0.71       693\n",
      "\n",
      "Ridge SMOTE_IPF\n",
      "F1 macro:  0.6502835538752364\n",
      "Accuracy:  0.733044733044733\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.75      0.78       447\n",
      "           1       0.61      0.70      0.65       246\n",
      "\n",
      "    accuracy                           0.73       693\n",
      "   macro avg       0.71      0.73      0.72       693\n",
      "weighted avg       0.74      0.73      0.74       693\n",
      "\n",
      "Ridge SMOBD\n",
      "F1 macro:  0.660377358490566\n",
      "Accuracy:  0.7402597402597403\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.76      0.79       447\n",
      "           1       0.62      0.71      0.66       246\n",
      "\n",
      "    accuracy                           0.74       693\n",
      "   macro avg       0.72      0.73      0.73       693\n",
      "weighted avg       0.75      0.74      0.74       693\n",
      "\n",
      "Ridge G_SMOTE\n",
      "F1 macro:  0.6567164179104478\n",
      "Accuracy:  0.7344877344877345\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.74      0.78       447\n",
      "           1       0.61      0.72      0.66       246\n",
      "\n",
      "    accuracy                           0.73       693\n",
      "   macro avg       0.72      0.73      0.72       693\n",
      "weighted avg       0.75      0.73      0.74       693\n",
      "\n",
      "Ridge CCR\n",
      "F1 macro:  0.38526912181303113\n",
      "Accuracy:  0.6868686868686869\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.91      0.79       447\n",
      "           1       0.64      0.28      0.39       246\n",
      "\n",
      "    accuracy                           0.69       693\n",
      "   macro avg       0.67      0.59      0.59       693\n",
      "weighted avg       0.67      0.69      0.65       693\n",
      "\n",
      "Ridge LVQ_SMOTE\n",
      "F1 macro:  0.6191536748329622\n",
      "Accuracy:  0.7532467532467533\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.86      0.82       447\n",
      "           1       0.68      0.57      0.62       246\n",
      "\n",
      "    accuracy                           0.75       693\n",
      "   macro avg       0.73      0.71      0.72       693\n",
      "weighted avg       0.75      0.75      0.75       693\n",
      "\n",
      "Ridge Assembled_SMOTE\n",
      "F1 macro:  0.6454033771106942\n",
      "Accuracy:  0.7272727272727273\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.74      0.78       447\n",
      "           1       0.60      0.70      0.65       246\n",
      "\n",
      "    accuracy                           0.73       693\n",
      "   macro avg       0.71      0.72      0.71       693\n",
      "weighted avg       0.74      0.73      0.73       693\n",
      "\n",
      "Ridge SMOTE_TomekLinks\n",
      "F1 macro:  0.6529080675422139\n",
      "Accuracy:  0.733044733044733\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.75      0.78       447\n",
      "           1       0.61      0.71      0.65       246\n",
      "\n",
      "    accuracy                           0.73       693\n",
      "   macro avg       0.71      0.73      0.72       693\n",
      "weighted avg       0.75      0.73      0.74       693\n",
      "\n",
      "Ridge polynom_fit_SMOTE\n",
      "F1 macro:  None\n",
      "Accuracy:  None\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      " None\n",
      "Ridge ProWSyn\n",
      "F1 macro:  None\n",
      "Accuracy:  None\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      " None\n",
      "Ridge SMOTE_IPF\n",
      "F1 macro:  None\n",
      "Accuracy:  None\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      " None\n",
      "Ridge SMOBD\n",
      "F1 macro:  None\n",
      "Accuracy:  None\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      " None\n",
      "Ridge G_SMOTE\n",
      "F1 macro:  None\n",
      "Accuracy:  None\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      " None\n",
      "Ridge CCR\n",
      "F1 macro:  None\n",
      "Accuracy:  None\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      " None\n",
      "Ridge LVQ_SMOTE\n",
      "F1 macro:  None\n",
      "Accuracy:  None\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      " None\n",
      "Ridge Assembled_SMOTE\n",
      "F1 macro:  None\n",
      "Accuracy:  None\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      " None\n",
      "Ridge SMOTE_TomekLinks\n",
      "F1 macro:  None\n",
      "Accuracy:  None\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      " None\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for path, (name, desc, dataset_type, truth, group, task, lenguage, y_pred) in df_pred.iterrows():\n",
    "    y_true = df_truth[(df_truth[\"Dataset type\"] == dataset_type) & (df_truth[\"Task\"] == task) & (df_truth[\"Lenguage\"] == lenguage)][\"Results\"]\n",
    "    y_true = [None] if y_true.empty else y_true\n",
    "    \n",
    "    result = {}\n",
    "    if task == \"hateval2019/task1\":\n",
    "        result = print_score_hateval_task1(y_true[0], y_pred, name)\n",
    "    if task == \"detoxis/task1\":\n",
    "        result = print_score_detoxis_task1(y_true[0], y_pred, name)\n",
    "        \n",
    "    result.update({\"Dataset type\": dataset_type.title(),\n",
    "                   \"Task\": ' '.join(task.split('/')).title(),\n",
    "                   \"Name\": name,\n",
    "                   \"Group\": ' '.join(group.split('_')).title(),\n",
    "                   \"Lenguage\": lenguage.title(),\n",
    "                   \"Description\": desc})\n",
    "    \n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c33b177",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Task</th>\n",
       "      <th>Lenguage</th>\n",
       "      <th>Dataset type</th>\n",
       "      <th>Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"174\" valign=\"top\">Detoxis Task1</th>\n",
       "      <th rowspan=\"174\" valign=\"top\">Spanish</th>\n",
       "      <th rowspan=\"58\" valign=\"top\">Dev</th>\n",
       "      <th>Ridge SMOBD</th>\n",
       "      <td>0.66038</td>\n",
       "      <td>0.74026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP SMOTE_TomekLinks</th>\n",
       "      <td>0.66019</td>\n",
       "      <td>0.74747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge G_SMOTE</th>\n",
       "      <td>0.65672</td>\n",
       "      <td>0.73449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bert base (3 epochs)</th>\n",
       "      <td>0.65471</td>\n",
       "      <td>0.77778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge SMOTE_TomekLinks</th>\n",
       "      <td>0.65291</td>\n",
       "      <td>0.73304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge SMOTE_IPF</th>\n",
       "      <td>0.65028</td>\n",
       "      <td>0.73304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bert Avarage</th>\n",
       "      <td>0.64819</td>\n",
       "      <td>0.76190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Assembled_SMOTE</th>\n",
       "      <td>0.64540</td>\n",
       "      <td>0.72727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bert base (4 epochs)</th>\n",
       "      <td>0.64069</td>\n",
       "      <td>0.76046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge polynom_fit_SMOTE</th>\n",
       "      <td>0.64060</td>\n",
       "      <td>0.72150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP Assembled_SMOTE</th>\n",
       "      <td>0.63315</td>\n",
       "      <td>0.71573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP SMOBD</th>\n",
       "      <td>0.62979</td>\n",
       "      <td>0.74892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC SMOBD</th>\n",
       "      <td>0.62559</td>\n",
       "      <td>0.77201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP LVQ_SMOTE</th>\n",
       "      <td>0.62343</td>\n",
       "      <td>0.74026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge ProWSyn</th>\n",
       "      <td>0.62197</td>\n",
       "      <td>0.70707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC G_SMOTE</th>\n",
       "      <td>0.62053</td>\n",
       "      <td>0.77056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP SMOTE_IPF</th>\n",
       "      <td>0.61983</td>\n",
       "      <td>0.73449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge LVQ_SMOTE</th>\n",
       "      <td>0.61915</td>\n",
       "      <td>0.75325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC SMOTE_IPF</th>\n",
       "      <td>0.61611</td>\n",
       "      <td>0.76623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP G_SMOTE</th>\n",
       "      <td>0.61339</td>\n",
       "      <td>0.74170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bert base (2 epochs)</th>\n",
       "      <td>0.61283</td>\n",
       "      <td>0.76479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC ProWSyn</th>\n",
       "      <td>0.61205</td>\n",
       "      <td>0.76768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multi-layer Perceptron classifier</th>\n",
       "      <td>0.61072</td>\n",
       "      <td>0.75902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC Assembled_SMOTE</th>\n",
       "      <td>0.60766</td>\n",
       "      <td>0.76335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC SMOTE_TomekLinks</th>\n",
       "      <td>0.60432</td>\n",
       "      <td>0.76190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP ProWSyn</th>\n",
       "      <td>0.60041</td>\n",
       "      <td>0.72150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP polynom_fit_SMOTE</th>\n",
       "      <td>0.60000</td>\n",
       "      <td>0.72294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Classification (best)</th>\n",
       "      <td>0.59722</td>\n",
       "      <td>0.74892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Classifier</th>\n",
       "      <td>0.57985</td>\n",
       "      <td>0.75325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC LVQ_SMOTE</th>\n",
       "      <td>0.57963</td>\n",
       "      <td>0.76768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Classifier (best)</th>\n",
       "      <td>0.57957</td>\n",
       "      <td>0.74459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC polynom_fit_SMOTE</th>\n",
       "      <td>0.56383</td>\n",
       "      <td>0.76335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Classification</th>\n",
       "      <td>0.56000</td>\n",
       "      <td>0.76190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multi-layer Perceptron classifier (best)</th>\n",
       "      <td>0.55208</td>\n",
       "      <td>0.75180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost classifier (best)</th>\n",
       "      <td>0.54505</td>\n",
       "      <td>0.70851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dummy Classifier (best)</th>\n",
       "      <td>0.52396</td>\n",
       "      <td>0.35498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost classifier (best)</th>\n",
       "      <td>0.52081</td>\n",
       "      <td>0.35209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost classifier</th>\n",
       "      <td>0.50575</td>\n",
       "      <td>0.68975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge CCR</th>\n",
       "      <td>0.38527</td>\n",
       "      <td>0.68687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest classifier (best)</th>\n",
       "      <td>0.37168</td>\n",
       "      <td>0.59019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest classifier (best)</th>\n",
       "      <td>0.36788</td>\n",
       "      <td>0.64791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bernoulli Naive Bayes classifier (best)</th>\n",
       "      <td>0.36145</td>\n",
       "      <td>0.54113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Classifier (best)</th>\n",
       "      <td>0.35841</td>\n",
       "      <td>0.58153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Classification (best)</th>\n",
       "      <td>0.35529</td>\n",
       "      <td>0.53391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest classifier</th>\n",
       "      <td>0.29352</td>\n",
       "      <td>0.70130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Classifier</th>\n",
       "      <td>0.26039</td>\n",
       "      <td>0.61472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bernoulli Naive Bayes classifier</th>\n",
       "      <td>0.21605</td>\n",
       "      <td>0.63348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial Naive Bayes classifier (best)</th>\n",
       "      <td>0.19692</td>\n",
       "      <td>0.62338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost classifier</th>\n",
       "      <td>0.16981</td>\n",
       "      <td>0.61905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest classifier</th>\n",
       "      <td>0.15385</td>\n",
       "      <td>0.61905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP CCR</th>\n",
       "      <td>0.09125</td>\n",
       "      <td>0.65512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atalaya</th>\n",
       "      <td>0.06792</td>\n",
       "      <td>0.64358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC CCR</th>\n",
       "      <td>0.03200</td>\n",
       "      <td>0.65079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial Naive Bayes classifier</th>\n",
       "      <td>0.03162</td>\n",
       "      <td>0.64646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Classification</th>\n",
       "      <td>0.02381</td>\n",
       "      <td>0.64502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dummy Classifier</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.64502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multi-layer Perceptron classifier (best)</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.64502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multi-layer Perceptron classifier</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.64214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"58\" valign=\"top\">Test</th>\n",
       "      <th>Atalaya</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bert Avarage</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bert base (2 epochs)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bert base (3 epochs)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bert base (4 epochs)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost classifier</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multi-layer Perceptron classifier</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest classifier</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Classifier</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Classification</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost classifier (best)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multi-layer Perceptron classifier (best)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest classifier (best)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Classifier (best)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Classification (best)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP Assembled_SMOTE</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP CCR</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP G_SMOTE</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP LVQ_SMOTE</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP ProWSyn</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP SMOBD</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP SMOTE_IPF</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP SMOTE_TomekLinks</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP polynom_fit_SMOTE</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Assembled_SMOTE</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge CCR</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge G_SMOTE</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge LVQ_SMOTE</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge ProWSyn</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge SMOBD</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge SMOTE_IPF</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge SMOTE_TomekLinks</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge polynom_fit_SMOTE</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC Assembled_SMOTE</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC CCR</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC G_SMOTE</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC LVQ_SMOTE</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC ProWSyn</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC SMOBD</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC SMOTE_IPF</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC SMOTE_TomekLinks</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC polynom_fit_SMOTE</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost classifier</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bernoulli Naive Bayes classifier</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dummy Classifier</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multi-layer Perceptron classifier</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial Naive Bayes classifier</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest classifier</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Classifier</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Classification</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost classifier (best)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bernoulli Naive Bayes classifier (best)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dummy Classifier (best)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multi-layer Perceptron classifier (best)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial Naive Bayes classifier (best)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest classifier (best)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Classifier (best)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Classification (best)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"58\" valign=\"top\">Train</th>\n",
       "      <th>Random Forest classifier</th>\n",
       "      <td>0.99944</td>\n",
       "      <td>0.99964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Classification (best)</th>\n",
       "      <td>0.99778</td>\n",
       "      <td>0.99856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bert Avarage</th>\n",
       "      <td>0.98041</td>\n",
       "      <td>0.98736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest classifier</th>\n",
       "      <td>0.97798</td>\n",
       "      <td>0.98592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bert base (4 epochs)</th>\n",
       "      <td>0.95833</td>\n",
       "      <td>0.97329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Classifier (best)</th>\n",
       "      <td>0.95722</td>\n",
       "      <td>0.97292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP SMOBD</th>\n",
       "      <td>0.95233</td>\n",
       "      <td>0.96859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP ProWSyn</th>\n",
       "      <td>0.92675</td>\n",
       "      <td>0.95235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP G_SMOTE</th>\n",
       "      <td>0.92385</td>\n",
       "      <td>0.95090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP polynom_fit_SMOTE</th>\n",
       "      <td>0.91958</td>\n",
       "      <td>0.94765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC SMOTE_IPF</th>\n",
       "      <td>0.91327</td>\n",
       "      <td>0.94549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC Assembled_SMOTE</th>\n",
       "      <td>0.91097</td>\n",
       "      <td>0.94404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC SMOTE_TomekLinks</th>\n",
       "      <td>0.90940</td>\n",
       "      <td>0.94296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC G_SMOTE</th>\n",
       "      <td>0.90731</td>\n",
       "      <td>0.94188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC SMOBD</th>\n",
       "      <td>0.90523</td>\n",
       "      <td>0.94043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC ProWSyn</th>\n",
       "      <td>0.90376</td>\n",
       "      <td>0.94079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost classifier (best)</th>\n",
       "      <td>0.88953</td>\n",
       "      <td>0.93141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Classification (best)</th>\n",
       "      <td>0.88662</td>\n",
       "      <td>0.92780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP SMOTE_IPF</th>\n",
       "      <td>0.88106</td>\n",
       "      <td>0.92202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest classifier (best)</th>\n",
       "      <td>0.86962</td>\n",
       "      <td>0.92130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Classification</th>\n",
       "      <td>0.86612</td>\n",
       "      <td>0.92310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC polynom_fit_SMOTE</th>\n",
       "      <td>0.86547</td>\n",
       "      <td>0.92166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bert base (3 epochs)</th>\n",
       "      <td>0.85899</td>\n",
       "      <td>0.91336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC LVQ_SMOTE</th>\n",
       "      <td>0.84950</td>\n",
       "      <td>0.91264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Classifier</th>\n",
       "      <td>0.82495</td>\n",
       "      <td>0.90072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Classification</th>\n",
       "      <td>0.82315</td>\n",
       "      <td>0.90072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial Naive Bayes classifier (best)</th>\n",
       "      <td>0.77249</td>\n",
       "      <td>0.87581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bernoulli Naive Bayes classifier (best)</th>\n",
       "      <td>0.76141</td>\n",
       "      <td>0.81877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP SMOTE_TomekLinks</th>\n",
       "      <td>0.74348</td>\n",
       "      <td>0.82238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP Assembled_SMOTE</th>\n",
       "      <td>0.72934</td>\n",
       "      <td>0.80253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest classifier (best)</th>\n",
       "      <td>0.72641</td>\n",
       "      <td>0.83357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Assembled_SMOTE</th>\n",
       "      <td>0.69830</td>\n",
       "      <td>0.78195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP LVQ_SMOTE</th>\n",
       "      <td>0.69575</td>\n",
       "      <td>0.80614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge G_SMOTE</th>\n",
       "      <td>0.69433</td>\n",
       "      <td>0.78195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge polynom_fit_SMOTE</th>\n",
       "      <td>0.69402</td>\n",
       "      <td>0.78195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge ProWSyn</th>\n",
       "      <td>0.69336</td>\n",
       "      <td>0.78159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge SMOBD</th>\n",
       "      <td>0.69273</td>\n",
       "      <td>0.77870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge SMOTE_IPF</th>\n",
       "      <td>0.68886</td>\n",
       "      <td>0.77726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge SMOTE_TomekLinks</th>\n",
       "      <td>0.68725</td>\n",
       "      <td>0.77690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bert base (2 epochs)</th>\n",
       "      <td>0.67094</td>\n",
       "      <td>0.81480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bernoulli Naive Bayes classifier</th>\n",
       "      <td>0.66345</td>\n",
       "      <td>0.82347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Classifier (best)</th>\n",
       "      <td>0.65409</td>\n",
       "      <td>0.80144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multi-layer Perceptron classifier</th>\n",
       "      <td>0.65392</td>\n",
       "      <td>0.79747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge LVQ_SMOTE</th>\n",
       "      <td>0.64858</td>\n",
       "      <td>0.78484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost classifier</th>\n",
       "      <td>0.64030</td>\n",
       "      <td>0.78989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Classifier</th>\n",
       "      <td>0.62939</td>\n",
       "      <td>0.79422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multi-layer Perceptron classifier (best)</th>\n",
       "      <td>0.54848</td>\n",
       "      <td>0.76462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost classifier (best)</th>\n",
       "      <td>0.49262</td>\n",
       "      <td>0.32996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dummy Classifier (best)</th>\n",
       "      <td>0.49087</td>\n",
       "      <td>0.32527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge CCR</th>\n",
       "      <td>0.39089</td>\n",
       "      <td>0.71986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atalaya</th>\n",
       "      <td>0.34249</td>\n",
       "      <td>0.74079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost classifier</th>\n",
       "      <td>0.30435</td>\n",
       "      <td>0.71119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial Naive Bayes classifier</th>\n",
       "      <td>0.27011</td>\n",
       "      <td>0.72491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP CCR</th>\n",
       "      <td>0.11922</td>\n",
       "      <td>0.69061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC CCR</th>\n",
       "      <td>0.04126</td>\n",
       "      <td>0.68123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multi-layer Perceptron classifier</th>\n",
       "      <td>0.03704</td>\n",
       "      <td>0.68087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dummy Classifier</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.67473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multi-layer Perceptron classifier (best)</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.67473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"120\" valign=\"top\">Hateval2019 Task1</th>\n",
       "      <th rowspan=\"66\" valign=\"top\">English</th>\n",
       "      <th rowspan=\"22\" valign=\"top\">Dev</th>\n",
       "      <th>Entire layer</th>\n",
       "      <td>0.75725</td>\n",
       "      <td>0.75900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bert Avarage</th>\n",
       "      <td>0.75085</td>\n",
       "      <td>0.75300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLS layers</th>\n",
       "      <td>0.75035</td>\n",
       "      <td>0.75300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>0.74822</td>\n",
       "      <td>0.75000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest classifier</th>\n",
       "      <td>0.74720</td>\n",
       "      <td>0.75400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bert base</th>\n",
       "      <td>0.74690</td>\n",
       "      <td>0.74900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest classifier (best)</th>\n",
       "      <td>0.74220</td>\n",
       "      <td>0.74800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atalaya</th>\n",
       "      <td>0.74002</td>\n",
       "      <td>0.74300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bernoulli Naive Bayes classifier (best)</th>\n",
       "      <td>0.73823</td>\n",
       "      <td>0.74200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bernoulli Naive Bayes classifier</th>\n",
       "      <td>0.73645</td>\n",
       "      <td>0.74000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPT2 base</th>\n",
       "      <td>0.73562</td>\n",
       "      <td>0.73900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial Naive Bayes classifier</th>\n",
       "      <td>0.73487</td>\n",
       "      <td>0.74200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial Naive Bayes classifier (best)</th>\n",
       "      <td>0.73487</td>\n",
       "      <td>0.74200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Classification (best)</th>\n",
       "      <td>0.73356</td>\n",
       "      <td>0.74200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Classification</th>\n",
       "      <td>0.73191</td>\n",
       "      <td>0.74200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Classifier (best)</th>\n",
       "      <td>0.73129</td>\n",
       "      <td>0.74000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost classifier (best)</th>\n",
       "      <td>0.72652</td>\n",
       "      <td>0.74000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multi-layer Perceptron classifier (best)</th>\n",
       "      <td>0.72553</td>\n",
       "      <td>0.73300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost classifier</th>\n",
       "      <td>0.72179</td>\n",
       "      <td>0.73600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Classifier</th>\n",
       "      <td>0.71097</td>\n",
       "      <td>0.71800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multi-layer Perceptron classifier</th>\n",
       "      <td>0.71006</td>\n",
       "      <td>0.72500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dummy Classifier</th>\n",
       "      <td>0.36427</td>\n",
       "      <td>0.57300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"22\" valign=\"top\">Test</th>\n",
       "      <th>Bert base</th>\n",
       "      <td>0.59415</td>\n",
       "      <td>0.60533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bert Avarage</th>\n",
       "      <td>0.59399</td>\n",
       "      <td>0.60600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLS layers</th>\n",
       "      <td>0.58977</td>\n",
       "      <td>0.60267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entire layer</th>\n",
       "      <td>0.58663</td>\n",
       "      <td>0.59933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>0.58653</td>\n",
       "      <td>0.59900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multi-layer Perceptron classifier</th>\n",
       "      <td>0.51049</td>\n",
       "      <td>0.52600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multi-layer Perceptron classifier (best)</th>\n",
       "      <td>0.50020</td>\n",
       "      <td>0.52267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Classifier</th>\n",
       "      <td>0.48698</td>\n",
       "      <td>0.51333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial Naive Bayes classifier (best)</th>\n",
       "      <td>0.47901</td>\n",
       "      <td>0.50633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Classifier (best)</th>\n",
       "      <td>0.47851</td>\n",
       "      <td>0.50633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial Naive Bayes classifier</th>\n",
       "      <td>0.47697</td>\n",
       "      <td>0.50400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atalaya</th>\n",
       "      <td>0.47074</td>\n",
       "      <td>0.50800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Classification (best)</th>\n",
       "      <td>0.44851</td>\n",
       "      <td>0.48733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Classification</th>\n",
       "      <td>0.44543</td>\n",
       "      <td>0.48467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPT2 base</th>\n",
       "      <td>0.43600</td>\n",
       "      <td>0.49067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bernoulli Naive Bayes classifier (best)</th>\n",
       "      <td>0.43153</td>\n",
       "      <td>0.48100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost classifier</th>\n",
       "      <td>0.42943</td>\n",
       "      <td>0.46800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost classifier (best)</th>\n",
       "      <td>0.42540</td>\n",
       "      <td>0.46667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bernoulli Naive Bayes classifier</th>\n",
       "      <td>0.41992</td>\n",
       "      <td>0.47400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest classifier</th>\n",
       "      <td>0.39627</td>\n",
       "      <td>0.45567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest classifier (best)</th>\n",
       "      <td>0.39346</td>\n",
       "      <td>0.45700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dummy Classifier</th>\n",
       "      <td>0.36709</td>\n",
       "      <td>0.58000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"22\" valign=\"top\">Train</th>\n",
       "      <th>Random Forest classifier</th>\n",
       "      <td>0.99897</td>\n",
       "      <td>0.99900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest classifier (best)</th>\n",
       "      <td>0.99772</td>\n",
       "      <td>0.99778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Classification</th>\n",
       "      <td>0.95552</td>\n",
       "      <td>0.95678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Classification (best)</th>\n",
       "      <td>0.95407</td>\n",
       "      <td>0.95533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entire layer</th>\n",
       "      <td>0.94064</td>\n",
       "      <td>0.94200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bert Avarage</th>\n",
       "      <td>0.93938</td>\n",
       "      <td>0.94078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>0.93611</td>\n",
       "      <td>0.93744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLS layers</th>\n",
       "      <td>0.93160</td>\n",
       "      <td>0.93311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bert base</th>\n",
       "      <td>0.92999</td>\n",
       "      <td>0.93156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atalaya</th>\n",
       "      <td>0.90158</td>\n",
       "      <td>0.90389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Classifier</th>\n",
       "      <td>0.87636</td>\n",
       "      <td>0.88067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Classifier (best)</th>\n",
       "      <td>0.83368</td>\n",
       "      <td>0.84156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bernoulli Naive Bayes classifier</th>\n",
       "      <td>0.81929</td>\n",
       "      <td>0.82444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial Naive Bayes classifier (best)</th>\n",
       "      <td>0.81622</td>\n",
       "      <td>0.82344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bernoulli Naive Bayes classifier (best)</th>\n",
       "      <td>0.81365</td>\n",
       "      <td>0.81978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial Naive Bayes classifier</th>\n",
       "      <td>0.81284</td>\n",
       "      <td>0.82067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multi-layer Perceptron classifier (best)</th>\n",
       "      <td>0.81200</td>\n",
       "      <td>0.82011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPT2 base</th>\n",
       "      <td>0.80546</td>\n",
       "      <td>0.80956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multi-layer Perceptron classifier</th>\n",
       "      <td>0.78679</td>\n",
       "      <td>0.79989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost classifier (best)</th>\n",
       "      <td>0.77103</td>\n",
       "      <td>0.78522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost classifier</th>\n",
       "      <td>0.76402</td>\n",
       "      <td>0.77878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dummy Classifier</th>\n",
       "      <td>0.36696</td>\n",
       "      <td>0.57967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"54\" valign=\"top\">Spanish</th>\n",
       "      <th rowspan=\"18\" valign=\"top\">Dev</th>\n",
       "      <th>Bert base</th>\n",
       "      <td>0.83318</td>\n",
       "      <td>0.83400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bert Avarage</th>\n",
       "      <td>0.83122</td>\n",
       "      <td>0.83200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest classifier</th>\n",
       "      <td>0.77751</td>\n",
       "      <td>0.78200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest classifier (best)</th>\n",
       "      <td>0.77679</td>\n",
       "      <td>0.78000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bernoulli Naive Bayes classifier</th>\n",
       "      <td>0.76414</td>\n",
       "      <td>0.76800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bernoulli Naive Bayes classifier (best)</th>\n",
       "      <td>0.76292</td>\n",
       "      <td>0.76600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost classifier</th>\n",
       "      <td>0.75159</td>\n",
       "      <td>0.76000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Classification</th>\n",
       "      <td>0.75159</td>\n",
       "      <td>0.76000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multi-layer Perceptron classifier</th>\n",
       "      <td>0.74864</td>\n",
       "      <td>0.75400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Classification (best)</th>\n",
       "      <td>0.74733</td>\n",
       "      <td>0.75200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Classifier (best)</th>\n",
       "      <td>0.74703</td>\n",
       "      <td>0.75400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Classifier</th>\n",
       "      <td>0.74015</td>\n",
       "      <td>0.74600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atalaya</th>\n",
       "      <td>0.73970</td>\n",
       "      <td>0.74200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial Naive Bayes classifier (best)</th>\n",
       "      <td>0.73847</td>\n",
       "      <td>0.75000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost classifier (best)</th>\n",
       "      <td>0.73692</td>\n",
       "      <td>0.74400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial Naive Bayes classifier</th>\n",
       "      <td>0.73205</td>\n",
       "      <td>0.74800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multi-layer Perceptron classifier (best)</th>\n",
       "      <td>0.73197</td>\n",
       "      <td>0.73800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dummy Classifier</th>\n",
       "      <td>0.35733</td>\n",
       "      <td>0.55600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"18\" valign=\"top\">Test</th>\n",
       "      <th>Bert Avarage</th>\n",
       "      <td>0.74574</td>\n",
       "      <td>0.74687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bert base</th>\n",
       "      <td>0.74132</td>\n",
       "      <td>0.74250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atalaya</th>\n",
       "      <td>0.70826</td>\n",
       "      <td>0.71125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multi-layer Perceptron classifier (best)</th>\n",
       "      <td>0.70015</td>\n",
       "      <td>0.70813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Classifier</th>\n",
       "      <td>0.69866</td>\n",
       "      <td>0.70375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Classifier (best)</th>\n",
       "      <td>0.69866</td>\n",
       "      <td>0.70625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Classification</th>\n",
       "      <td>0.69784</td>\n",
       "      <td>0.70875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multi-layer Perceptron classifier</th>\n",
       "      <td>0.69751</td>\n",
       "      <td>0.70625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Classification (best)</th>\n",
       "      <td>0.69406</td>\n",
       "      <td>0.69875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial Naive Bayes classifier (best)</th>\n",
       "      <td>0.69320</td>\n",
       "      <td>0.70625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bernoulli Naive Bayes classifier (best)</th>\n",
       "      <td>0.69093</td>\n",
       "      <td>0.69437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest classifier</th>\n",
       "      <td>0.68993</td>\n",
       "      <td>0.69750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial Naive Bayes classifier</th>\n",
       "      <td>0.68504</td>\n",
       "      <td>0.70375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest classifier (best)</th>\n",
       "      <td>0.68362</td>\n",
       "      <td>0.68812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost classifier (best)</th>\n",
       "      <td>0.67729</td>\n",
       "      <td>0.68437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost classifier</th>\n",
       "      <td>0.66419</td>\n",
       "      <td>0.67688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bernoulli Naive Bayes classifier</th>\n",
       "      <td>0.65404</td>\n",
       "      <td>0.66000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dummy Classifier</th>\n",
       "      <td>0.37008</td>\n",
       "      <td>0.58750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"18\" valign=\"top\">Train</th>\n",
       "      <th>Random Forest classifier</th>\n",
       "      <td>0.99771</td>\n",
       "      <td>0.99778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest classifier (best)</th>\n",
       "      <td>0.99565</td>\n",
       "      <td>0.99578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bert Avarage</th>\n",
       "      <td>0.98353</td>\n",
       "      <td>0.98400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Classification</th>\n",
       "      <td>0.97568</td>\n",
       "      <td>0.97644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bert base</th>\n",
       "      <td>0.95920</td>\n",
       "      <td>0.96022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atalaya</th>\n",
       "      <td>0.94656</td>\n",
       "      <td>0.94800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Classifier</th>\n",
       "      <td>0.94179</td>\n",
       "      <td>0.94378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multi-layer Perceptron classifier (best)</th>\n",
       "      <td>0.92631</td>\n",
       "      <td>0.92867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Classification (best)</th>\n",
       "      <td>0.91948</td>\n",
       "      <td>0.92222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Classifier (best)</th>\n",
       "      <td>0.90766</td>\n",
       "      <td>0.91156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multi-layer Perceptron classifier</th>\n",
       "      <td>0.90000</td>\n",
       "      <td>0.90400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bernoulli Naive Bayes classifier (best)</th>\n",
       "      <td>0.88969</td>\n",
       "      <td>0.89289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial Naive Bayes classifier (best)</th>\n",
       "      <td>0.88361</td>\n",
       "      <td>0.88933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bernoulli Naive Bayes classifier</th>\n",
       "      <td>0.87582</td>\n",
       "      <td>0.88022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial Naive Bayes classifier</th>\n",
       "      <td>0.86123</td>\n",
       "      <td>0.87000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost classifier (best)</th>\n",
       "      <td>0.85434</td>\n",
       "      <td>0.86133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost classifier</th>\n",
       "      <td>0.77327</td>\n",
       "      <td>0.78711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dummy Classifier</th>\n",
       "      <td>0.37001</td>\n",
       "      <td>0.58733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                        F1  \\\n",
       "Task              Lenguage Dataset type Name                                                 \n",
       "Detoxis Task1     Spanish  Dev          Ridge SMOBD                                0.66038   \n",
       "                                        MLP SMOTE_TomekLinks                       0.66019   \n",
       "                                        Ridge G_SMOTE                              0.65672   \n",
       "                                        Bert base (3 epochs)                       0.65471   \n",
       "                                        Ridge SMOTE_TomekLinks                     0.65291   \n",
       "                                        Ridge SMOTE_IPF                            0.65028   \n",
       "                                        Bert Avarage                               0.64819   \n",
       "                                        Ridge Assembled_SMOTE                      0.64540   \n",
       "                                        Bert base (4 epochs)                       0.64069   \n",
       "                                        Ridge polynom_fit_SMOTE                    0.64060   \n",
       "                                        MLP Assembled_SMOTE                        0.63315   \n",
       "                                        MLP SMOBD                                  0.62979   \n",
       "                                        SVC SMOBD                                  0.62559   \n",
       "                                        MLP LVQ_SMOTE                              0.62343   \n",
       "                                        Ridge ProWSyn                              0.62197   \n",
       "                                        SVC G_SMOTE                                0.62053   \n",
       "                                        MLP SMOTE_IPF                              0.61983   \n",
       "                                        Ridge LVQ_SMOTE                            0.61915   \n",
       "                                        SVC SMOTE_IPF                              0.61611   \n",
       "                                        MLP G_SMOTE                                0.61339   \n",
       "                                        Bert base (2 epochs)                       0.61283   \n",
       "                                        SVC ProWSyn                                0.61205   \n",
       "                                        Multi-layer Perceptron classifier          0.61072   \n",
       "                                        SVC Assembled_SMOTE                        0.60766   \n",
       "                                        SVC SMOTE_TomekLinks                       0.60432   \n",
       "                                        MLP ProWSyn                                0.60041   \n",
       "                                        MLP polynom_fit_SMOTE                      0.60000   \n",
       "                                        Support Vector Classification (best)       0.59722   \n",
       "                                        Ridge Classifier                           0.57985   \n",
       "                                        SVC LVQ_SMOTE                              0.57963   \n",
       "                                        Ridge Classifier (best)                    0.57957   \n",
       "                                        SVC polynom_fit_SMOTE                      0.56383   \n",
       "                                        Support Vector Classification              0.56000   \n",
       "                                        Multi-layer Perceptron classifier (best)   0.55208   \n",
       "                                        AdaBoost classifier (best)                 0.54505   \n",
       "                                        Dummy Classifier (best)                    0.52396   \n",
       "                                        AdaBoost classifier (best)                 0.52081   \n",
       "                                        AdaBoost classifier                        0.50575   \n",
       "                                        Ridge CCR                                  0.38527   \n",
       "                                        Random Forest classifier (best)            0.37168   \n",
       "                                        Random Forest classifier (best)            0.36788   \n",
       "                                        Bernoulli Naive Bayes classifier (best)    0.36145   \n",
       "                                        Ridge Classifier (best)                    0.35841   \n",
       "                                        Support Vector Classification (best)       0.35529   \n",
       "                                        Random Forest classifier                   0.29352   \n",
       "                                        Ridge Classifier                           0.26039   \n",
       "                                        Bernoulli Naive Bayes classifier           0.21605   \n",
       "                                        Multinomial Naive Bayes classifier (best)  0.19692   \n",
       "                                        AdaBoost classifier                        0.16981   \n",
       "                                        Random Forest classifier                   0.15385   \n",
       "                                        MLP CCR                                    0.09125   \n",
       "                                        Atalaya                                    0.06792   \n",
       "                                        SVC CCR                                    0.03200   \n",
       "                                        Multinomial Naive Bayes classifier         0.03162   \n",
       "                                        Support Vector Classification              0.02381   \n",
       "                                        Dummy Classifier                           0.00000   \n",
       "                                        Multi-layer Perceptron classifier (best)   0.00000   \n",
       "                                        Multi-layer Perceptron classifier          0.00000   \n",
       "                           Test         Atalaya                                        NaN   \n",
       "                                        Bert Avarage                                   NaN   \n",
       "                                        Bert base (2 epochs)                           NaN   \n",
       "                                        Bert base (3 epochs)                           NaN   \n",
       "                                        Bert base (4 epochs)                           NaN   \n",
       "                                        AdaBoost classifier                            NaN   \n",
       "                                        Multi-layer Perceptron classifier              NaN   \n",
       "                                        Random Forest classifier                       NaN   \n",
       "                                        Ridge Classifier                               NaN   \n",
       "                                        Support Vector Classification                  NaN   \n",
       "                                        AdaBoost classifier (best)                     NaN   \n",
       "                                        Multi-layer Perceptron classifier (best)       NaN   \n",
       "                                        Random Forest classifier (best)                NaN   \n",
       "                                        Ridge Classifier (best)                        NaN   \n",
       "                                        Support Vector Classification (best)           NaN   \n",
       "                                        MLP Assembled_SMOTE                            NaN   \n",
       "                                        MLP CCR                                        NaN   \n",
       "                                        MLP G_SMOTE                                    NaN   \n",
       "                                        MLP LVQ_SMOTE                                  NaN   \n",
       "                                        MLP ProWSyn                                    NaN   \n",
       "                                        MLP SMOBD                                      NaN   \n",
       "                                        MLP SMOTE_IPF                                  NaN   \n",
       "                                        MLP SMOTE_TomekLinks                           NaN   \n",
       "                                        MLP polynom_fit_SMOTE                          NaN   \n",
       "                                        Ridge Assembled_SMOTE                          NaN   \n",
       "                                        Ridge CCR                                      NaN   \n",
       "                                        Ridge G_SMOTE                                  NaN   \n",
       "                                        Ridge LVQ_SMOTE                                NaN   \n",
       "                                        Ridge ProWSyn                                  NaN   \n",
       "                                        Ridge SMOBD                                    NaN   \n",
       "                                        Ridge SMOTE_IPF                                NaN   \n",
       "                                        Ridge SMOTE_TomekLinks                         NaN   \n",
       "                                        Ridge polynom_fit_SMOTE                        NaN   \n",
       "                                        SVC Assembled_SMOTE                            NaN   \n",
       "                                        SVC CCR                                        NaN   \n",
       "                                        SVC G_SMOTE                                    NaN   \n",
       "                                        SVC LVQ_SMOTE                                  NaN   \n",
       "                                        SVC ProWSyn                                    NaN   \n",
       "                                        SVC SMOBD                                      NaN   \n",
       "                                        SVC SMOTE_IPF                                  NaN   \n",
       "                                        SVC SMOTE_TomekLinks                           NaN   \n",
       "                                        SVC polynom_fit_SMOTE                          NaN   \n",
       "                                        AdaBoost classifier                            NaN   \n",
       "                                        Bernoulli Naive Bayes classifier               NaN   \n",
       "                                        Dummy Classifier                               NaN   \n",
       "                                        Multi-layer Perceptron classifier              NaN   \n",
       "                                        Multinomial Naive Bayes classifier             NaN   \n",
       "                                        Random Forest classifier                       NaN   \n",
       "                                        Ridge Classifier                               NaN   \n",
       "                                        Support Vector Classification                  NaN   \n",
       "                                        AdaBoost classifier (best)                     NaN   \n",
       "                                        Bernoulli Naive Bayes classifier (best)        NaN   \n",
       "                                        Dummy Classifier (best)                        NaN   \n",
       "                                        Multi-layer Perceptron classifier (best)       NaN   \n",
       "                                        Multinomial Naive Bayes classifier (best)      NaN   \n",
       "                                        Random Forest classifier (best)                NaN   \n",
       "                                        Ridge Classifier (best)                        NaN   \n",
       "                                        Support Vector Classification (best)           NaN   \n",
       "                           Train        Random Forest classifier                   0.99944   \n",
       "                                        Support Vector Classification (best)       0.99778   \n",
       "                                        Bert Avarage                               0.98041   \n",
       "                                        Random Forest classifier                   0.97798   \n",
       "                                        Bert base (4 epochs)                       0.95833   \n",
       "                                        Ridge Classifier (best)                    0.95722   \n",
       "                                        MLP SMOBD                                  0.95233   \n",
       "                                        MLP ProWSyn                                0.92675   \n",
       "                                        MLP G_SMOTE                                0.92385   \n",
       "                                        MLP polynom_fit_SMOTE                      0.91958   \n",
       "                                        SVC SMOTE_IPF                              0.91327   \n",
       "                                        SVC Assembled_SMOTE                        0.91097   \n",
       "                                        SVC SMOTE_TomekLinks                       0.90940   \n",
       "                                        SVC G_SMOTE                                0.90731   \n",
       "                                        SVC SMOBD                                  0.90523   \n",
       "                                        SVC ProWSyn                                0.90376   \n",
       "                                        AdaBoost classifier (best)                 0.88953   \n",
       "                                        Support Vector Classification (best)       0.88662   \n",
       "                                        MLP SMOTE_IPF                              0.88106   \n",
       "                                        Random Forest classifier (best)            0.86962   \n",
       "                                        Support Vector Classification              0.86612   \n",
       "                                        SVC polynom_fit_SMOTE                      0.86547   \n",
       "                                        Bert base (3 epochs)                       0.85899   \n",
       "                                        SVC LVQ_SMOTE                              0.84950   \n",
       "                                        Ridge Classifier                           0.82495   \n",
       "                                        Support Vector Classification              0.82315   \n",
       "                                        Multinomial Naive Bayes classifier (best)  0.77249   \n",
       "                                        Bernoulli Naive Bayes classifier (best)    0.76141   \n",
       "                                        MLP SMOTE_TomekLinks                       0.74348   \n",
       "                                        MLP Assembled_SMOTE                        0.72934   \n",
       "                                        Random Forest classifier (best)            0.72641   \n",
       "                                        Ridge Assembled_SMOTE                      0.69830   \n",
       "                                        MLP LVQ_SMOTE                              0.69575   \n",
       "                                        Ridge G_SMOTE                              0.69433   \n",
       "                                        Ridge polynom_fit_SMOTE                    0.69402   \n",
       "                                        Ridge ProWSyn                              0.69336   \n",
       "                                        Ridge SMOBD                                0.69273   \n",
       "                                        Ridge SMOTE_IPF                            0.68886   \n",
       "                                        Ridge SMOTE_TomekLinks                     0.68725   \n",
       "                                        Bert base (2 epochs)                       0.67094   \n",
       "                                        Bernoulli Naive Bayes classifier           0.66345   \n",
       "                                        Ridge Classifier (best)                    0.65409   \n",
       "                                        Multi-layer Perceptron classifier          0.65392   \n",
       "                                        Ridge LVQ_SMOTE                            0.64858   \n",
       "                                        AdaBoost classifier                        0.64030   \n",
       "                                        Ridge Classifier                           0.62939   \n",
       "                                        Multi-layer Perceptron classifier (best)   0.54848   \n",
       "                                        AdaBoost classifier (best)                 0.49262   \n",
       "                                        Dummy Classifier (best)                    0.49087   \n",
       "                                        Ridge CCR                                  0.39089   \n",
       "                                        Atalaya                                    0.34249   \n",
       "                                        AdaBoost classifier                        0.30435   \n",
       "                                        Multinomial Naive Bayes classifier         0.27011   \n",
       "                                        MLP CCR                                    0.11922   \n",
       "                                        SVC CCR                                    0.04126   \n",
       "                                        Multi-layer Perceptron classifier          0.03704   \n",
       "                                        Dummy Classifier                           0.00000   \n",
       "                                        Multi-layer Perceptron classifier (best)   0.00000   \n",
       "Hateval2019 Task1 English  Dev          Entire layer                               0.75725   \n",
       "                                        Bert Avarage                               0.75085   \n",
       "                                        CLS layers                                 0.75035   \n",
       "                                        Tokens                                     0.74822   \n",
       "                                        Random Forest classifier                   0.74720   \n",
       "                                        Bert base                                  0.74690   \n",
       "                                        Random Forest classifier (best)            0.74220   \n",
       "                                        Atalaya                                    0.74002   \n",
       "                                        Bernoulli Naive Bayes classifier (best)    0.73823   \n",
       "                                        Bernoulli Naive Bayes classifier           0.73645   \n",
       "                                        GPT2 base                                  0.73562   \n",
       "                                        Multinomial Naive Bayes classifier         0.73487   \n",
       "                                        Multinomial Naive Bayes classifier (best)  0.73487   \n",
       "                                        Support Vector Classification (best)       0.73356   \n",
       "                                        Support Vector Classification              0.73191   \n",
       "                                        Ridge Classifier (best)                    0.73129   \n",
       "                                        AdaBoost classifier (best)                 0.72652   \n",
       "                                        Multi-layer Perceptron classifier (best)   0.72553   \n",
       "                                        AdaBoost classifier                        0.72179   \n",
       "                                        Ridge Classifier                           0.71097   \n",
       "                                        Multi-layer Perceptron classifier          0.71006   \n",
       "                                        Dummy Classifier                           0.36427   \n",
       "                           Test         Bert base                                  0.59415   \n",
       "                                        Bert Avarage                               0.59399   \n",
       "                                        CLS layers                                 0.58977   \n",
       "                                        Entire layer                               0.58663   \n",
       "                                        Tokens                                     0.58653   \n",
       "                                        Multi-layer Perceptron classifier          0.51049   \n",
       "                                        Multi-layer Perceptron classifier (best)   0.50020   \n",
       "                                        Ridge Classifier                           0.48698   \n",
       "                                        Multinomial Naive Bayes classifier (best)  0.47901   \n",
       "                                        Ridge Classifier (best)                    0.47851   \n",
       "                                        Multinomial Naive Bayes classifier         0.47697   \n",
       "                                        Atalaya                                    0.47074   \n",
       "                                        Support Vector Classification (best)       0.44851   \n",
       "                                        Support Vector Classification              0.44543   \n",
       "                                        GPT2 base                                  0.43600   \n",
       "                                        Bernoulli Naive Bayes classifier (best)    0.43153   \n",
       "                                        AdaBoost classifier                        0.42943   \n",
       "                                        AdaBoost classifier (best)                 0.42540   \n",
       "                                        Bernoulli Naive Bayes classifier           0.41992   \n",
       "                                        Random Forest classifier                   0.39627   \n",
       "                                        Random Forest classifier (best)            0.39346   \n",
       "                                        Dummy Classifier                           0.36709   \n",
       "                           Train        Random Forest classifier                   0.99897   \n",
       "                                        Random Forest classifier (best)            0.99772   \n",
       "                                        Support Vector Classification              0.95552   \n",
       "                                        Support Vector Classification (best)       0.95407   \n",
       "                                        Entire layer                               0.94064   \n",
       "                                        Bert Avarage                               0.93938   \n",
       "                                        Tokens                                     0.93611   \n",
       "                                        CLS layers                                 0.93160   \n",
       "                                        Bert base                                  0.92999   \n",
       "                                        Atalaya                                    0.90158   \n",
       "                                        Ridge Classifier                           0.87636   \n",
       "                                        Ridge Classifier (best)                    0.83368   \n",
       "                                        Bernoulli Naive Bayes classifier           0.81929   \n",
       "                                        Multinomial Naive Bayes classifier (best)  0.81622   \n",
       "                                        Bernoulli Naive Bayes classifier (best)    0.81365   \n",
       "                                        Multinomial Naive Bayes classifier         0.81284   \n",
       "                                        Multi-layer Perceptron classifier (best)   0.81200   \n",
       "                                        GPT2 base                                  0.80546   \n",
       "                                        Multi-layer Perceptron classifier          0.78679   \n",
       "                                        AdaBoost classifier (best)                 0.77103   \n",
       "                                        AdaBoost classifier                        0.76402   \n",
       "                                        Dummy Classifier                           0.36696   \n",
       "                  Spanish  Dev          Bert base                                  0.83318   \n",
       "                                        Bert Avarage                               0.83122   \n",
       "                                        Random Forest classifier                   0.77751   \n",
       "                                        Random Forest classifier (best)            0.77679   \n",
       "                                        Bernoulli Naive Bayes classifier           0.76414   \n",
       "                                        Bernoulli Naive Bayes classifier (best)    0.76292   \n",
       "                                        AdaBoost classifier                        0.75159   \n",
       "                                        Support Vector Classification              0.75159   \n",
       "                                        Multi-layer Perceptron classifier          0.74864   \n",
       "                                        Support Vector Classification (best)       0.74733   \n",
       "                                        Ridge Classifier (best)                    0.74703   \n",
       "                                        Ridge Classifier                           0.74015   \n",
       "                                        Atalaya                                    0.73970   \n",
       "                                        Multinomial Naive Bayes classifier (best)  0.73847   \n",
       "                                        AdaBoost classifier (best)                 0.73692   \n",
       "                                        Multinomial Naive Bayes classifier         0.73205   \n",
       "                                        Multi-layer Perceptron classifier (best)   0.73197   \n",
       "                                        Dummy Classifier                           0.35733   \n",
       "                           Test         Bert Avarage                               0.74574   \n",
       "                                        Bert base                                  0.74132   \n",
       "                                        Atalaya                                    0.70826   \n",
       "                                        Multi-layer Perceptron classifier (best)   0.70015   \n",
       "                                        Ridge Classifier                           0.69866   \n",
       "                                        Ridge Classifier (best)                    0.69866   \n",
       "                                        Support Vector Classification              0.69784   \n",
       "                                        Multi-layer Perceptron classifier          0.69751   \n",
       "                                        Support Vector Classification (best)       0.69406   \n",
       "                                        Multinomial Naive Bayes classifier (best)  0.69320   \n",
       "                                        Bernoulli Naive Bayes classifier (best)    0.69093   \n",
       "                                        Random Forest classifier                   0.68993   \n",
       "                                        Multinomial Naive Bayes classifier         0.68504   \n",
       "                                        Random Forest classifier (best)            0.68362   \n",
       "                                        AdaBoost classifier (best)                 0.67729   \n",
       "                                        AdaBoost classifier                        0.66419   \n",
       "                                        Bernoulli Naive Bayes classifier           0.65404   \n",
       "                                        Dummy Classifier                           0.37008   \n",
       "                           Train        Random Forest classifier                   0.99771   \n",
       "                                        Random Forest classifier (best)            0.99565   \n",
       "                                        Bert Avarage                               0.98353   \n",
       "                                        Support Vector Classification              0.97568   \n",
       "                                        Bert base                                  0.95920   \n",
       "                                        Atalaya                                    0.94656   \n",
       "                                        Ridge Classifier                           0.94179   \n",
       "                                        Multi-layer Perceptron classifier (best)   0.92631   \n",
       "                                        Support Vector Classification (best)       0.91948   \n",
       "                                        Ridge Classifier (best)                    0.90766   \n",
       "                                        Multi-layer Perceptron classifier          0.90000   \n",
       "                                        Bernoulli Naive Bayes classifier (best)    0.88969   \n",
       "                                        Multinomial Naive Bayes classifier (best)  0.88361   \n",
       "                                        Bernoulli Naive Bayes classifier           0.87582   \n",
       "                                        Multinomial Naive Bayes classifier         0.86123   \n",
       "                                        AdaBoost classifier (best)                 0.85434   \n",
       "                                        AdaBoost classifier                        0.77327   \n",
       "                                        Dummy Classifier                           0.37001   \n",
       "\n",
       "                                                                                   Accuracy  \n",
       "Task              Lenguage Dataset type Name                                                 \n",
       "Detoxis Task1     Spanish  Dev          Ridge SMOBD                                 0.74026  \n",
       "                                        MLP SMOTE_TomekLinks                        0.74747  \n",
       "                                        Ridge G_SMOTE                               0.73449  \n",
       "                                        Bert base (3 epochs)                        0.77778  \n",
       "                                        Ridge SMOTE_TomekLinks                      0.73304  \n",
       "                                        Ridge SMOTE_IPF                             0.73304  \n",
       "                                        Bert Avarage                                0.76190  \n",
       "                                        Ridge Assembled_SMOTE                       0.72727  \n",
       "                                        Bert base (4 epochs)                        0.76046  \n",
       "                                        Ridge polynom_fit_SMOTE                     0.72150  \n",
       "                                        MLP Assembled_SMOTE                         0.71573  \n",
       "                                        MLP SMOBD                                   0.74892  \n",
       "                                        SVC SMOBD                                   0.77201  \n",
       "                                        MLP LVQ_SMOTE                               0.74026  \n",
       "                                        Ridge ProWSyn                               0.70707  \n",
       "                                        SVC G_SMOTE                                 0.77056  \n",
       "                                        MLP SMOTE_IPF                               0.73449  \n",
       "                                        Ridge LVQ_SMOTE                             0.75325  \n",
       "                                        SVC SMOTE_IPF                               0.76623  \n",
       "                                        MLP G_SMOTE                                 0.74170  \n",
       "                                        Bert base (2 epochs)                        0.76479  \n",
       "                                        SVC ProWSyn                                 0.76768  \n",
       "                                        Multi-layer Perceptron classifier           0.75902  \n",
       "                                        SVC Assembled_SMOTE                         0.76335  \n",
       "                                        SVC SMOTE_TomekLinks                        0.76190  \n",
       "                                        MLP ProWSyn                                 0.72150  \n",
       "                                        MLP polynom_fit_SMOTE                       0.72294  \n",
       "                                        Support Vector Classification (best)        0.74892  \n",
       "                                        Ridge Classifier                            0.75325  \n",
       "                                        SVC LVQ_SMOTE                               0.76768  \n",
       "                                        Ridge Classifier (best)                     0.74459  \n",
       "                                        SVC polynom_fit_SMOTE                       0.76335  \n",
       "                                        Support Vector Classification               0.76190  \n",
       "                                        Multi-layer Perceptron classifier (best)    0.75180  \n",
       "                                        AdaBoost classifier (best)                  0.70851  \n",
       "                                        Dummy Classifier (best)                     0.35498  \n",
       "                                        AdaBoost classifier (best)                  0.35209  \n",
       "                                        AdaBoost classifier                         0.68975  \n",
       "                                        Ridge CCR                                   0.68687  \n",
       "                                        Random Forest classifier (best)             0.59019  \n",
       "                                        Random Forest classifier (best)             0.64791  \n",
       "                                        Bernoulli Naive Bayes classifier (best)     0.54113  \n",
       "                                        Ridge Classifier (best)                     0.58153  \n",
       "                                        Support Vector Classification (best)        0.53391  \n",
       "                                        Random Forest classifier                    0.70130  \n",
       "                                        Ridge Classifier                            0.61472  \n",
       "                                        Bernoulli Naive Bayes classifier            0.63348  \n",
       "                                        Multinomial Naive Bayes classifier (best)   0.62338  \n",
       "                                        AdaBoost classifier                         0.61905  \n",
       "                                        Random Forest classifier                    0.61905  \n",
       "                                        MLP CCR                                     0.65512  \n",
       "                                        Atalaya                                     0.64358  \n",
       "                                        SVC CCR                                     0.65079  \n",
       "                                        Multinomial Naive Bayes classifier          0.64646  \n",
       "                                        Support Vector Classification               0.64502  \n",
       "                                        Dummy Classifier                            0.64502  \n",
       "                                        Multi-layer Perceptron classifier (best)    0.64502  \n",
       "                                        Multi-layer Perceptron classifier           0.64214  \n",
       "                           Test         Atalaya                                         NaN  \n",
       "                                        Bert Avarage                                    NaN  \n",
       "                                        Bert base (2 epochs)                            NaN  \n",
       "                                        Bert base (3 epochs)                            NaN  \n",
       "                                        Bert base (4 epochs)                            NaN  \n",
       "                                        AdaBoost classifier                             NaN  \n",
       "                                        Multi-layer Perceptron classifier               NaN  \n",
       "                                        Random Forest classifier                        NaN  \n",
       "                                        Ridge Classifier                                NaN  \n",
       "                                        Support Vector Classification                   NaN  \n",
       "                                        AdaBoost classifier (best)                      NaN  \n",
       "                                        Multi-layer Perceptron classifier (best)        NaN  \n",
       "                                        Random Forest classifier (best)                 NaN  \n",
       "                                        Ridge Classifier (best)                         NaN  \n",
       "                                        Support Vector Classification (best)            NaN  \n",
       "                                        MLP Assembled_SMOTE                             NaN  \n",
       "                                        MLP CCR                                         NaN  \n",
       "                                        MLP G_SMOTE                                     NaN  \n",
       "                                        MLP LVQ_SMOTE                                   NaN  \n",
       "                                        MLP ProWSyn                                     NaN  \n",
       "                                        MLP SMOBD                                       NaN  \n",
       "                                        MLP SMOTE_IPF                                   NaN  \n",
       "                                        MLP SMOTE_TomekLinks                            NaN  \n",
       "                                        MLP polynom_fit_SMOTE                           NaN  \n",
       "                                        Ridge Assembled_SMOTE                           NaN  \n",
       "                                        Ridge CCR                                       NaN  \n",
       "                                        Ridge G_SMOTE                                   NaN  \n",
       "                                        Ridge LVQ_SMOTE                                 NaN  \n",
       "                                        Ridge ProWSyn                                   NaN  \n",
       "                                        Ridge SMOBD                                     NaN  \n",
       "                                        Ridge SMOTE_IPF                                 NaN  \n",
       "                                        Ridge SMOTE_TomekLinks                          NaN  \n",
       "                                        Ridge polynom_fit_SMOTE                         NaN  \n",
       "                                        SVC Assembled_SMOTE                             NaN  \n",
       "                                        SVC CCR                                         NaN  \n",
       "                                        SVC G_SMOTE                                     NaN  \n",
       "                                        SVC LVQ_SMOTE                                   NaN  \n",
       "                                        SVC ProWSyn                                     NaN  \n",
       "                                        SVC SMOBD                                       NaN  \n",
       "                                        SVC SMOTE_IPF                                   NaN  \n",
       "                                        SVC SMOTE_TomekLinks                            NaN  \n",
       "                                        SVC polynom_fit_SMOTE                           NaN  \n",
       "                                        AdaBoost classifier                             NaN  \n",
       "                                        Bernoulli Naive Bayes classifier                NaN  \n",
       "                                        Dummy Classifier                                NaN  \n",
       "                                        Multi-layer Perceptron classifier               NaN  \n",
       "                                        Multinomial Naive Bayes classifier              NaN  \n",
       "                                        Random Forest classifier                        NaN  \n",
       "                                        Ridge Classifier                                NaN  \n",
       "                                        Support Vector Classification                   NaN  \n",
       "                                        AdaBoost classifier (best)                      NaN  \n",
       "                                        Bernoulli Naive Bayes classifier (best)         NaN  \n",
       "                                        Dummy Classifier (best)                         NaN  \n",
       "                                        Multi-layer Perceptron classifier (best)        NaN  \n",
       "                                        Multinomial Naive Bayes classifier (best)       NaN  \n",
       "                                        Random Forest classifier (best)                 NaN  \n",
       "                                        Ridge Classifier (best)                         NaN  \n",
       "                                        Support Vector Classification (best)            NaN  \n",
       "                           Train        Random Forest classifier                    0.99964  \n",
       "                                        Support Vector Classification (best)        0.99856  \n",
       "                                        Bert Avarage                                0.98736  \n",
       "                                        Random Forest classifier                    0.98592  \n",
       "                                        Bert base (4 epochs)                        0.97329  \n",
       "                                        Ridge Classifier (best)                     0.97292  \n",
       "                                        MLP SMOBD                                   0.96859  \n",
       "                                        MLP ProWSyn                                 0.95235  \n",
       "                                        MLP G_SMOTE                                 0.95090  \n",
       "                                        MLP polynom_fit_SMOTE                       0.94765  \n",
       "                                        SVC SMOTE_IPF                               0.94549  \n",
       "                                        SVC Assembled_SMOTE                         0.94404  \n",
       "                                        SVC SMOTE_TomekLinks                        0.94296  \n",
       "                                        SVC G_SMOTE                                 0.94188  \n",
       "                                        SVC SMOBD                                   0.94043  \n",
       "                                        SVC ProWSyn                                 0.94079  \n",
       "                                        AdaBoost classifier (best)                  0.93141  \n",
       "                                        Support Vector Classification (best)        0.92780  \n",
       "                                        MLP SMOTE_IPF                               0.92202  \n",
       "                                        Random Forest classifier (best)             0.92130  \n",
       "                                        Support Vector Classification               0.92310  \n",
       "                                        SVC polynom_fit_SMOTE                       0.92166  \n",
       "                                        Bert base (3 epochs)                        0.91336  \n",
       "                                        SVC LVQ_SMOTE                               0.91264  \n",
       "                                        Ridge Classifier                            0.90072  \n",
       "                                        Support Vector Classification               0.90072  \n",
       "                                        Multinomial Naive Bayes classifier (best)   0.87581  \n",
       "                                        Bernoulli Naive Bayes classifier (best)     0.81877  \n",
       "                                        MLP SMOTE_TomekLinks                        0.82238  \n",
       "                                        MLP Assembled_SMOTE                         0.80253  \n",
       "                                        Random Forest classifier (best)             0.83357  \n",
       "                                        Ridge Assembled_SMOTE                       0.78195  \n",
       "                                        MLP LVQ_SMOTE                               0.80614  \n",
       "                                        Ridge G_SMOTE                               0.78195  \n",
       "                                        Ridge polynom_fit_SMOTE                     0.78195  \n",
       "                                        Ridge ProWSyn                               0.78159  \n",
       "                                        Ridge SMOBD                                 0.77870  \n",
       "                                        Ridge SMOTE_IPF                             0.77726  \n",
       "                                        Ridge SMOTE_TomekLinks                      0.77690  \n",
       "                                        Bert base (2 epochs)                        0.81480  \n",
       "                                        Bernoulli Naive Bayes classifier            0.82347  \n",
       "                                        Ridge Classifier (best)                     0.80144  \n",
       "                                        Multi-layer Perceptron classifier           0.79747  \n",
       "                                        Ridge LVQ_SMOTE                             0.78484  \n",
       "                                        AdaBoost classifier                         0.78989  \n",
       "                                        Ridge Classifier                            0.79422  \n",
       "                                        Multi-layer Perceptron classifier (best)    0.76462  \n",
       "                                        AdaBoost classifier (best)                  0.32996  \n",
       "                                        Dummy Classifier (best)                     0.32527  \n",
       "                                        Ridge CCR                                   0.71986  \n",
       "                                        Atalaya                                     0.74079  \n",
       "                                        AdaBoost classifier                         0.71119  \n",
       "                                        Multinomial Naive Bayes classifier          0.72491  \n",
       "                                        MLP CCR                                     0.69061  \n",
       "                                        SVC CCR                                     0.68123  \n",
       "                                        Multi-layer Perceptron classifier           0.68087  \n",
       "                                        Dummy Classifier                            0.67473  \n",
       "                                        Multi-layer Perceptron classifier (best)    0.67473  \n",
       "Hateval2019 Task1 English  Dev          Entire layer                                0.75900  \n",
       "                                        Bert Avarage                                0.75300  \n",
       "                                        CLS layers                                  0.75300  \n",
       "                                        Tokens                                      0.75000  \n",
       "                                        Random Forest classifier                    0.75400  \n",
       "                                        Bert base                                   0.74900  \n",
       "                                        Random Forest classifier (best)             0.74800  \n",
       "                                        Atalaya                                     0.74300  \n",
       "                                        Bernoulli Naive Bayes classifier (best)     0.74200  \n",
       "                                        Bernoulli Naive Bayes classifier            0.74000  \n",
       "                                        GPT2 base                                   0.73900  \n",
       "                                        Multinomial Naive Bayes classifier          0.74200  \n",
       "                                        Multinomial Naive Bayes classifier (best)   0.74200  \n",
       "                                        Support Vector Classification (best)        0.74200  \n",
       "                                        Support Vector Classification               0.74200  \n",
       "                                        Ridge Classifier (best)                     0.74000  \n",
       "                                        AdaBoost classifier (best)                  0.74000  \n",
       "                                        Multi-layer Perceptron classifier (best)    0.73300  \n",
       "                                        AdaBoost classifier                         0.73600  \n",
       "                                        Ridge Classifier                            0.71800  \n",
       "                                        Multi-layer Perceptron classifier           0.72500  \n",
       "                                        Dummy Classifier                            0.57300  \n",
       "                           Test         Bert base                                   0.60533  \n",
       "                                        Bert Avarage                                0.60600  \n",
       "                                        CLS layers                                  0.60267  \n",
       "                                        Entire layer                                0.59933  \n",
       "                                        Tokens                                      0.59900  \n",
       "                                        Multi-layer Perceptron classifier           0.52600  \n",
       "                                        Multi-layer Perceptron classifier (best)    0.52267  \n",
       "                                        Ridge Classifier                            0.51333  \n",
       "                                        Multinomial Naive Bayes classifier (best)   0.50633  \n",
       "                                        Ridge Classifier (best)                     0.50633  \n",
       "                                        Multinomial Naive Bayes classifier          0.50400  \n",
       "                                        Atalaya                                     0.50800  \n",
       "                                        Support Vector Classification (best)        0.48733  \n",
       "                                        Support Vector Classification               0.48467  \n",
       "                                        GPT2 base                                   0.49067  \n",
       "                                        Bernoulli Naive Bayes classifier (best)     0.48100  \n",
       "                                        AdaBoost classifier                         0.46800  \n",
       "                                        AdaBoost classifier (best)                  0.46667  \n",
       "                                        Bernoulli Naive Bayes classifier            0.47400  \n",
       "                                        Random Forest classifier                    0.45567  \n",
       "                                        Random Forest classifier (best)             0.45700  \n",
       "                                        Dummy Classifier                            0.58000  \n",
       "                           Train        Random Forest classifier                    0.99900  \n",
       "                                        Random Forest classifier (best)             0.99778  \n",
       "                                        Support Vector Classification               0.95678  \n",
       "                                        Support Vector Classification (best)        0.95533  \n",
       "                                        Entire layer                                0.94200  \n",
       "                                        Bert Avarage                                0.94078  \n",
       "                                        Tokens                                      0.93744  \n",
       "                                        CLS layers                                  0.93311  \n",
       "                                        Bert base                                   0.93156  \n",
       "                                        Atalaya                                     0.90389  \n",
       "                                        Ridge Classifier                            0.88067  \n",
       "                                        Ridge Classifier (best)                     0.84156  \n",
       "                                        Bernoulli Naive Bayes classifier            0.82444  \n",
       "                                        Multinomial Naive Bayes classifier (best)   0.82344  \n",
       "                                        Bernoulli Naive Bayes classifier (best)     0.81978  \n",
       "                                        Multinomial Naive Bayes classifier          0.82067  \n",
       "                                        Multi-layer Perceptron classifier (best)    0.82011  \n",
       "                                        GPT2 base                                   0.80956  \n",
       "                                        Multi-layer Perceptron classifier           0.79989  \n",
       "                                        AdaBoost classifier (best)                  0.78522  \n",
       "                                        AdaBoost classifier                         0.77878  \n",
       "                                        Dummy Classifier                            0.57967  \n",
       "                  Spanish  Dev          Bert base                                   0.83400  \n",
       "                                        Bert Avarage                                0.83200  \n",
       "                                        Random Forest classifier                    0.78200  \n",
       "                                        Random Forest classifier (best)             0.78000  \n",
       "                                        Bernoulli Naive Bayes classifier            0.76800  \n",
       "                                        Bernoulli Naive Bayes classifier (best)     0.76600  \n",
       "                                        AdaBoost classifier                         0.76000  \n",
       "                                        Support Vector Classification               0.76000  \n",
       "                                        Multi-layer Perceptron classifier           0.75400  \n",
       "                                        Support Vector Classification (best)        0.75200  \n",
       "                                        Ridge Classifier (best)                     0.75400  \n",
       "                                        Ridge Classifier                            0.74600  \n",
       "                                        Atalaya                                     0.74200  \n",
       "                                        Multinomial Naive Bayes classifier (best)   0.75000  \n",
       "                                        AdaBoost classifier (best)                  0.74400  \n",
       "                                        Multinomial Naive Bayes classifier          0.74800  \n",
       "                                        Multi-layer Perceptron classifier (best)    0.73800  \n",
       "                                        Dummy Classifier                            0.55600  \n",
       "                           Test         Bert Avarage                                0.74687  \n",
       "                                        Bert base                                   0.74250  \n",
       "                                        Atalaya                                     0.71125  \n",
       "                                        Multi-layer Perceptron classifier (best)    0.70813  \n",
       "                                        Ridge Classifier                            0.70375  \n",
       "                                        Ridge Classifier (best)                     0.70625  \n",
       "                                        Support Vector Classification               0.70875  \n",
       "                                        Multi-layer Perceptron classifier           0.70625  \n",
       "                                        Support Vector Classification (best)        0.69875  \n",
       "                                        Multinomial Naive Bayes classifier (best)   0.70625  \n",
       "                                        Bernoulli Naive Bayes classifier (best)     0.69437  \n",
       "                                        Random Forest classifier                    0.69750  \n",
       "                                        Multinomial Naive Bayes classifier          0.70375  \n",
       "                                        Random Forest classifier (best)             0.68812  \n",
       "                                        AdaBoost classifier (best)                  0.68437  \n",
       "                                        AdaBoost classifier                         0.67688  \n",
       "                                        Bernoulli Naive Bayes classifier            0.66000  \n",
       "                                        Dummy Classifier                            0.58750  \n",
       "                           Train        Random Forest classifier                    0.99778  \n",
       "                                        Random Forest classifier (best)             0.99578  \n",
       "                                        Bert Avarage                                0.98400  \n",
       "                                        Support Vector Classification               0.97644  \n",
       "                                        Bert base                                   0.96022  \n",
       "                                        Atalaya                                     0.94800  \n",
       "                                        Ridge Classifier                            0.94378  \n",
       "                                        Multi-layer Perceptron classifier (best)    0.92867  \n",
       "                                        Support Vector Classification (best)        0.92222  \n",
       "                                        Ridge Classifier (best)                     0.91156  \n",
       "                                        Multi-layer Perceptron classifier           0.90400  \n",
       "                                        Bernoulli Naive Bayes classifier (best)     0.89289  \n",
       "                                        Multinomial Naive Bayes classifier (best)   0.88933  \n",
       "                                        Bernoulli Naive Bayes classifier            0.88022  \n",
       "                                        Multinomial Naive Bayes classifier          0.87000  \n",
       "                                        AdaBoost classifier (best)                  0.86133  \n",
       "                                        AdaBoost classifier                         0.78711  \n",
       "                                        Dummy Classifier                            0.58733  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.DataFrame(results).set_index([\"Task\", \"Lenguage\", \"Dataset type\", \"Group\", \"Name\", \"Description\"]).sort_index(level=[0, 1, 2, 3, 4])\n",
    "scores = df_results.columns.to_list()\n",
    "df_results_index = df_results.sort_values(by=[\"Task\", \"Lenguage\", \"Dataset type\"] + scores, ascending=3*[True] + len(scores) * [False]).droplevel(\"Group\")\n",
    "df_results_index.droplevel(\"Description\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23812940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 3 1\n"
     ]
    }
   ],
   "source": [
    "a = [lambda x: 1, lambda x: 2, lambda x: 3] # Objective\n",
    "b = [(lambda x: i+1) for i in range(3)] # Problem\n",
    "c = [(lambda i: lambda x: i+1)(i) for i in range(3)] #First solution\n",
    "\n",
    "print(a[0](1), b[0](1), c[0](1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a9942f0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">F1</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Dev</th>\n",
       "      <th>Test</th>\n",
       "      <th>Train</th>\n",
       "      <th>Dev</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Task</th>\n",
       "      <th>Lenguage</th>\n",
       "      <th>Group</th>\n",
       "      <th>Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"58\" valign=\"top\">Detoxis Task1</th>\n",
       "      <th rowspan=\"58\" valign=\"top\">Spanish</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">Deep Learning</th>\n",
       "      <th>Bert base (3 epochs)</th>\n",
       "      <td>0.85899</td>\n",
       "      <td>0.65471</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.91336</td>\n",
       "      <td>0.77778</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bert Avarage</th>\n",
       "      <td>0.98041</td>\n",
       "      <td>0.64819</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.98736</td>\n",
       "      <td>0.76190</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bert base (4 epochs)</th>\n",
       "      <td>0.95833</td>\n",
       "      <td>0.64069</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.97329</td>\n",
       "      <td>0.76046</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bert base (2 epochs)</th>\n",
       "      <td>0.67094</td>\n",
       "      <td>0.61283</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.81480</td>\n",
       "      <td>0.76479</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atalaya</th>\n",
       "      <td>0.34249</td>\n",
       "      <td>0.06792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.74079</td>\n",
       "      <td>0.64358</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Sbert</th>\n",
       "      <th>Multi-layer Perceptron classifier</th>\n",
       "      <td>0.65392</td>\n",
       "      <td>0.61072</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.79747</td>\n",
       "      <td>0.75902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Classifier</th>\n",
       "      <td>0.62939</td>\n",
       "      <td>0.57985</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.79422</td>\n",
       "      <td>0.75325</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Classification</th>\n",
       "      <td>0.82315</td>\n",
       "      <td>0.56000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.90072</td>\n",
       "      <td>0.76190</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost classifier</th>\n",
       "      <td>0.64030</td>\n",
       "      <td>0.50575</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.78989</td>\n",
       "      <td>0.68975</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest classifier</th>\n",
       "      <td>0.99944</td>\n",
       "      <td>0.29352</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.99964</td>\n",
       "      <td>0.70130</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Sbert Best</th>\n",
       "      <th>Support Vector Classification (best)</th>\n",
       "      <td>0.99778</td>\n",
       "      <td>0.59722</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.99856</td>\n",
       "      <td>0.74892</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Classifier (best)</th>\n",
       "      <td>0.65409</td>\n",
       "      <td>0.57957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.80144</td>\n",
       "      <td>0.74459</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multi-layer Perceptron classifier (best)</th>\n",
       "      <td>0.54848</td>\n",
       "      <td>0.55208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.76462</td>\n",
       "      <td>0.75180</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost classifier (best)</th>\n",
       "      <td>0.88953</td>\n",
       "      <td>0.54505</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.93141</td>\n",
       "      <td>0.70851</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest classifier (best)</th>\n",
       "      <td>0.86962</td>\n",
       "      <td>0.36788</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.92130</td>\n",
       "      <td>0.64791</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"27\" valign=\"top\">Sbert Oversampling</th>\n",
       "      <th>Ridge SMOBD</th>\n",
       "      <td>0.69273</td>\n",
       "      <td>0.66038</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.77870</td>\n",
       "      <td>0.74026</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP SMOTE_TomekLinks</th>\n",
       "      <td>0.74348</td>\n",
       "      <td>0.66019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.82238</td>\n",
       "      <td>0.74747</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge G_SMOTE</th>\n",
       "      <td>0.69433</td>\n",
       "      <td>0.65672</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.78195</td>\n",
       "      <td>0.73449</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge SMOTE_TomekLinks</th>\n",
       "      <td>0.68725</td>\n",
       "      <td>0.65291</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.77690</td>\n",
       "      <td>0.73304</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge SMOTE_IPF</th>\n",
       "      <td>0.68886</td>\n",
       "      <td>0.65028</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.77726</td>\n",
       "      <td>0.73304</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Assembled_SMOTE</th>\n",
       "      <td>0.69830</td>\n",
       "      <td>0.64540</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.78195</td>\n",
       "      <td>0.72727</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge polynom_fit_SMOTE</th>\n",
       "      <td>0.69402</td>\n",
       "      <td>0.64060</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.78195</td>\n",
       "      <td>0.72150</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP Assembled_SMOTE</th>\n",
       "      <td>0.72934</td>\n",
       "      <td>0.63315</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.80253</td>\n",
       "      <td>0.71573</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP SMOBD</th>\n",
       "      <td>0.95233</td>\n",
       "      <td>0.62979</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.96859</td>\n",
       "      <td>0.74892</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC SMOBD</th>\n",
       "      <td>0.90523</td>\n",
       "      <td>0.62559</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.94043</td>\n",
       "      <td>0.77201</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP LVQ_SMOTE</th>\n",
       "      <td>0.69575</td>\n",
       "      <td>0.62343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.80614</td>\n",
       "      <td>0.74026</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge ProWSyn</th>\n",
       "      <td>0.69336</td>\n",
       "      <td>0.62197</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.78159</td>\n",
       "      <td>0.70707</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC G_SMOTE</th>\n",
       "      <td>0.90731</td>\n",
       "      <td>0.62053</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.94188</td>\n",
       "      <td>0.77056</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP SMOTE_IPF</th>\n",
       "      <td>0.88106</td>\n",
       "      <td>0.61983</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.92202</td>\n",
       "      <td>0.73449</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge LVQ_SMOTE</th>\n",
       "      <td>0.64858</td>\n",
       "      <td>0.61915</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.78484</td>\n",
       "      <td>0.75325</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC SMOTE_IPF</th>\n",
       "      <td>0.91327</td>\n",
       "      <td>0.61611</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.94549</td>\n",
       "      <td>0.76623</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP G_SMOTE</th>\n",
       "      <td>0.92385</td>\n",
       "      <td>0.61339</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.95090</td>\n",
       "      <td>0.74170</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC ProWSyn</th>\n",
       "      <td>0.90376</td>\n",
       "      <td>0.61205</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.94079</td>\n",
       "      <td>0.76768</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC Assembled_SMOTE</th>\n",
       "      <td>0.91097</td>\n",
       "      <td>0.60766</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.94404</td>\n",
       "      <td>0.76335</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC SMOTE_TomekLinks</th>\n",
       "      <td>0.90940</td>\n",
       "      <td>0.60432</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.94296</td>\n",
       "      <td>0.76190</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP ProWSyn</th>\n",
       "      <td>0.92675</td>\n",
       "      <td>0.60041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.95235</td>\n",
       "      <td>0.72150</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP polynom_fit_SMOTE</th>\n",
       "      <td>0.91958</td>\n",
       "      <td>0.60000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.94765</td>\n",
       "      <td>0.72294</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC LVQ_SMOTE</th>\n",
       "      <td>0.84950</td>\n",
       "      <td>0.57963</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.91264</td>\n",
       "      <td>0.76768</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC polynom_fit_SMOTE</th>\n",
       "      <td>0.86547</td>\n",
       "      <td>0.56383</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.92166</td>\n",
       "      <td>0.76335</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge CCR</th>\n",
       "      <td>0.39089</td>\n",
       "      <td>0.38527</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.71986</td>\n",
       "      <td>0.68687</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP CCR</th>\n",
       "      <td>0.11922</td>\n",
       "      <td>0.09125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.69061</td>\n",
       "      <td>0.65512</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC CCR</th>\n",
       "      <td>0.04126</td>\n",
       "      <td>0.03200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.68123</td>\n",
       "      <td>0.65079</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">Traditional</th>\n",
       "      <th>Ridge Classifier</th>\n",
       "      <td>0.82495</td>\n",
       "      <td>0.26039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.90072</td>\n",
       "      <td>0.61472</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bernoulli Naive Bayes classifier</th>\n",
       "      <td>0.66345</td>\n",
       "      <td>0.21605</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.82347</td>\n",
       "      <td>0.63348</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost classifier</th>\n",
       "      <td>0.30435</td>\n",
       "      <td>0.16981</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.71119</td>\n",
       "      <td>0.61905</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest classifier</th>\n",
       "      <td>0.97798</td>\n",
       "      <td>0.15385</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.98592</td>\n",
       "      <td>0.61905</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial Naive Bayes classifier</th>\n",
       "      <td>0.27011</td>\n",
       "      <td>0.03162</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.72491</td>\n",
       "      <td>0.64646</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Classification</th>\n",
       "      <td>0.86612</td>\n",
       "      <td>0.02381</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.92310</td>\n",
       "      <td>0.64502</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dummy Classifier</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.67473</td>\n",
       "      <td>0.64502</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multi-layer Perceptron classifier</th>\n",
       "      <td>0.03704</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.68087</td>\n",
       "      <td>0.64214</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">Traditional Best</th>\n",
       "      <th>Dummy Classifier (best)</th>\n",
       "      <td>0.49087</td>\n",
       "      <td>0.52396</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.32527</td>\n",
       "      <td>0.35498</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost classifier (best)</th>\n",
       "      <td>0.49262</td>\n",
       "      <td>0.52081</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.32996</td>\n",
       "      <td>0.35209</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest classifier (best)</th>\n",
       "      <td>0.72641</td>\n",
       "      <td>0.37168</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.83357</td>\n",
       "      <td>0.59019</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bernoulli Naive Bayes classifier (best)</th>\n",
       "      <td>0.76141</td>\n",
       "      <td>0.36145</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.81877</td>\n",
       "      <td>0.54113</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Classifier (best)</th>\n",
       "      <td>0.95722</td>\n",
       "      <td>0.35841</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.97292</td>\n",
       "      <td>0.58153</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Classification (best)</th>\n",
       "      <td>0.88662</td>\n",
       "      <td>0.35529</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.92780</td>\n",
       "      <td>0.53391</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial Naive Bayes classifier (best)</th>\n",
       "      <td>0.77249</td>\n",
       "      <td>0.19692</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.87581</td>\n",
       "      <td>0.62338</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multi-layer Perceptron classifier (best)</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.67473</td>\n",
       "      <td>0.64502</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"40\" valign=\"top\">Hateval2019 Task1</th>\n",
       "      <th rowspan=\"22\" valign=\"top\">English</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">Bert Avarage</th>\n",
       "      <th>CLS layers</th>\n",
       "      <td>0.93160</td>\n",
       "      <td>0.75035</td>\n",
       "      <td>0.58977</td>\n",
       "      <td>0.93311</td>\n",
       "      <td>0.75300</td>\n",
       "      <td>0.60267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entire layer</th>\n",
       "      <td>0.94064</td>\n",
       "      <td>0.75725</td>\n",
       "      <td>0.58663</td>\n",
       "      <td>0.94200</td>\n",
       "      <td>0.75900</td>\n",
       "      <td>0.59933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>0.93611</td>\n",
       "      <td>0.74822</td>\n",
       "      <td>0.58653</td>\n",
       "      <td>0.93744</td>\n",
       "      <td>0.75000</td>\n",
       "      <td>0.59900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Deep Learning</th>\n",
       "      <th>Bert base</th>\n",
       "      <td>0.92999</td>\n",
       "      <td>0.74690</td>\n",
       "      <td>0.59415</td>\n",
       "      <td>0.93156</td>\n",
       "      <td>0.74900</td>\n",
       "      <td>0.60533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bert Avarage</th>\n",
       "      <td>0.93938</td>\n",
       "      <td>0.75085</td>\n",
       "      <td>0.59399</td>\n",
       "      <td>0.94078</td>\n",
       "      <td>0.75300</td>\n",
       "      <td>0.60600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atalaya</th>\n",
       "      <td>0.90158</td>\n",
       "      <td>0.74002</td>\n",
       "      <td>0.47074</td>\n",
       "      <td>0.90389</td>\n",
       "      <td>0.74300</td>\n",
       "      <td>0.50800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPT2 base</th>\n",
       "      <td>0.80546</td>\n",
       "      <td>0.73562</td>\n",
       "      <td>0.43600</td>\n",
       "      <td>0.80956</td>\n",
       "      <td>0.73900</td>\n",
       "      <td>0.49067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">Traditional</th>\n",
       "      <th>Multi-layer Perceptron classifier</th>\n",
       "      <td>0.78679</td>\n",
       "      <td>0.71006</td>\n",
       "      <td>0.51049</td>\n",
       "      <td>0.79989</td>\n",
       "      <td>0.72500</td>\n",
       "      <td>0.52600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Classifier</th>\n",
       "      <td>0.87636</td>\n",
       "      <td>0.71097</td>\n",
       "      <td>0.48698</td>\n",
       "      <td>0.88067</td>\n",
       "      <td>0.71800</td>\n",
       "      <td>0.51333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial Naive Bayes classifier</th>\n",
       "      <td>0.81284</td>\n",
       "      <td>0.73487</td>\n",
       "      <td>0.47697</td>\n",
       "      <td>0.82067</td>\n",
       "      <td>0.74200</td>\n",
       "      <td>0.50400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Classification</th>\n",
       "      <td>0.95552</td>\n",
       "      <td>0.73191</td>\n",
       "      <td>0.44543</td>\n",
       "      <td>0.95678</td>\n",
       "      <td>0.74200</td>\n",
       "      <td>0.48467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost classifier</th>\n",
       "      <td>0.76402</td>\n",
       "      <td>0.72179</td>\n",
       "      <td>0.42943</td>\n",
       "      <td>0.77878</td>\n",
       "      <td>0.73600</td>\n",
       "      <td>0.46800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bernoulli Naive Bayes classifier</th>\n",
       "      <td>0.81929</td>\n",
       "      <td>0.73645</td>\n",
       "      <td>0.41992</td>\n",
       "      <td>0.82444</td>\n",
       "      <td>0.74000</td>\n",
       "      <td>0.47400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest classifier</th>\n",
       "      <td>0.99897</td>\n",
       "      <td>0.74720</td>\n",
       "      <td>0.39627</td>\n",
       "      <td>0.99900</td>\n",
       "      <td>0.75400</td>\n",
       "      <td>0.45567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dummy Classifier</th>\n",
       "      <td>0.36696</td>\n",
       "      <td>0.36427</td>\n",
       "      <td>0.36709</td>\n",
       "      <td>0.57967</td>\n",
       "      <td>0.57300</td>\n",
       "      <td>0.58000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">Traditional Best</th>\n",
       "      <th>Multi-layer Perceptron classifier (best)</th>\n",
       "      <td>0.81200</td>\n",
       "      <td>0.72553</td>\n",
       "      <td>0.50020</td>\n",
       "      <td>0.82011</td>\n",
       "      <td>0.73300</td>\n",
       "      <td>0.52267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial Naive Bayes classifier (best)</th>\n",
       "      <td>0.81622</td>\n",
       "      <td>0.73487</td>\n",
       "      <td>0.47901</td>\n",
       "      <td>0.82344</td>\n",
       "      <td>0.74200</td>\n",
       "      <td>0.50633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Classifier (best)</th>\n",
       "      <td>0.83368</td>\n",
       "      <td>0.73129</td>\n",
       "      <td>0.47851</td>\n",
       "      <td>0.84156</td>\n",
       "      <td>0.74000</td>\n",
       "      <td>0.50633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Classification (best)</th>\n",
       "      <td>0.95407</td>\n",
       "      <td>0.73356</td>\n",
       "      <td>0.44851</td>\n",
       "      <td>0.95533</td>\n",
       "      <td>0.74200</td>\n",
       "      <td>0.48733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bernoulli Naive Bayes classifier (best)</th>\n",
       "      <td>0.81365</td>\n",
       "      <td>0.73823</td>\n",
       "      <td>0.43153</td>\n",
       "      <td>0.81978</td>\n",
       "      <td>0.74200</td>\n",
       "      <td>0.48100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost classifier (best)</th>\n",
       "      <td>0.77103</td>\n",
       "      <td>0.72652</td>\n",
       "      <td>0.42540</td>\n",
       "      <td>0.78522</td>\n",
       "      <td>0.74000</td>\n",
       "      <td>0.46667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest classifier (best)</th>\n",
       "      <td>0.99772</td>\n",
       "      <td>0.74220</td>\n",
       "      <td>0.39346</td>\n",
       "      <td>0.99778</td>\n",
       "      <td>0.74800</td>\n",
       "      <td>0.45700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"18\" valign=\"top\">Spanish</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">Deep Learning</th>\n",
       "      <th>Bert Avarage</th>\n",
       "      <td>0.98353</td>\n",
       "      <td>0.83122</td>\n",
       "      <td>0.74574</td>\n",
       "      <td>0.98400</td>\n",
       "      <td>0.83200</td>\n",
       "      <td>0.74687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bert base</th>\n",
       "      <td>0.95920</td>\n",
       "      <td>0.83318</td>\n",
       "      <td>0.74132</td>\n",
       "      <td>0.96022</td>\n",
       "      <td>0.83400</td>\n",
       "      <td>0.74250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atalaya</th>\n",
       "      <td>0.94656</td>\n",
       "      <td>0.73970</td>\n",
       "      <td>0.70826</td>\n",
       "      <td>0.94800</td>\n",
       "      <td>0.74200</td>\n",
       "      <td>0.71125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">Traditional</th>\n",
       "      <th>Ridge Classifier</th>\n",
       "      <td>0.94179</td>\n",
       "      <td>0.74015</td>\n",
       "      <td>0.69866</td>\n",
       "      <td>0.94378</td>\n",
       "      <td>0.74600</td>\n",
       "      <td>0.70375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Classification</th>\n",
       "      <td>0.97568</td>\n",
       "      <td>0.75159</td>\n",
       "      <td>0.69784</td>\n",
       "      <td>0.97644</td>\n",
       "      <td>0.76000</td>\n",
       "      <td>0.70875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multi-layer Perceptron classifier</th>\n",
       "      <td>0.90000</td>\n",
       "      <td>0.74864</td>\n",
       "      <td>0.69751</td>\n",
       "      <td>0.90400</td>\n",
       "      <td>0.75400</td>\n",
       "      <td>0.70625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest classifier</th>\n",
       "      <td>0.99771</td>\n",
       "      <td>0.77751</td>\n",
       "      <td>0.68993</td>\n",
       "      <td>0.99778</td>\n",
       "      <td>0.78200</td>\n",
       "      <td>0.69750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial Naive Bayes classifier</th>\n",
       "      <td>0.86123</td>\n",
       "      <td>0.73205</td>\n",
       "      <td>0.68504</td>\n",
       "      <td>0.87000</td>\n",
       "      <td>0.74800</td>\n",
       "      <td>0.70375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost classifier</th>\n",
       "      <td>0.77327</td>\n",
       "      <td>0.75159</td>\n",
       "      <td>0.66419</td>\n",
       "      <td>0.78711</td>\n",
       "      <td>0.76000</td>\n",
       "      <td>0.67688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bernoulli Naive Bayes classifier</th>\n",
       "      <td>0.87582</td>\n",
       "      <td>0.76414</td>\n",
       "      <td>0.65404</td>\n",
       "      <td>0.88022</td>\n",
       "      <td>0.76800</td>\n",
       "      <td>0.66000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dummy Classifier</th>\n",
       "      <td>0.37001</td>\n",
       "      <td>0.35733</td>\n",
       "      <td>0.37008</td>\n",
       "      <td>0.58733</td>\n",
       "      <td>0.55600</td>\n",
       "      <td>0.58750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">Traditional Best</th>\n",
       "      <th>Multi-layer Perceptron classifier (best)</th>\n",
       "      <td>0.92631</td>\n",
       "      <td>0.73197</td>\n",
       "      <td>0.70015</td>\n",
       "      <td>0.92867</td>\n",
       "      <td>0.73800</td>\n",
       "      <td>0.70813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Classifier (best)</th>\n",
       "      <td>0.90766</td>\n",
       "      <td>0.74703</td>\n",
       "      <td>0.69866</td>\n",
       "      <td>0.91156</td>\n",
       "      <td>0.75400</td>\n",
       "      <td>0.70625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Classification (best)</th>\n",
       "      <td>0.91948</td>\n",
       "      <td>0.74733</td>\n",
       "      <td>0.69406</td>\n",
       "      <td>0.92222</td>\n",
       "      <td>0.75200</td>\n",
       "      <td>0.69875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial Naive Bayes classifier (best)</th>\n",
       "      <td>0.88361</td>\n",
       "      <td>0.73847</td>\n",
       "      <td>0.69320</td>\n",
       "      <td>0.88933</td>\n",
       "      <td>0.75000</td>\n",
       "      <td>0.70625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bernoulli Naive Bayes classifier (best)</th>\n",
       "      <td>0.88969</td>\n",
       "      <td>0.76292</td>\n",
       "      <td>0.69093</td>\n",
       "      <td>0.89289</td>\n",
       "      <td>0.76600</td>\n",
       "      <td>0.69437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest classifier (best)</th>\n",
       "      <td>0.99565</td>\n",
       "      <td>0.77679</td>\n",
       "      <td>0.68362</td>\n",
       "      <td>0.99578</td>\n",
       "      <td>0.78000</td>\n",
       "      <td>0.68812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost classifier (best)</th>\n",
       "      <td>0.85434</td>\n",
       "      <td>0.73692</td>\n",
       "      <td>0.67729</td>\n",
       "      <td>0.86133</td>\n",
       "      <td>0.74400</td>\n",
       "      <td>0.68437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                              F1  \\\n",
       "                                                                                           Train   \n",
       "Task              Lenguage Group              Name                                                 \n",
       "Detoxis Task1     Spanish  Deep Learning      Bert base (3 epochs)                       0.85899   \n",
       "                                              Bert Avarage                               0.98041   \n",
       "                                              Bert base (4 epochs)                       0.95833   \n",
       "                                              Bert base (2 epochs)                       0.67094   \n",
       "                                              Atalaya                                    0.34249   \n",
       "                           Sbert              Multi-layer Perceptron classifier          0.65392   \n",
       "                                              Ridge Classifier                           0.62939   \n",
       "                                              Support Vector Classification              0.82315   \n",
       "                                              AdaBoost classifier                        0.64030   \n",
       "                                              Random Forest classifier                   0.99944   \n",
       "                           Sbert Best         Support Vector Classification (best)       0.99778   \n",
       "                                              Ridge Classifier (best)                    0.65409   \n",
       "                                              Multi-layer Perceptron classifier (best)   0.54848   \n",
       "                                              AdaBoost classifier (best)                 0.88953   \n",
       "                                              Random Forest classifier (best)            0.86962   \n",
       "                           Sbert Oversampling Ridge SMOBD                                0.69273   \n",
       "                                              MLP SMOTE_TomekLinks                       0.74348   \n",
       "                                              Ridge G_SMOTE                              0.69433   \n",
       "                                              Ridge SMOTE_TomekLinks                     0.68725   \n",
       "                                              Ridge SMOTE_IPF                            0.68886   \n",
       "                                              Ridge Assembled_SMOTE                      0.69830   \n",
       "                                              Ridge polynom_fit_SMOTE                    0.69402   \n",
       "                                              MLP Assembled_SMOTE                        0.72934   \n",
       "                                              MLP SMOBD                                  0.95233   \n",
       "                                              SVC SMOBD                                  0.90523   \n",
       "                                              MLP LVQ_SMOTE                              0.69575   \n",
       "                                              Ridge ProWSyn                              0.69336   \n",
       "                                              SVC G_SMOTE                                0.90731   \n",
       "                                              MLP SMOTE_IPF                              0.88106   \n",
       "                                              Ridge LVQ_SMOTE                            0.64858   \n",
       "                                              SVC SMOTE_IPF                              0.91327   \n",
       "                                              MLP G_SMOTE                                0.92385   \n",
       "                                              SVC ProWSyn                                0.90376   \n",
       "                                              SVC Assembled_SMOTE                        0.91097   \n",
       "                                              SVC SMOTE_TomekLinks                       0.90940   \n",
       "                                              MLP ProWSyn                                0.92675   \n",
       "                                              MLP polynom_fit_SMOTE                      0.91958   \n",
       "                                              SVC LVQ_SMOTE                              0.84950   \n",
       "                                              SVC polynom_fit_SMOTE                      0.86547   \n",
       "                                              Ridge CCR                                  0.39089   \n",
       "                                              MLP CCR                                    0.11922   \n",
       "                                              SVC CCR                                    0.04126   \n",
       "                           Traditional        Ridge Classifier                           0.82495   \n",
       "                                              Bernoulli Naive Bayes classifier           0.66345   \n",
       "                                              AdaBoost classifier                        0.30435   \n",
       "                                              Random Forest classifier                   0.97798   \n",
       "                                              Multinomial Naive Bayes classifier         0.27011   \n",
       "                                              Support Vector Classification              0.86612   \n",
       "                                              Dummy Classifier                           0.00000   \n",
       "                                              Multi-layer Perceptron classifier          0.03704   \n",
       "                           Traditional Best   Dummy Classifier (best)                    0.49087   \n",
       "                                              AdaBoost classifier (best)                 0.49262   \n",
       "                                              Random Forest classifier (best)            0.72641   \n",
       "                                              Bernoulli Naive Bayes classifier (best)    0.76141   \n",
       "                                              Ridge Classifier (best)                    0.95722   \n",
       "                                              Support Vector Classification (best)       0.88662   \n",
       "                                              Multinomial Naive Bayes classifier (best)  0.77249   \n",
       "                                              Multi-layer Perceptron classifier (best)   0.00000   \n",
       "Hateval2019 Task1 English  Bert Avarage       CLS layers                                 0.93160   \n",
       "                                              Entire layer                               0.94064   \n",
       "                                              Tokens                                     0.93611   \n",
       "                           Deep Learning      Bert base                                  0.92999   \n",
       "                                              Bert Avarage                               0.93938   \n",
       "                                              Atalaya                                    0.90158   \n",
       "                                              GPT2 base                                  0.80546   \n",
       "                           Traditional        Multi-layer Perceptron classifier          0.78679   \n",
       "                                              Ridge Classifier                           0.87636   \n",
       "                                              Multinomial Naive Bayes classifier         0.81284   \n",
       "                                              Support Vector Classification              0.95552   \n",
       "                                              AdaBoost classifier                        0.76402   \n",
       "                                              Bernoulli Naive Bayes classifier           0.81929   \n",
       "                                              Random Forest classifier                   0.99897   \n",
       "                                              Dummy Classifier                           0.36696   \n",
       "                           Traditional Best   Multi-layer Perceptron classifier (best)   0.81200   \n",
       "                                              Multinomial Naive Bayes classifier (best)  0.81622   \n",
       "                                              Ridge Classifier (best)                    0.83368   \n",
       "                                              Support Vector Classification (best)       0.95407   \n",
       "                                              Bernoulli Naive Bayes classifier (best)    0.81365   \n",
       "                                              AdaBoost classifier (best)                 0.77103   \n",
       "                                              Random Forest classifier (best)            0.99772   \n",
       "                  Spanish  Deep Learning      Bert Avarage                               0.98353   \n",
       "                                              Bert base                                  0.95920   \n",
       "                                              Atalaya                                    0.94656   \n",
       "                           Traditional        Ridge Classifier                           0.94179   \n",
       "                                              Support Vector Classification              0.97568   \n",
       "                                              Multi-layer Perceptron classifier          0.90000   \n",
       "                                              Random Forest classifier                   0.99771   \n",
       "                                              Multinomial Naive Bayes classifier         0.86123   \n",
       "                                              AdaBoost classifier                        0.77327   \n",
       "                                              Bernoulli Naive Bayes classifier           0.87582   \n",
       "                                              Dummy Classifier                           0.37001   \n",
       "                           Traditional Best   Multi-layer Perceptron classifier (best)   0.92631   \n",
       "                                              Ridge Classifier (best)                    0.90766   \n",
       "                                              Support Vector Classification (best)       0.91948   \n",
       "                                              Multinomial Naive Bayes classifier (best)  0.88361   \n",
       "                                              Bernoulli Naive Bayes classifier (best)    0.88969   \n",
       "                                              Random Forest classifier (best)            0.99565   \n",
       "                                              AdaBoost classifier (best)                 0.85434   \n",
       "\n",
       "                                                                                                  \\\n",
       "                                                                                             Dev   \n",
       "Task              Lenguage Group              Name                                                 \n",
       "Detoxis Task1     Spanish  Deep Learning      Bert base (3 epochs)                       0.65471   \n",
       "                                              Bert Avarage                               0.64819   \n",
       "                                              Bert base (4 epochs)                       0.64069   \n",
       "                                              Bert base (2 epochs)                       0.61283   \n",
       "                                              Atalaya                                    0.06792   \n",
       "                           Sbert              Multi-layer Perceptron classifier          0.61072   \n",
       "                                              Ridge Classifier                           0.57985   \n",
       "                                              Support Vector Classification              0.56000   \n",
       "                                              AdaBoost classifier                        0.50575   \n",
       "                                              Random Forest classifier                   0.29352   \n",
       "                           Sbert Best         Support Vector Classification (best)       0.59722   \n",
       "                                              Ridge Classifier (best)                    0.57957   \n",
       "                                              Multi-layer Perceptron classifier (best)   0.55208   \n",
       "                                              AdaBoost classifier (best)                 0.54505   \n",
       "                                              Random Forest classifier (best)            0.36788   \n",
       "                           Sbert Oversampling Ridge SMOBD                                0.66038   \n",
       "                                              MLP SMOTE_TomekLinks                       0.66019   \n",
       "                                              Ridge G_SMOTE                              0.65672   \n",
       "                                              Ridge SMOTE_TomekLinks                     0.65291   \n",
       "                                              Ridge SMOTE_IPF                            0.65028   \n",
       "                                              Ridge Assembled_SMOTE                      0.64540   \n",
       "                                              Ridge polynom_fit_SMOTE                    0.64060   \n",
       "                                              MLP Assembled_SMOTE                        0.63315   \n",
       "                                              MLP SMOBD                                  0.62979   \n",
       "                                              SVC SMOBD                                  0.62559   \n",
       "                                              MLP LVQ_SMOTE                              0.62343   \n",
       "                                              Ridge ProWSyn                              0.62197   \n",
       "                                              SVC G_SMOTE                                0.62053   \n",
       "                                              MLP SMOTE_IPF                              0.61983   \n",
       "                                              Ridge LVQ_SMOTE                            0.61915   \n",
       "                                              SVC SMOTE_IPF                              0.61611   \n",
       "                                              MLP G_SMOTE                                0.61339   \n",
       "                                              SVC ProWSyn                                0.61205   \n",
       "                                              SVC Assembled_SMOTE                        0.60766   \n",
       "                                              SVC SMOTE_TomekLinks                       0.60432   \n",
       "                                              MLP ProWSyn                                0.60041   \n",
       "                                              MLP polynom_fit_SMOTE                      0.60000   \n",
       "                                              SVC LVQ_SMOTE                              0.57963   \n",
       "                                              SVC polynom_fit_SMOTE                      0.56383   \n",
       "                                              Ridge CCR                                  0.38527   \n",
       "                                              MLP CCR                                    0.09125   \n",
       "                                              SVC CCR                                    0.03200   \n",
       "                           Traditional        Ridge Classifier                           0.26039   \n",
       "                                              Bernoulli Naive Bayes classifier           0.21605   \n",
       "                                              AdaBoost classifier                        0.16981   \n",
       "                                              Random Forest classifier                   0.15385   \n",
       "                                              Multinomial Naive Bayes classifier         0.03162   \n",
       "                                              Support Vector Classification              0.02381   \n",
       "                                              Dummy Classifier                           0.00000   \n",
       "                                              Multi-layer Perceptron classifier          0.00000   \n",
       "                           Traditional Best   Dummy Classifier (best)                    0.52396   \n",
       "                                              AdaBoost classifier (best)                 0.52081   \n",
       "                                              Random Forest classifier (best)            0.37168   \n",
       "                                              Bernoulli Naive Bayes classifier (best)    0.36145   \n",
       "                                              Ridge Classifier (best)                    0.35841   \n",
       "                                              Support Vector Classification (best)       0.35529   \n",
       "                                              Multinomial Naive Bayes classifier (best)  0.19692   \n",
       "                                              Multi-layer Perceptron classifier (best)   0.00000   \n",
       "Hateval2019 Task1 English  Bert Avarage       CLS layers                                 0.75035   \n",
       "                                              Entire layer                               0.75725   \n",
       "                                              Tokens                                     0.74822   \n",
       "                           Deep Learning      Bert base                                  0.74690   \n",
       "                                              Bert Avarage                               0.75085   \n",
       "                                              Atalaya                                    0.74002   \n",
       "                                              GPT2 base                                  0.73562   \n",
       "                           Traditional        Multi-layer Perceptron classifier          0.71006   \n",
       "                                              Ridge Classifier                           0.71097   \n",
       "                                              Multinomial Naive Bayes classifier         0.73487   \n",
       "                                              Support Vector Classification              0.73191   \n",
       "                                              AdaBoost classifier                        0.72179   \n",
       "                                              Bernoulli Naive Bayes classifier           0.73645   \n",
       "                                              Random Forest classifier                   0.74720   \n",
       "                                              Dummy Classifier                           0.36427   \n",
       "                           Traditional Best   Multi-layer Perceptron classifier (best)   0.72553   \n",
       "                                              Multinomial Naive Bayes classifier (best)  0.73487   \n",
       "                                              Ridge Classifier (best)                    0.73129   \n",
       "                                              Support Vector Classification (best)       0.73356   \n",
       "                                              Bernoulli Naive Bayes classifier (best)    0.73823   \n",
       "                                              AdaBoost classifier (best)                 0.72652   \n",
       "                                              Random Forest classifier (best)            0.74220   \n",
       "                  Spanish  Deep Learning      Bert Avarage                               0.83122   \n",
       "                                              Bert base                                  0.83318   \n",
       "                                              Atalaya                                    0.73970   \n",
       "                           Traditional        Ridge Classifier                           0.74015   \n",
       "                                              Support Vector Classification              0.75159   \n",
       "                                              Multi-layer Perceptron classifier          0.74864   \n",
       "                                              Random Forest classifier                   0.77751   \n",
       "                                              Multinomial Naive Bayes classifier         0.73205   \n",
       "                                              AdaBoost classifier                        0.75159   \n",
       "                                              Bernoulli Naive Bayes classifier           0.76414   \n",
       "                                              Dummy Classifier                           0.35733   \n",
       "                           Traditional Best   Multi-layer Perceptron classifier (best)   0.73197   \n",
       "                                              Ridge Classifier (best)                    0.74703   \n",
       "                                              Support Vector Classification (best)       0.74733   \n",
       "                                              Multinomial Naive Bayes classifier (best)  0.73847   \n",
       "                                              Bernoulli Naive Bayes classifier (best)    0.76292   \n",
       "                                              Random Forest classifier (best)            0.77679   \n",
       "                                              AdaBoost classifier (best)                 0.73692   \n",
       "\n",
       "                                                                                                  \\\n",
       "                                                                                            Test   \n",
       "Task              Lenguage Group              Name                                                 \n",
       "Detoxis Task1     Spanish  Deep Learning      Bert base (3 epochs)                           NaN   \n",
       "                                              Bert Avarage                                   NaN   \n",
       "                                              Bert base (4 epochs)                           NaN   \n",
       "                                              Bert base (2 epochs)                           NaN   \n",
       "                                              Atalaya                                        NaN   \n",
       "                           Sbert              Multi-layer Perceptron classifier              NaN   \n",
       "                                              Ridge Classifier                               NaN   \n",
       "                                              Support Vector Classification                  NaN   \n",
       "                                              AdaBoost classifier                            NaN   \n",
       "                                              Random Forest classifier                       NaN   \n",
       "                           Sbert Best         Support Vector Classification (best)           NaN   \n",
       "                                              Ridge Classifier (best)                        NaN   \n",
       "                                              Multi-layer Perceptron classifier (best)       NaN   \n",
       "                                              AdaBoost classifier (best)                     NaN   \n",
       "                                              Random Forest classifier (best)                NaN   \n",
       "                           Sbert Oversampling Ridge SMOBD                                    NaN   \n",
       "                                              MLP SMOTE_TomekLinks                           NaN   \n",
       "                                              Ridge G_SMOTE                                  NaN   \n",
       "                                              Ridge SMOTE_TomekLinks                         NaN   \n",
       "                                              Ridge SMOTE_IPF                                NaN   \n",
       "                                              Ridge Assembled_SMOTE                          NaN   \n",
       "                                              Ridge polynom_fit_SMOTE                        NaN   \n",
       "                                              MLP Assembled_SMOTE                            NaN   \n",
       "                                              MLP SMOBD                                      NaN   \n",
       "                                              SVC SMOBD                                      NaN   \n",
       "                                              MLP LVQ_SMOTE                                  NaN   \n",
       "                                              Ridge ProWSyn                                  NaN   \n",
       "                                              SVC G_SMOTE                                    NaN   \n",
       "                                              MLP SMOTE_IPF                                  NaN   \n",
       "                                              Ridge LVQ_SMOTE                                NaN   \n",
       "                                              SVC SMOTE_IPF                                  NaN   \n",
       "                                              MLP G_SMOTE                                    NaN   \n",
       "                                              SVC ProWSyn                                    NaN   \n",
       "                                              SVC Assembled_SMOTE                            NaN   \n",
       "                                              SVC SMOTE_TomekLinks                           NaN   \n",
       "                                              MLP ProWSyn                                    NaN   \n",
       "                                              MLP polynom_fit_SMOTE                          NaN   \n",
       "                                              SVC LVQ_SMOTE                                  NaN   \n",
       "                                              SVC polynom_fit_SMOTE                          NaN   \n",
       "                                              Ridge CCR                                      NaN   \n",
       "                                              MLP CCR                                        NaN   \n",
       "                                              SVC CCR                                        NaN   \n",
       "                           Traditional        Ridge Classifier                               NaN   \n",
       "                                              Bernoulli Naive Bayes classifier               NaN   \n",
       "                                              AdaBoost classifier                            NaN   \n",
       "                                              Random Forest classifier                       NaN   \n",
       "                                              Multinomial Naive Bayes classifier             NaN   \n",
       "                                              Support Vector Classification                  NaN   \n",
       "                                              Dummy Classifier                               NaN   \n",
       "                                              Multi-layer Perceptron classifier              NaN   \n",
       "                           Traditional Best   Dummy Classifier (best)                        NaN   \n",
       "                                              AdaBoost classifier (best)                     NaN   \n",
       "                                              Random Forest classifier (best)                NaN   \n",
       "                                              Bernoulli Naive Bayes classifier (best)        NaN   \n",
       "                                              Ridge Classifier (best)                        NaN   \n",
       "                                              Support Vector Classification (best)           NaN   \n",
       "                                              Multinomial Naive Bayes classifier (best)      NaN   \n",
       "                                              Multi-layer Perceptron classifier (best)       NaN   \n",
       "Hateval2019 Task1 English  Bert Avarage       CLS layers                                 0.58977   \n",
       "                                              Entire layer                               0.58663   \n",
       "                                              Tokens                                     0.58653   \n",
       "                           Deep Learning      Bert base                                  0.59415   \n",
       "                                              Bert Avarage                               0.59399   \n",
       "                                              Atalaya                                    0.47074   \n",
       "                                              GPT2 base                                  0.43600   \n",
       "                           Traditional        Multi-layer Perceptron classifier          0.51049   \n",
       "                                              Ridge Classifier                           0.48698   \n",
       "                                              Multinomial Naive Bayes classifier         0.47697   \n",
       "                                              Support Vector Classification              0.44543   \n",
       "                                              AdaBoost classifier                        0.42943   \n",
       "                                              Bernoulli Naive Bayes classifier           0.41992   \n",
       "                                              Random Forest classifier                   0.39627   \n",
       "                                              Dummy Classifier                           0.36709   \n",
       "                           Traditional Best   Multi-layer Perceptron classifier (best)   0.50020   \n",
       "                                              Multinomial Naive Bayes classifier (best)  0.47901   \n",
       "                                              Ridge Classifier (best)                    0.47851   \n",
       "                                              Support Vector Classification (best)       0.44851   \n",
       "                                              Bernoulli Naive Bayes classifier (best)    0.43153   \n",
       "                                              AdaBoost classifier (best)                 0.42540   \n",
       "                                              Random Forest classifier (best)            0.39346   \n",
       "                  Spanish  Deep Learning      Bert Avarage                               0.74574   \n",
       "                                              Bert base                                  0.74132   \n",
       "                                              Atalaya                                    0.70826   \n",
       "                           Traditional        Ridge Classifier                           0.69866   \n",
       "                                              Support Vector Classification              0.69784   \n",
       "                                              Multi-layer Perceptron classifier          0.69751   \n",
       "                                              Random Forest classifier                   0.68993   \n",
       "                                              Multinomial Naive Bayes classifier         0.68504   \n",
       "                                              AdaBoost classifier                        0.66419   \n",
       "                                              Bernoulli Naive Bayes classifier           0.65404   \n",
       "                                              Dummy Classifier                           0.37008   \n",
       "                           Traditional Best   Multi-layer Perceptron classifier (best)   0.70015   \n",
       "                                              Ridge Classifier (best)                    0.69866   \n",
       "                                              Support Vector Classification (best)       0.69406   \n",
       "                                              Multinomial Naive Bayes classifier (best)  0.69320   \n",
       "                                              Bernoulli Naive Bayes classifier (best)    0.69093   \n",
       "                                              Random Forest classifier (best)            0.68362   \n",
       "                                              AdaBoost classifier (best)                 0.67729   \n",
       "\n",
       "                                                                                        Accuracy  \\\n",
       "                                                                                           Train   \n",
       "Task              Lenguage Group              Name                                                 \n",
       "Detoxis Task1     Spanish  Deep Learning      Bert base (3 epochs)                       0.91336   \n",
       "                                              Bert Avarage                               0.98736   \n",
       "                                              Bert base (4 epochs)                       0.97329   \n",
       "                                              Bert base (2 epochs)                       0.81480   \n",
       "                                              Atalaya                                    0.74079   \n",
       "                           Sbert              Multi-layer Perceptron classifier          0.79747   \n",
       "                                              Ridge Classifier                           0.79422   \n",
       "                                              Support Vector Classification              0.90072   \n",
       "                                              AdaBoost classifier                        0.78989   \n",
       "                                              Random Forest classifier                   0.99964   \n",
       "                           Sbert Best         Support Vector Classification (best)       0.99856   \n",
       "                                              Ridge Classifier (best)                    0.80144   \n",
       "                                              Multi-layer Perceptron classifier (best)   0.76462   \n",
       "                                              AdaBoost classifier (best)                 0.93141   \n",
       "                                              Random Forest classifier (best)            0.92130   \n",
       "                           Sbert Oversampling Ridge SMOBD                                0.77870   \n",
       "                                              MLP SMOTE_TomekLinks                       0.82238   \n",
       "                                              Ridge G_SMOTE                              0.78195   \n",
       "                                              Ridge SMOTE_TomekLinks                     0.77690   \n",
       "                                              Ridge SMOTE_IPF                            0.77726   \n",
       "                                              Ridge Assembled_SMOTE                      0.78195   \n",
       "                                              Ridge polynom_fit_SMOTE                    0.78195   \n",
       "                                              MLP Assembled_SMOTE                        0.80253   \n",
       "                                              MLP SMOBD                                  0.96859   \n",
       "                                              SVC SMOBD                                  0.94043   \n",
       "                                              MLP LVQ_SMOTE                              0.80614   \n",
       "                                              Ridge ProWSyn                              0.78159   \n",
       "                                              SVC G_SMOTE                                0.94188   \n",
       "                                              MLP SMOTE_IPF                              0.92202   \n",
       "                                              Ridge LVQ_SMOTE                            0.78484   \n",
       "                                              SVC SMOTE_IPF                              0.94549   \n",
       "                                              MLP G_SMOTE                                0.95090   \n",
       "                                              SVC ProWSyn                                0.94079   \n",
       "                                              SVC Assembled_SMOTE                        0.94404   \n",
       "                                              SVC SMOTE_TomekLinks                       0.94296   \n",
       "                                              MLP ProWSyn                                0.95235   \n",
       "                                              MLP polynom_fit_SMOTE                      0.94765   \n",
       "                                              SVC LVQ_SMOTE                              0.91264   \n",
       "                                              SVC polynom_fit_SMOTE                      0.92166   \n",
       "                                              Ridge CCR                                  0.71986   \n",
       "                                              MLP CCR                                    0.69061   \n",
       "                                              SVC CCR                                    0.68123   \n",
       "                           Traditional        Ridge Classifier                           0.90072   \n",
       "                                              Bernoulli Naive Bayes classifier           0.82347   \n",
       "                                              AdaBoost classifier                        0.71119   \n",
       "                                              Random Forest classifier                   0.98592   \n",
       "                                              Multinomial Naive Bayes classifier         0.72491   \n",
       "                                              Support Vector Classification              0.92310   \n",
       "                                              Dummy Classifier                           0.67473   \n",
       "                                              Multi-layer Perceptron classifier          0.68087   \n",
       "                           Traditional Best   Dummy Classifier (best)                    0.32527   \n",
       "                                              AdaBoost classifier (best)                 0.32996   \n",
       "                                              Random Forest classifier (best)            0.83357   \n",
       "                                              Bernoulli Naive Bayes classifier (best)    0.81877   \n",
       "                                              Ridge Classifier (best)                    0.97292   \n",
       "                                              Support Vector Classification (best)       0.92780   \n",
       "                                              Multinomial Naive Bayes classifier (best)  0.87581   \n",
       "                                              Multi-layer Perceptron classifier (best)   0.67473   \n",
       "Hateval2019 Task1 English  Bert Avarage       CLS layers                                 0.93311   \n",
       "                                              Entire layer                               0.94200   \n",
       "                                              Tokens                                     0.93744   \n",
       "                           Deep Learning      Bert base                                  0.93156   \n",
       "                                              Bert Avarage                               0.94078   \n",
       "                                              Atalaya                                    0.90389   \n",
       "                                              GPT2 base                                  0.80956   \n",
       "                           Traditional        Multi-layer Perceptron classifier          0.79989   \n",
       "                                              Ridge Classifier                           0.88067   \n",
       "                                              Multinomial Naive Bayes classifier         0.82067   \n",
       "                                              Support Vector Classification              0.95678   \n",
       "                                              AdaBoost classifier                        0.77878   \n",
       "                                              Bernoulli Naive Bayes classifier           0.82444   \n",
       "                                              Random Forest classifier                   0.99900   \n",
       "                                              Dummy Classifier                           0.57967   \n",
       "                           Traditional Best   Multi-layer Perceptron classifier (best)   0.82011   \n",
       "                                              Multinomial Naive Bayes classifier (best)  0.82344   \n",
       "                                              Ridge Classifier (best)                    0.84156   \n",
       "                                              Support Vector Classification (best)       0.95533   \n",
       "                                              Bernoulli Naive Bayes classifier (best)    0.81978   \n",
       "                                              AdaBoost classifier (best)                 0.78522   \n",
       "                                              Random Forest classifier (best)            0.99778   \n",
       "                  Spanish  Deep Learning      Bert Avarage                               0.98400   \n",
       "                                              Bert base                                  0.96022   \n",
       "                                              Atalaya                                    0.94800   \n",
       "                           Traditional        Ridge Classifier                           0.94378   \n",
       "                                              Support Vector Classification              0.97644   \n",
       "                                              Multi-layer Perceptron classifier          0.90400   \n",
       "                                              Random Forest classifier                   0.99778   \n",
       "                                              Multinomial Naive Bayes classifier         0.87000   \n",
       "                                              AdaBoost classifier                        0.78711   \n",
       "                                              Bernoulli Naive Bayes classifier           0.88022   \n",
       "                                              Dummy Classifier                           0.58733   \n",
       "                           Traditional Best   Multi-layer Perceptron classifier (best)   0.92867   \n",
       "                                              Ridge Classifier (best)                    0.91156   \n",
       "                                              Support Vector Classification (best)       0.92222   \n",
       "                                              Multinomial Naive Bayes classifier (best)  0.88933   \n",
       "                                              Bernoulli Naive Bayes classifier (best)    0.89289   \n",
       "                                              Random Forest classifier (best)            0.99578   \n",
       "                                              AdaBoost classifier (best)                 0.86133   \n",
       "\n",
       "                                                                                                  \\\n",
       "                                                                                             Dev   \n",
       "Task              Lenguage Group              Name                                                 \n",
       "Detoxis Task1     Spanish  Deep Learning      Bert base (3 epochs)                       0.77778   \n",
       "                                              Bert Avarage                               0.76190   \n",
       "                                              Bert base (4 epochs)                       0.76046   \n",
       "                                              Bert base (2 epochs)                       0.76479   \n",
       "                                              Atalaya                                    0.64358   \n",
       "                           Sbert              Multi-layer Perceptron classifier          0.75902   \n",
       "                                              Ridge Classifier                           0.75325   \n",
       "                                              Support Vector Classification              0.76190   \n",
       "                                              AdaBoost classifier                        0.68975   \n",
       "                                              Random Forest classifier                   0.70130   \n",
       "                           Sbert Best         Support Vector Classification (best)       0.74892   \n",
       "                                              Ridge Classifier (best)                    0.74459   \n",
       "                                              Multi-layer Perceptron classifier (best)   0.75180   \n",
       "                                              AdaBoost classifier (best)                 0.70851   \n",
       "                                              Random Forest classifier (best)            0.64791   \n",
       "                           Sbert Oversampling Ridge SMOBD                                0.74026   \n",
       "                                              MLP SMOTE_TomekLinks                       0.74747   \n",
       "                                              Ridge G_SMOTE                              0.73449   \n",
       "                                              Ridge SMOTE_TomekLinks                     0.73304   \n",
       "                                              Ridge SMOTE_IPF                            0.73304   \n",
       "                                              Ridge Assembled_SMOTE                      0.72727   \n",
       "                                              Ridge polynom_fit_SMOTE                    0.72150   \n",
       "                                              MLP Assembled_SMOTE                        0.71573   \n",
       "                                              MLP SMOBD                                  0.74892   \n",
       "                                              SVC SMOBD                                  0.77201   \n",
       "                                              MLP LVQ_SMOTE                              0.74026   \n",
       "                                              Ridge ProWSyn                              0.70707   \n",
       "                                              SVC G_SMOTE                                0.77056   \n",
       "                                              MLP SMOTE_IPF                              0.73449   \n",
       "                                              Ridge LVQ_SMOTE                            0.75325   \n",
       "                                              SVC SMOTE_IPF                              0.76623   \n",
       "                                              MLP G_SMOTE                                0.74170   \n",
       "                                              SVC ProWSyn                                0.76768   \n",
       "                                              SVC Assembled_SMOTE                        0.76335   \n",
       "                                              SVC SMOTE_TomekLinks                       0.76190   \n",
       "                                              MLP ProWSyn                                0.72150   \n",
       "                                              MLP polynom_fit_SMOTE                      0.72294   \n",
       "                                              SVC LVQ_SMOTE                              0.76768   \n",
       "                                              SVC polynom_fit_SMOTE                      0.76335   \n",
       "                                              Ridge CCR                                  0.68687   \n",
       "                                              MLP CCR                                    0.65512   \n",
       "                                              SVC CCR                                    0.65079   \n",
       "                           Traditional        Ridge Classifier                           0.61472   \n",
       "                                              Bernoulli Naive Bayes classifier           0.63348   \n",
       "                                              AdaBoost classifier                        0.61905   \n",
       "                                              Random Forest classifier                   0.61905   \n",
       "                                              Multinomial Naive Bayes classifier         0.64646   \n",
       "                                              Support Vector Classification              0.64502   \n",
       "                                              Dummy Classifier                           0.64502   \n",
       "                                              Multi-layer Perceptron classifier          0.64214   \n",
       "                           Traditional Best   Dummy Classifier (best)                    0.35498   \n",
       "                                              AdaBoost classifier (best)                 0.35209   \n",
       "                                              Random Forest classifier (best)            0.59019   \n",
       "                                              Bernoulli Naive Bayes classifier (best)    0.54113   \n",
       "                                              Ridge Classifier (best)                    0.58153   \n",
       "                                              Support Vector Classification (best)       0.53391   \n",
       "                                              Multinomial Naive Bayes classifier (best)  0.62338   \n",
       "                                              Multi-layer Perceptron classifier (best)   0.64502   \n",
       "Hateval2019 Task1 English  Bert Avarage       CLS layers                                 0.75300   \n",
       "                                              Entire layer                               0.75900   \n",
       "                                              Tokens                                     0.75000   \n",
       "                           Deep Learning      Bert base                                  0.74900   \n",
       "                                              Bert Avarage                               0.75300   \n",
       "                                              Atalaya                                    0.74300   \n",
       "                                              GPT2 base                                  0.73900   \n",
       "                           Traditional        Multi-layer Perceptron classifier          0.72500   \n",
       "                                              Ridge Classifier                           0.71800   \n",
       "                                              Multinomial Naive Bayes classifier         0.74200   \n",
       "                                              Support Vector Classification              0.74200   \n",
       "                                              AdaBoost classifier                        0.73600   \n",
       "                                              Bernoulli Naive Bayes classifier           0.74000   \n",
       "                                              Random Forest classifier                   0.75400   \n",
       "                                              Dummy Classifier                           0.57300   \n",
       "                           Traditional Best   Multi-layer Perceptron classifier (best)   0.73300   \n",
       "                                              Multinomial Naive Bayes classifier (best)  0.74200   \n",
       "                                              Ridge Classifier (best)                    0.74000   \n",
       "                                              Support Vector Classification (best)       0.74200   \n",
       "                                              Bernoulli Naive Bayes classifier (best)    0.74200   \n",
       "                                              AdaBoost classifier (best)                 0.74000   \n",
       "                                              Random Forest classifier (best)            0.74800   \n",
       "                  Spanish  Deep Learning      Bert Avarage                               0.83200   \n",
       "                                              Bert base                                  0.83400   \n",
       "                                              Atalaya                                    0.74200   \n",
       "                           Traditional        Ridge Classifier                           0.74600   \n",
       "                                              Support Vector Classification              0.76000   \n",
       "                                              Multi-layer Perceptron classifier          0.75400   \n",
       "                                              Random Forest classifier                   0.78200   \n",
       "                                              Multinomial Naive Bayes classifier         0.74800   \n",
       "                                              AdaBoost classifier                        0.76000   \n",
       "                                              Bernoulli Naive Bayes classifier           0.76800   \n",
       "                                              Dummy Classifier                           0.55600   \n",
       "                           Traditional Best   Multi-layer Perceptron classifier (best)   0.73800   \n",
       "                                              Ridge Classifier (best)                    0.75400   \n",
       "                                              Support Vector Classification (best)       0.75200   \n",
       "                                              Multinomial Naive Bayes classifier (best)  0.75000   \n",
       "                                              Bernoulli Naive Bayes classifier (best)    0.76600   \n",
       "                                              Random Forest classifier (best)            0.78000   \n",
       "                                              AdaBoost classifier (best)                 0.74400   \n",
       "\n",
       "                                                                                                  \n",
       "                                                                                            Test  \n",
       "Task              Lenguage Group              Name                                                \n",
       "Detoxis Task1     Spanish  Deep Learning      Bert base (3 epochs)                           NaN  \n",
       "                                              Bert Avarage                                   NaN  \n",
       "                                              Bert base (4 epochs)                           NaN  \n",
       "                                              Bert base (2 epochs)                           NaN  \n",
       "                                              Atalaya                                        NaN  \n",
       "                           Sbert              Multi-layer Perceptron classifier              NaN  \n",
       "                                              Ridge Classifier                               NaN  \n",
       "                                              Support Vector Classification                  NaN  \n",
       "                                              AdaBoost classifier                            NaN  \n",
       "                                              Random Forest classifier                       NaN  \n",
       "                           Sbert Best         Support Vector Classification (best)           NaN  \n",
       "                                              Ridge Classifier (best)                        NaN  \n",
       "                                              Multi-layer Perceptron classifier (best)       NaN  \n",
       "                                              AdaBoost classifier (best)                     NaN  \n",
       "                                              Random Forest classifier (best)                NaN  \n",
       "                           Sbert Oversampling Ridge SMOBD                                    NaN  \n",
       "                                              MLP SMOTE_TomekLinks                           NaN  \n",
       "                                              Ridge G_SMOTE                                  NaN  \n",
       "                                              Ridge SMOTE_TomekLinks                         NaN  \n",
       "                                              Ridge SMOTE_IPF                                NaN  \n",
       "                                              Ridge Assembled_SMOTE                          NaN  \n",
       "                                              Ridge polynom_fit_SMOTE                        NaN  \n",
       "                                              MLP Assembled_SMOTE                            NaN  \n",
       "                                              MLP SMOBD                                      NaN  \n",
       "                                              SVC SMOBD                                      NaN  \n",
       "                                              MLP LVQ_SMOTE                                  NaN  \n",
       "                                              Ridge ProWSyn                                  NaN  \n",
       "                                              SVC G_SMOTE                                    NaN  \n",
       "                                              MLP SMOTE_IPF                                  NaN  \n",
       "                                              Ridge LVQ_SMOTE                                NaN  \n",
       "                                              SVC SMOTE_IPF                                  NaN  \n",
       "                                              MLP G_SMOTE                                    NaN  \n",
       "                                              SVC ProWSyn                                    NaN  \n",
       "                                              SVC Assembled_SMOTE                            NaN  \n",
       "                                              SVC SMOTE_TomekLinks                           NaN  \n",
       "                                              MLP ProWSyn                                    NaN  \n",
       "                                              MLP polynom_fit_SMOTE                          NaN  \n",
       "                                              SVC LVQ_SMOTE                                  NaN  \n",
       "                                              SVC polynom_fit_SMOTE                          NaN  \n",
       "                                              Ridge CCR                                      NaN  \n",
       "                                              MLP CCR                                        NaN  \n",
       "                                              SVC CCR                                        NaN  \n",
       "                           Traditional        Ridge Classifier                               NaN  \n",
       "                                              Bernoulli Naive Bayes classifier               NaN  \n",
       "                                              AdaBoost classifier                            NaN  \n",
       "                                              Random Forest classifier                       NaN  \n",
       "                                              Multinomial Naive Bayes classifier             NaN  \n",
       "                                              Support Vector Classification                  NaN  \n",
       "                                              Dummy Classifier                               NaN  \n",
       "                                              Multi-layer Perceptron classifier              NaN  \n",
       "                           Traditional Best   Dummy Classifier (best)                        NaN  \n",
       "                                              AdaBoost classifier (best)                     NaN  \n",
       "                                              Random Forest classifier (best)                NaN  \n",
       "                                              Bernoulli Naive Bayes classifier (best)        NaN  \n",
       "                                              Ridge Classifier (best)                        NaN  \n",
       "                                              Support Vector Classification (best)           NaN  \n",
       "                                              Multinomial Naive Bayes classifier (best)      NaN  \n",
       "                                              Multi-layer Perceptron classifier (best)       NaN  \n",
       "Hateval2019 Task1 English  Bert Avarage       CLS layers                                 0.60267  \n",
       "                                              Entire layer                               0.59933  \n",
       "                                              Tokens                                     0.59900  \n",
       "                           Deep Learning      Bert base                                  0.60533  \n",
       "                                              Bert Avarage                               0.60600  \n",
       "                                              Atalaya                                    0.50800  \n",
       "                                              GPT2 base                                  0.49067  \n",
       "                           Traditional        Multi-layer Perceptron classifier          0.52600  \n",
       "                                              Ridge Classifier                           0.51333  \n",
       "                                              Multinomial Naive Bayes classifier         0.50400  \n",
       "                                              Support Vector Classification              0.48467  \n",
       "                                              AdaBoost classifier                        0.46800  \n",
       "                                              Bernoulli Naive Bayes classifier           0.47400  \n",
       "                                              Random Forest classifier                   0.45567  \n",
       "                                              Dummy Classifier                           0.58000  \n",
       "                           Traditional Best   Multi-layer Perceptron classifier (best)   0.52267  \n",
       "                                              Multinomial Naive Bayes classifier (best)  0.50633  \n",
       "                                              Ridge Classifier (best)                    0.50633  \n",
       "                                              Support Vector Classification (best)       0.48733  \n",
       "                                              Bernoulli Naive Bayes classifier (best)    0.48100  \n",
       "                                              AdaBoost classifier (best)                 0.46667  \n",
       "                                              Random Forest classifier (best)            0.45700  \n",
       "                  Spanish  Deep Learning      Bert Avarage                               0.74687  \n",
       "                                              Bert base                                  0.74250  \n",
       "                                              Atalaya                                    0.71125  \n",
       "                           Traditional        Ridge Classifier                           0.70375  \n",
       "                                              Support Vector Classification              0.70875  \n",
       "                                              Multi-layer Perceptron classifier          0.70625  \n",
       "                                              Random Forest classifier                   0.69750  \n",
       "                                              Multinomial Naive Bayes classifier         0.70375  \n",
       "                                              AdaBoost classifier                        0.67688  \n",
       "                                              Bernoulli Naive Bayes classifier           0.66000  \n",
       "                                              Dummy Classifier                           0.58750  \n",
       "                           Traditional Best   Multi-layer Perceptron classifier (best)   0.70813  \n",
       "                                              Ridge Classifier (best)                    0.70625  \n",
       "                                              Support Vector Classification (best)       0.69875  \n",
       "                                              Multinomial Naive Bayes classifier (best)  0.70625  \n",
       "                                              Bernoulli Naive Bayes classifier (best)    0.69437  \n",
       "                                              Random Forest classifier (best)            0.68812  \n",
       "                                              AdaBoost classifier (best)                 0.68437  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_aggregate = [(lambda t: lambda x: x[:, :, t])(t.title()) for t in dataset_types]\n",
    "\n",
    "df_results_columns = df_results.groupby([\"Task\", \"Lenguage\",'Group','Name'], as_index=False).aggregate(list_aggregate)\n",
    "df_results_columns.columns = pd.MultiIndex.from_product([scores, [t.title() for t in dataset_types]])\n",
    "df_results_columns = df_results_columns.sort_values(by=['Task', 'Lenguage', 'Group', (\"F1\", dataset_types.test.title()), (\"F1\", dataset_types.development.title())], ascending=[True, True, True, False, False])\n",
    "\n",
    "df_results_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92b47aca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">F1</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Dev</th>\n",
       "      <th>Test</th>\n",
       "      <th>Train</th>\n",
       "      <th>Dev</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Task</th>\n",
       "      <th>Lenguage</th>\n",
       "      <th>Group</th>\n",
       "      <th>Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"58\" valign=\"top\">Detoxis Task1</th>\n",
       "      <th rowspan=\"58\" valign=\"top\">Spanish</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">Sbert Oversampling</th>\n",
       "      <th>Ridge SMOBD</th>\n",
       "      <td>0.69273</td>\n",
       "      <td>0.66038</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.77870</td>\n",
       "      <td>0.74026</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP SMOTE_TomekLinks</th>\n",
       "      <td>0.74348</td>\n",
       "      <td>0.66019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.82238</td>\n",
       "      <td>0.74747</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge G_SMOTE</th>\n",
       "      <td>0.69433</td>\n",
       "      <td>0.65672</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.78195</td>\n",
       "      <td>0.73449</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Deep Learning</th>\n",
       "      <th>Bert base (3 epochs)</th>\n",
       "      <td>0.85899</td>\n",
       "      <td>0.65471</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.91336</td>\n",
       "      <td>0.77778</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Sbert Oversampling</th>\n",
       "      <th>Ridge SMOTE_TomekLinks</th>\n",
       "      <td>0.68725</td>\n",
       "      <td>0.65291</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.77690</td>\n",
       "      <td>0.73304</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge SMOTE_IPF</th>\n",
       "      <td>0.68886</td>\n",
       "      <td>0.65028</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.77726</td>\n",
       "      <td>0.73304</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Deep Learning</th>\n",
       "      <th>Bert Avarage</th>\n",
       "      <td>0.98041</td>\n",
       "      <td>0.64819</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.98736</td>\n",
       "      <td>0.76190</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sbert Oversampling</th>\n",
       "      <th>Ridge Assembled_SMOTE</th>\n",
       "      <td>0.69830</td>\n",
       "      <td>0.64540</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.78195</td>\n",
       "      <td>0.72727</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Deep Learning</th>\n",
       "      <th>Bert base (4 epochs)</th>\n",
       "      <td>0.95833</td>\n",
       "      <td>0.64069</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.97329</td>\n",
       "      <td>0.76046</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">Sbert Oversampling</th>\n",
       "      <th>Ridge polynom_fit_SMOTE</th>\n",
       "      <td>0.69402</td>\n",
       "      <td>0.64060</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.78195</td>\n",
       "      <td>0.72150</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP Assembled_SMOTE</th>\n",
       "      <td>0.72934</td>\n",
       "      <td>0.63315</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.80253</td>\n",
       "      <td>0.71573</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP SMOBD</th>\n",
       "      <td>0.95233</td>\n",
       "      <td>0.62979</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.96859</td>\n",
       "      <td>0.74892</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC SMOBD</th>\n",
       "      <td>0.90523</td>\n",
       "      <td>0.62559</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.94043</td>\n",
       "      <td>0.77201</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP LVQ_SMOTE</th>\n",
       "      <td>0.69575</td>\n",
       "      <td>0.62343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.80614</td>\n",
       "      <td>0.74026</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge ProWSyn</th>\n",
       "      <td>0.69336</td>\n",
       "      <td>0.62197</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.78159</td>\n",
       "      <td>0.70707</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC G_SMOTE</th>\n",
       "      <td>0.90731</td>\n",
       "      <td>0.62053</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.94188</td>\n",
       "      <td>0.77056</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP SMOTE_IPF</th>\n",
       "      <td>0.88106</td>\n",
       "      <td>0.61983</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.92202</td>\n",
       "      <td>0.73449</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge LVQ_SMOTE</th>\n",
       "      <td>0.64858</td>\n",
       "      <td>0.61915</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.78484</td>\n",
       "      <td>0.75325</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC SMOTE_IPF</th>\n",
       "      <td>0.91327</td>\n",
       "      <td>0.61611</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.94549</td>\n",
       "      <td>0.76623</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP G_SMOTE</th>\n",
       "      <td>0.92385</td>\n",
       "      <td>0.61339</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.95090</td>\n",
       "      <td>0.74170</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Deep Learning</th>\n",
       "      <th>Bert base (2 epochs)</th>\n",
       "      <td>0.67094</td>\n",
       "      <td>0.61283</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.81480</td>\n",
       "      <td>0.76479</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sbert Oversampling</th>\n",
       "      <th>SVC ProWSyn</th>\n",
       "      <td>0.90376</td>\n",
       "      <td>0.61205</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.94079</td>\n",
       "      <td>0.76768</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sbert</th>\n",
       "      <th>Multi-layer Perceptron classifier</th>\n",
       "      <td>0.65392</td>\n",
       "      <td>0.61072</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.79747</td>\n",
       "      <td>0.75902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Sbert Oversampling</th>\n",
       "      <th>SVC Assembled_SMOTE</th>\n",
       "      <td>0.91097</td>\n",
       "      <td>0.60766</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.94404</td>\n",
       "      <td>0.76335</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC SMOTE_TomekLinks</th>\n",
       "      <td>0.90940</td>\n",
       "      <td>0.60432</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.94296</td>\n",
       "      <td>0.76190</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP ProWSyn</th>\n",
       "      <td>0.92675</td>\n",
       "      <td>0.60041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.95235</td>\n",
       "      <td>0.72150</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP polynom_fit_SMOTE</th>\n",
       "      <td>0.91958</td>\n",
       "      <td>0.60000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.94765</td>\n",
       "      <td>0.72294</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sbert Best</th>\n",
       "      <th>Support Vector Classification (best)</th>\n",
       "      <td>0.99778</td>\n",
       "      <td>0.59722</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.99856</td>\n",
       "      <td>0.74892</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sbert</th>\n",
       "      <th>Ridge Classifier</th>\n",
       "      <td>0.62939</td>\n",
       "      <td>0.57985</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.79422</td>\n",
       "      <td>0.75325</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sbert Oversampling</th>\n",
       "      <th>SVC LVQ_SMOTE</th>\n",
       "      <td>0.84950</td>\n",
       "      <td>0.57963</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.91264</td>\n",
       "      <td>0.76768</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sbert Best</th>\n",
       "      <th>Ridge Classifier (best)</th>\n",
       "      <td>0.65409</td>\n",
       "      <td>0.57957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.80144</td>\n",
       "      <td>0.74459</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sbert Oversampling</th>\n",
       "      <th>SVC polynom_fit_SMOTE</th>\n",
       "      <td>0.86547</td>\n",
       "      <td>0.56383</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.92166</td>\n",
       "      <td>0.76335</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sbert</th>\n",
       "      <th>Support Vector Classification</th>\n",
       "      <td>0.82315</td>\n",
       "      <td>0.56000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.90072</td>\n",
       "      <td>0.76190</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Sbert Best</th>\n",
       "      <th>Multi-layer Perceptron classifier (best)</th>\n",
       "      <td>0.54848</td>\n",
       "      <td>0.55208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.76462</td>\n",
       "      <td>0.75180</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost classifier (best)</th>\n",
       "      <td>0.88953</td>\n",
       "      <td>0.54505</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.93141</td>\n",
       "      <td>0.70851</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Traditional Best</th>\n",
       "      <th>Dummy Classifier (best)</th>\n",
       "      <td>0.49087</td>\n",
       "      <td>0.52396</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.32527</td>\n",
       "      <td>0.35498</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost classifier (best)</th>\n",
       "      <td>0.49262</td>\n",
       "      <td>0.52081</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.32996</td>\n",
       "      <td>0.35209</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sbert</th>\n",
       "      <th>AdaBoost classifier</th>\n",
       "      <td>0.64030</td>\n",
       "      <td>0.50575</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.78989</td>\n",
       "      <td>0.68975</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sbert Oversampling</th>\n",
       "      <th>Ridge CCR</th>\n",
       "      <td>0.39089</td>\n",
       "      <td>0.38527</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.71986</td>\n",
       "      <td>0.68687</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Traditional Best</th>\n",
       "      <th>Random Forest classifier (best)</th>\n",
       "      <td>0.72641</td>\n",
       "      <td>0.37168</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.83357</td>\n",
       "      <td>0.59019</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sbert Best</th>\n",
       "      <th>Random Forest classifier (best)</th>\n",
       "      <td>0.86962</td>\n",
       "      <td>0.36788</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.92130</td>\n",
       "      <td>0.64791</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Traditional Best</th>\n",
       "      <th>Bernoulli Naive Bayes classifier (best)</th>\n",
       "      <td>0.76141</td>\n",
       "      <td>0.36145</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.81877</td>\n",
       "      <td>0.54113</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Classifier (best)</th>\n",
       "      <td>0.95722</td>\n",
       "      <td>0.35841</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.97292</td>\n",
       "      <td>0.58153</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Classification (best)</th>\n",
       "      <td>0.88662</td>\n",
       "      <td>0.35529</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.92780</td>\n",
       "      <td>0.53391</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sbert</th>\n",
       "      <th>Random Forest classifier</th>\n",
       "      <td>0.99944</td>\n",
       "      <td>0.29352</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.99964</td>\n",
       "      <td>0.70130</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Traditional</th>\n",
       "      <th>Ridge Classifier</th>\n",
       "      <td>0.82495</td>\n",
       "      <td>0.26039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.90072</td>\n",
       "      <td>0.61472</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bernoulli Naive Bayes classifier</th>\n",
       "      <td>0.66345</td>\n",
       "      <td>0.21605</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.82347</td>\n",
       "      <td>0.63348</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Traditional Best</th>\n",
       "      <th>Multinomial Naive Bayes classifier (best)</th>\n",
       "      <td>0.77249</td>\n",
       "      <td>0.19692</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.87581</td>\n",
       "      <td>0.62338</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Traditional</th>\n",
       "      <th>AdaBoost classifier</th>\n",
       "      <td>0.30435</td>\n",
       "      <td>0.16981</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.71119</td>\n",
       "      <td>0.61905</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest classifier</th>\n",
       "      <td>0.97798</td>\n",
       "      <td>0.15385</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.98592</td>\n",
       "      <td>0.61905</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sbert Oversampling</th>\n",
       "      <th>MLP CCR</th>\n",
       "      <td>0.11922</td>\n",
       "      <td>0.09125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.69061</td>\n",
       "      <td>0.65512</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Deep Learning</th>\n",
       "      <th>Atalaya</th>\n",
       "      <td>0.34249</td>\n",
       "      <td>0.06792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.74079</td>\n",
       "      <td>0.64358</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sbert Oversampling</th>\n",
       "      <th>SVC CCR</th>\n",
       "      <td>0.04126</td>\n",
       "      <td>0.03200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.68123</td>\n",
       "      <td>0.65079</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Traditional</th>\n",
       "      <th>Multinomial Naive Bayes classifier</th>\n",
       "      <td>0.27011</td>\n",
       "      <td>0.03162</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.72491</td>\n",
       "      <td>0.64646</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Classification</th>\n",
       "      <td>0.86612</td>\n",
       "      <td>0.02381</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.92310</td>\n",
       "      <td>0.64502</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dummy Classifier</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.67473</td>\n",
       "      <td>0.64502</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multi-layer Perceptron classifier</th>\n",
       "      <td>0.03704</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.68087</td>\n",
       "      <td>0.64214</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Traditional Best</th>\n",
       "      <th>Multi-layer Perceptron classifier (best)</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.67473</td>\n",
       "      <td>0.64502</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"40\" valign=\"top\">Hateval2019 Task1</th>\n",
       "      <th rowspan=\"22\" valign=\"top\">English</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Deep Learning</th>\n",
       "      <th>Bert base</th>\n",
       "      <td>0.92999</td>\n",
       "      <td>0.74690</td>\n",
       "      <td>0.59415</td>\n",
       "      <td>0.93156</td>\n",
       "      <td>0.74900</td>\n",
       "      <td>0.60533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bert Avarage</th>\n",
       "      <td>0.93938</td>\n",
       "      <td>0.75085</td>\n",
       "      <td>0.59399</td>\n",
       "      <td>0.94078</td>\n",
       "      <td>0.75300</td>\n",
       "      <td>0.60600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Bert Avarage</th>\n",
       "      <th>CLS layers</th>\n",
       "      <td>0.93160</td>\n",
       "      <td>0.75035</td>\n",
       "      <td>0.58977</td>\n",
       "      <td>0.93311</td>\n",
       "      <td>0.75300</td>\n",
       "      <td>0.60267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entire layer</th>\n",
       "      <td>0.94064</td>\n",
       "      <td>0.75725</td>\n",
       "      <td>0.58663</td>\n",
       "      <td>0.94200</td>\n",
       "      <td>0.75900</td>\n",
       "      <td>0.59933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>0.93611</td>\n",
       "      <td>0.74822</td>\n",
       "      <td>0.58653</td>\n",
       "      <td>0.93744</td>\n",
       "      <td>0.75000</td>\n",
       "      <td>0.59900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Traditional</th>\n",
       "      <th>Multi-layer Perceptron classifier</th>\n",
       "      <td>0.78679</td>\n",
       "      <td>0.71006</td>\n",
       "      <td>0.51049</td>\n",
       "      <td>0.79989</td>\n",
       "      <td>0.72500</td>\n",
       "      <td>0.52600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Traditional Best</th>\n",
       "      <th>Multi-layer Perceptron classifier (best)</th>\n",
       "      <td>0.81200</td>\n",
       "      <td>0.72553</td>\n",
       "      <td>0.50020</td>\n",
       "      <td>0.82011</td>\n",
       "      <td>0.73300</td>\n",
       "      <td>0.52267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Traditional</th>\n",
       "      <th>Ridge Classifier</th>\n",
       "      <td>0.87636</td>\n",
       "      <td>0.71097</td>\n",
       "      <td>0.48698</td>\n",
       "      <td>0.88067</td>\n",
       "      <td>0.71800</td>\n",
       "      <td>0.51333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Traditional Best</th>\n",
       "      <th>Multinomial Naive Bayes classifier (best)</th>\n",
       "      <td>0.81622</td>\n",
       "      <td>0.73487</td>\n",
       "      <td>0.47901</td>\n",
       "      <td>0.82344</td>\n",
       "      <td>0.74200</td>\n",
       "      <td>0.50633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Classifier (best)</th>\n",
       "      <td>0.83368</td>\n",
       "      <td>0.73129</td>\n",
       "      <td>0.47851</td>\n",
       "      <td>0.84156</td>\n",
       "      <td>0.74000</td>\n",
       "      <td>0.50633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Traditional</th>\n",
       "      <th>Multinomial Naive Bayes classifier</th>\n",
       "      <td>0.81284</td>\n",
       "      <td>0.73487</td>\n",
       "      <td>0.47697</td>\n",
       "      <td>0.82067</td>\n",
       "      <td>0.74200</td>\n",
       "      <td>0.50400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Deep Learning</th>\n",
       "      <th>Atalaya</th>\n",
       "      <td>0.90158</td>\n",
       "      <td>0.74002</td>\n",
       "      <td>0.47074</td>\n",
       "      <td>0.90389</td>\n",
       "      <td>0.74300</td>\n",
       "      <td>0.50800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Traditional Best</th>\n",
       "      <th>Support Vector Classification (best)</th>\n",
       "      <td>0.95407</td>\n",
       "      <td>0.73356</td>\n",
       "      <td>0.44851</td>\n",
       "      <td>0.95533</td>\n",
       "      <td>0.74200</td>\n",
       "      <td>0.48733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Traditional</th>\n",
       "      <th>Support Vector Classification</th>\n",
       "      <td>0.95552</td>\n",
       "      <td>0.73191</td>\n",
       "      <td>0.44543</td>\n",
       "      <td>0.95678</td>\n",
       "      <td>0.74200</td>\n",
       "      <td>0.48467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Deep Learning</th>\n",
       "      <th>GPT2 base</th>\n",
       "      <td>0.80546</td>\n",
       "      <td>0.73562</td>\n",
       "      <td>0.43600</td>\n",
       "      <td>0.80956</td>\n",
       "      <td>0.73900</td>\n",
       "      <td>0.49067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Traditional Best</th>\n",
       "      <th>Bernoulli Naive Bayes classifier (best)</th>\n",
       "      <td>0.81365</td>\n",
       "      <td>0.73823</td>\n",
       "      <td>0.43153</td>\n",
       "      <td>0.81978</td>\n",
       "      <td>0.74200</td>\n",
       "      <td>0.48100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Traditional</th>\n",
       "      <th>AdaBoost classifier</th>\n",
       "      <td>0.76402</td>\n",
       "      <td>0.72179</td>\n",
       "      <td>0.42943</td>\n",
       "      <td>0.77878</td>\n",
       "      <td>0.73600</td>\n",
       "      <td>0.46800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Traditional Best</th>\n",
       "      <th>AdaBoost classifier (best)</th>\n",
       "      <td>0.77103</td>\n",
       "      <td>0.72652</td>\n",
       "      <td>0.42540</td>\n",
       "      <td>0.78522</td>\n",
       "      <td>0.74000</td>\n",
       "      <td>0.46667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Traditional</th>\n",
       "      <th>Bernoulli Naive Bayes classifier</th>\n",
       "      <td>0.81929</td>\n",
       "      <td>0.73645</td>\n",
       "      <td>0.41992</td>\n",
       "      <td>0.82444</td>\n",
       "      <td>0.74000</td>\n",
       "      <td>0.47400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest classifier</th>\n",
       "      <td>0.99897</td>\n",
       "      <td>0.74720</td>\n",
       "      <td>0.39627</td>\n",
       "      <td>0.99900</td>\n",
       "      <td>0.75400</td>\n",
       "      <td>0.45567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Traditional Best</th>\n",
       "      <th>Random Forest classifier (best)</th>\n",
       "      <td>0.99772</td>\n",
       "      <td>0.74220</td>\n",
       "      <td>0.39346</td>\n",
       "      <td>0.99778</td>\n",
       "      <td>0.74800</td>\n",
       "      <td>0.45700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Traditional</th>\n",
       "      <th>Dummy Classifier</th>\n",
       "      <td>0.36696</td>\n",
       "      <td>0.36427</td>\n",
       "      <td>0.36709</td>\n",
       "      <td>0.57967</td>\n",
       "      <td>0.57300</td>\n",
       "      <td>0.58000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"18\" valign=\"top\">Spanish</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">Deep Learning</th>\n",
       "      <th>Bert Avarage</th>\n",
       "      <td>0.98353</td>\n",
       "      <td>0.83122</td>\n",
       "      <td>0.74574</td>\n",
       "      <td>0.98400</td>\n",
       "      <td>0.83200</td>\n",
       "      <td>0.74687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bert base</th>\n",
       "      <td>0.95920</td>\n",
       "      <td>0.83318</td>\n",
       "      <td>0.74132</td>\n",
       "      <td>0.96022</td>\n",
       "      <td>0.83400</td>\n",
       "      <td>0.74250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atalaya</th>\n",
       "      <td>0.94656</td>\n",
       "      <td>0.73970</td>\n",
       "      <td>0.70826</td>\n",
       "      <td>0.94800</td>\n",
       "      <td>0.74200</td>\n",
       "      <td>0.71125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Traditional Best</th>\n",
       "      <th>Multi-layer Perceptron classifier (best)</th>\n",
       "      <td>0.92631</td>\n",
       "      <td>0.73197</td>\n",
       "      <td>0.70015</td>\n",
       "      <td>0.92867</td>\n",
       "      <td>0.73800</td>\n",
       "      <td>0.70813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Traditional</th>\n",
       "      <th>Ridge Classifier</th>\n",
       "      <td>0.94179</td>\n",
       "      <td>0.74015</td>\n",
       "      <td>0.69866</td>\n",
       "      <td>0.94378</td>\n",
       "      <td>0.74600</td>\n",
       "      <td>0.70375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Traditional Best</th>\n",
       "      <th>Ridge Classifier (best)</th>\n",
       "      <td>0.90766</td>\n",
       "      <td>0.74703</td>\n",
       "      <td>0.69866</td>\n",
       "      <td>0.91156</td>\n",
       "      <td>0.75400</td>\n",
       "      <td>0.70625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Traditional</th>\n",
       "      <th>Support Vector Classification</th>\n",
       "      <td>0.97568</td>\n",
       "      <td>0.75159</td>\n",
       "      <td>0.69784</td>\n",
       "      <td>0.97644</td>\n",
       "      <td>0.76000</td>\n",
       "      <td>0.70875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multi-layer Perceptron classifier</th>\n",
       "      <td>0.90000</td>\n",
       "      <td>0.74864</td>\n",
       "      <td>0.69751</td>\n",
       "      <td>0.90400</td>\n",
       "      <td>0.75400</td>\n",
       "      <td>0.70625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Traditional Best</th>\n",
       "      <th>Support Vector Classification (best)</th>\n",
       "      <td>0.91948</td>\n",
       "      <td>0.74733</td>\n",
       "      <td>0.69406</td>\n",
       "      <td>0.92222</td>\n",
       "      <td>0.75200</td>\n",
       "      <td>0.69875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial Naive Bayes classifier (best)</th>\n",
       "      <td>0.88361</td>\n",
       "      <td>0.73847</td>\n",
       "      <td>0.69320</td>\n",
       "      <td>0.88933</td>\n",
       "      <td>0.75000</td>\n",
       "      <td>0.70625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bernoulli Naive Bayes classifier (best)</th>\n",
       "      <td>0.88969</td>\n",
       "      <td>0.76292</td>\n",
       "      <td>0.69093</td>\n",
       "      <td>0.89289</td>\n",
       "      <td>0.76600</td>\n",
       "      <td>0.69437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Traditional</th>\n",
       "      <th>Random Forest classifier</th>\n",
       "      <td>0.99771</td>\n",
       "      <td>0.77751</td>\n",
       "      <td>0.68993</td>\n",
       "      <td>0.99778</td>\n",
       "      <td>0.78200</td>\n",
       "      <td>0.69750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial Naive Bayes classifier</th>\n",
       "      <td>0.86123</td>\n",
       "      <td>0.73205</td>\n",
       "      <td>0.68504</td>\n",
       "      <td>0.87000</td>\n",
       "      <td>0.74800</td>\n",
       "      <td>0.70375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Traditional Best</th>\n",
       "      <th>Random Forest classifier (best)</th>\n",
       "      <td>0.99565</td>\n",
       "      <td>0.77679</td>\n",
       "      <td>0.68362</td>\n",
       "      <td>0.99578</td>\n",
       "      <td>0.78000</td>\n",
       "      <td>0.68812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost classifier (best)</th>\n",
       "      <td>0.85434</td>\n",
       "      <td>0.73692</td>\n",
       "      <td>0.67729</td>\n",
       "      <td>0.86133</td>\n",
       "      <td>0.74400</td>\n",
       "      <td>0.68437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Traditional</th>\n",
       "      <th>AdaBoost classifier</th>\n",
       "      <td>0.77327</td>\n",
       "      <td>0.75159</td>\n",
       "      <td>0.66419</td>\n",
       "      <td>0.78711</td>\n",
       "      <td>0.76000</td>\n",
       "      <td>0.67688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bernoulli Naive Bayes classifier</th>\n",
       "      <td>0.87582</td>\n",
       "      <td>0.76414</td>\n",
       "      <td>0.65404</td>\n",
       "      <td>0.88022</td>\n",
       "      <td>0.76800</td>\n",
       "      <td>0.66000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dummy Classifier</th>\n",
       "      <td>0.37001</td>\n",
       "      <td>0.35733</td>\n",
       "      <td>0.37008</td>\n",
       "      <td>0.58733</td>\n",
       "      <td>0.55600</td>\n",
       "      <td>0.58750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                              F1  \\\n",
       "                                                                                           Train   \n",
       "Task              Lenguage Group              Name                                                 \n",
       "Detoxis Task1     Spanish  Sbert Oversampling Ridge SMOBD                                0.69273   \n",
       "                                              MLP SMOTE_TomekLinks                       0.74348   \n",
       "                                              Ridge G_SMOTE                              0.69433   \n",
       "                           Deep Learning      Bert base (3 epochs)                       0.85899   \n",
       "                           Sbert Oversampling Ridge SMOTE_TomekLinks                     0.68725   \n",
       "                                              Ridge SMOTE_IPF                            0.68886   \n",
       "                           Deep Learning      Bert Avarage                               0.98041   \n",
       "                           Sbert Oversampling Ridge Assembled_SMOTE                      0.69830   \n",
       "                           Deep Learning      Bert base (4 epochs)                       0.95833   \n",
       "                           Sbert Oversampling Ridge polynom_fit_SMOTE                    0.69402   \n",
       "                                              MLP Assembled_SMOTE                        0.72934   \n",
       "                                              MLP SMOBD                                  0.95233   \n",
       "                                              SVC SMOBD                                  0.90523   \n",
       "                                              MLP LVQ_SMOTE                              0.69575   \n",
       "                                              Ridge ProWSyn                              0.69336   \n",
       "                                              SVC G_SMOTE                                0.90731   \n",
       "                                              MLP SMOTE_IPF                              0.88106   \n",
       "                                              Ridge LVQ_SMOTE                            0.64858   \n",
       "                                              SVC SMOTE_IPF                              0.91327   \n",
       "                                              MLP G_SMOTE                                0.92385   \n",
       "                           Deep Learning      Bert base (2 epochs)                       0.67094   \n",
       "                           Sbert Oversampling SVC ProWSyn                                0.90376   \n",
       "                           Sbert              Multi-layer Perceptron classifier          0.65392   \n",
       "                           Sbert Oversampling SVC Assembled_SMOTE                        0.91097   \n",
       "                                              SVC SMOTE_TomekLinks                       0.90940   \n",
       "                                              MLP ProWSyn                                0.92675   \n",
       "                                              MLP polynom_fit_SMOTE                      0.91958   \n",
       "                           Sbert Best         Support Vector Classification (best)       0.99778   \n",
       "                           Sbert              Ridge Classifier                           0.62939   \n",
       "                           Sbert Oversampling SVC LVQ_SMOTE                              0.84950   \n",
       "                           Sbert Best         Ridge Classifier (best)                    0.65409   \n",
       "                           Sbert Oversampling SVC polynom_fit_SMOTE                      0.86547   \n",
       "                           Sbert              Support Vector Classification              0.82315   \n",
       "                           Sbert Best         Multi-layer Perceptron classifier (best)   0.54848   \n",
       "                                              AdaBoost classifier (best)                 0.88953   \n",
       "                           Traditional Best   Dummy Classifier (best)                    0.49087   \n",
       "                                              AdaBoost classifier (best)                 0.49262   \n",
       "                           Sbert              AdaBoost classifier                        0.64030   \n",
       "                           Sbert Oversampling Ridge CCR                                  0.39089   \n",
       "                           Traditional Best   Random Forest classifier (best)            0.72641   \n",
       "                           Sbert Best         Random Forest classifier (best)            0.86962   \n",
       "                           Traditional Best   Bernoulli Naive Bayes classifier (best)    0.76141   \n",
       "                                              Ridge Classifier (best)                    0.95722   \n",
       "                                              Support Vector Classification (best)       0.88662   \n",
       "                           Sbert              Random Forest classifier                   0.99944   \n",
       "                           Traditional        Ridge Classifier                           0.82495   \n",
       "                                              Bernoulli Naive Bayes classifier           0.66345   \n",
       "                           Traditional Best   Multinomial Naive Bayes classifier (best)  0.77249   \n",
       "                           Traditional        AdaBoost classifier                        0.30435   \n",
       "                                              Random Forest classifier                   0.97798   \n",
       "                           Sbert Oversampling MLP CCR                                    0.11922   \n",
       "                           Deep Learning      Atalaya                                    0.34249   \n",
       "                           Sbert Oversampling SVC CCR                                    0.04126   \n",
       "                           Traditional        Multinomial Naive Bayes classifier         0.27011   \n",
       "                                              Support Vector Classification              0.86612   \n",
       "                                              Dummy Classifier                           0.00000   \n",
       "                                              Multi-layer Perceptron classifier          0.03704   \n",
       "                           Traditional Best   Multi-layer Perceptron classifier (best)   0.00000   \n",
       "Hateval2019 Task1 English  Deep Learning      Bert base                                  0.92999   \n",
       "                                              Bert Avarage                               0.93938   \n",
       "                           Bert Avarage       CLS layers                                 0.93160   \n",
       "                                              Entire layer                               0.94064   \n",
       "                                              Tokens                                     0.93611   \n",
       "                           Traditional        Multi-layer Perceptron classifier          0.78679   \n",
       "                           Traditional Best   Multi-layer Perceptron classifier (best)   0.81200   \n",
       "                           Traditional        Ridge Classifier                           0.87636   \n",
       "                           Traditional Best   Multinomial Naive Bayes classifier (best)  0.81622   \n",
       "                                              Ridge Classifier (best)                    0.83368   \n",
       "                           Traditional        Multinomial Naive Bayes classifier         0.81284   \n",
       "                           Deep Learning      Atalaya                                    0.90158   \n",
       "                           Traditional Best   Support Vector Classification (best)       0.95407   \n",
       "                           Traditional        Support Vector Classification              0.95552   \n",
       "                           Deep Learning      GPT2 base                                  0.80546   \n",
       "                           Traditional Best   Bernoulli Naive Bayes classifier (best)    0.81365   \n",
       "                           Traditional        AdaBoost classifier                        0.76402   \n",
       "                           Traditional Best   AdaBoost classifier (best)                 0.77103   \n",
       "                           Traditional        Bernoulli Naive Bayes classifier           0.81929   \n",
       "                                              Random Forest classifier                   0.99897   \n",
       "                           Traditional Best   Random Forest classifier (best)            0.99772   \n",
       "                           Traditional        Dummy Classifier                           0.36696   \n",
       "                  Spanish  Deep Learning      Bert Avarage                               0.98353   \n",
       "                                              Bert base                                  0.95920   \n",
       "                                              Atalaya                                    0.94656   \n",
       "                           Traditional Best   Multi-layer Perceptron classifier (best)   0.92631   \n",
       "                           Traditional        Ridge Classifier                           0.94179   \n",
       "                           Traditional Best   Ridge Classifier (best)                    0.90766   \n",
       "                           Traditional        Support Vector Classification              0.97568   \n",
       "                                              Multi-layer Perceptron classifier          0.90000   \n",
       "                           Traditional Best   Support Vector Classification (best)       0.91948   \n",
       "                                              Multinomial Naive Bayes classifier (best)  0.88361   \n",
       "                                              Bernoulli Naive Bayes classifier (best)    0.88969   \n",
       "                           Traditional        Random Forest classifier                   0.99771   \n",
       "                                              Multinomial Naive Bayes classifier         0.86123   \n",
       "                           Traditional Best   Random Forest classifier (best)            0.99565   \n",
       "                                              AdaBoost classifier (best)                 0.85434   \n",
       "                           Traditional        AdaBoost classifier                        0.77327   \n",
       "                                              Bernoulli Naive Bayes classifier           0.87582   \n",
       "                                              Dummy Classifier                           0.37001   \n",
       "\n",
       "                                                                                                  \\\n",
       "                                                                                             Dev   \n",
       "Task              Lenguage Group              Name                                                 \n",
       "Detoxis Task1     Spanish  Sbert Oversampling Ridge SMOBD                                0.66038   \n",
       "                                              MLP SMOTE_TomekLinks                       0.66019   \n",
       "                                              Ridge G_SMOTE                              0.65672   \n",
       "                           Deep Learning      Bert base (3 epochs)                       0.65471   \n",
       "                           Sbert Oversampling Ridge SMOTE_TomekLinks                     0.65291   \n",
       "                                              Ridge SMOTE_IPF                            0.65028   \n",
       "                           Deep Learning      Bert Avarage                               0.64819   \n",
       "                           Sbert Oversampling Ridge Assembled_SMOTE                      0.64540   \n",
       "                           Deep Learning      Bert base (4 epochs)                       0.64069   \n",
       "                           Sbert Oversampling Ridge polynom_fit_SMOTE                    0.64060   \n",
       "                                              MLP Assembled_SMOTE                        0.63315   \n",
       "                                              MLP SMOBD                                  0.62979   \n",
       "                                              SVC SMOBD                                  0.62559   \n",
       "                                              MLP LVQ_SMOTE                              0.62343   \n",
       "                                              Ridge ProWSyn                              0.62197   \n",
       "                                              SVC G_SMOTE                                0.62053   \n",
       "                                              MLP SMOTE_IPF                              0.61983   \n",
       "                                              Ridge LVQ_SMOTE                            0.61915   \n",
       "                                              SVC SMOTE_IPF                              0.61611   \n",
       "                                              MLP G_SMOTE                                0.61339   \n",
       "                           Deep Learning      Bert base (2 epochs)                       0.61283   \n",
       "                           Sbert Oversampling SVC ProWSyn                                0.61205   \n",
       "                           Sbert              Multi-layer Perceptron classifier          0.61072   \n",
       "                           Sbert Oversampling SVC Assembled_SMOTE                        0.60766   \n",
       "                                              SVC SMOTE_TomekLinks                       0.60432   \n",
       "                                              MLP ProWSyn                                0.60041   \n",
       "                                              MLP polynom_fit_SMOTE                      0.60000   \n",
       "                           Sbert Best         Support Vector Classification (best)       0.59722   \n",
       "                           Sbert              Ridge Classifier                           0.57985   \n",
       "                           Sbert Oversampling SVC LVQ_SMOTE                              0.57963   \n",
       "                           Sbert Best         Ridge Classifier (best)                    0.57957   \n",
       "                           Sbert Oversampling SVC polynom_fit_SMOTE                      0.56383   \n",
       "                           Sbert              Support Vector Classification              0.56000   \n",
       "                           Sbert Best         Multi-layer Perceptron classifier (best)   0.55208   \n",
       "                                              AdaBoost classifier (best)                 0.54505   \n",
       "                           Traditional Best   Dummy Classifier (best)                    0.52396   \n",
       "                                              AdaBoost classifier (best)                 0.52081   \n",
       "                           Sbert              AdaBoost classifier                        0.50575   \n",
       "                           Sbert Oversampling Ridge CCR                                  0.38527   \n",
       "                           Traditional Best   Random Forest classifier (best)            0.37168   \n",
       "                           Sbert Best         Random Forest classifier (best)            0.36788   \n",
       "                           Traditional Best   Bernoulli Naive Bayes classifier (best)    0.36145   \n",
       "                                              Ridge Classifier (best)                    0.35841   \n",
       "                                              Support Vector Classification (best)       0.35529   \n",
       "                           Sbert              Random Forest classifier                   0.29352   \n",
       "                           Traditional        Ridge Classifier                           0.26039   \n",
       "                                              Bernoulli Naive Bayes classifier           0.21605   \n",
       "                           Traditional Best   Multinomial Naive Bayes classifier (best)  0.19692   \n",
       "                           Traditional        AdaBoost classifier                        0.16981   \n",
       "                                              Random Forest classifier                   0.15385   \n",
       "                           Sbert Oversampling MLP CCR                                    0.09125   \n",
       "                           Deep Learning      Atalaya                                    0.06792   \n",
       "                           Sbert Oversampling SVC CCR                                    0.03200   \n",
       "                           Traditional        Multinomial Naive Bayes classifier         0.03162   \n",
       "                                              Support Vector Classification              0.02381   \n",
       "                                              Dummy Classifier                           0.00000   \n",
       "                                              Multi-layer Perceptron classifier          0.00000   \n",
       "                           Traditional Best   Multi-layer Perceptron classifier (best)   0.00000   \n",
       "Hateval2019 Task1 English  Deep Learning      Bert base                                  0.74690   \n",
       "                                              Bert Avarage                               0.75085   \n",
       "                           Bert Avarage       CLS layers                                 0.75035   \n",
       "                                              Entire layer                               0.75725   \n",
       "                                              Tokens                                     0.74822   \n",
       "                           Traditional        Multi-layer Perceptron classifier          0.71006   \n",
       "                           Traditional Best   Multi-layer Perceptron classifier (best)   0.72553   \n",
       "                           Traditional        Ridge Classifier                           0.71097   \n",
       "                           Traditional Best   Multinomial Naive Bayes classifier (best)  0.73487   \n",
       "                                              Ridge Classifier (best)                    0.73129   \n",
       "                           Traditional        Multinomial Naive Bayes classifier         0.73487   \n",
       "                           Deep Learning      Atalaya                                    0.74002   \n",
       "                           Traditional Best   Support Vector Classification (best)       0.73356   \n",
       "                           Traditional        Support Vector Classification              0.73191   \n",
       "                           Deep Learning      GPT2 base                                  0.73562   \n",
       "                           Traditional Best   Bernoulli Naive Bayes classifier (best)    0.73823   \n",
       "                           Traditional        AdaBoost classifier                        0.72179   \n",
       "                           Traditional Best   AdaBoost classifier (best)                 0.72652   \n",
       "                           Traditional        Bernoulli Naive Bayes classifier           0.73645   \n",
       "                                              Random Forest classifier                   0.74720   \n",
       "                           Traditional Best   Random Forest classifier (best)            0.74220   \n",
       "                           Traditional        Dummy Classifier                           0.36427   \n",
       "                  Spanish  Deep Learning      Bert Avarage                               0.83122   \n",
       "                                              Bert base                                  0.83318   \n",
       "                                              Atalaya                                    0.73970   \n",
       "                           Traditional Best   Multi-layer Perceptron classifier (best)   0.73197   \n",
       "                           Traditional        Ridge Classifier                           0.74015   \n",
       "                           Traditional Best   Ridge Classifier (best)                    0.74703   \n",
       "                           Traditional        Support Vector Classification              0.75159   \n",
       "                                              Multi-layer Perceptron classifier          0.74864   \n",
       "                           Traditional Best   Support Vector Classification (best)       0.74733   \n",
       "                                              Multinomial Naive Bayes classifier (best)  0.73847   \n",
       "                                              Bernoulli Naive Bayes classifier (best)    0.76292   \n",
       "                           Traditional        Random Forest classifier                   0.77751   \n",
       "                                              Multinomial Naive Bayes classifier         0.73205   \n",
       "                           Traditional Best   Random Forest classifier (best)            0.77679   \n",
       "                                              AdaBoost classifier (best)                 0.73692   \n",
       "                           Traditional        AdaBoost classifier                        0.75159   \n",
       "                                              Bernoulli Naive Bayes classifier           0.76414   \n",
       "                                              Dummy Classifier                           0.35733   \n",
       "\n",
       "                                                                                                  \\\n",
       "                                                                                            Test   \n",
       "Task              Lenguage Group              Name                                                 \n",
       "Detoxis Task1     Spanish  Sbert Oversampling Ridge SMOBD                                    NaN   \n",
       "                                              MLP SMOTE_TomekLinks                           NaN   \n",
       "                                              Ridge G_SMOTE                                  NaN   \n",
       "                           Deep Learning      Bert base (3 epochs)                           NaN   \n",
       "                           Sbert Oversampling Ridge SMOTE_TomekLinks                         NaN   \n",
       "                                              Ridge SMOTE_IPF                                NaN   \n",
       "                           Deep Learning      Bert Avarage                                   NaN   \n",
       "                           Sbert Oversampling Ridge Assembled_SMOTE                          NaN   \n",
       "                           Deep Learning      Bert base (4 epochs)                           NaN   \n",
       "                           Sbert Oversampling Ridge polynom_fit_SMOTE                        NaN   \n",
       "                                              MLP Assembled_SMOTE                            NaN   \n",
       "                                              MLP SMOBD                                      NaN   \n",
       "                                              SVC SMOBD                                      NaN   \n",
       "                                              MLP LVQ_SMOTE                                  NaN   \n",
       "                                              Ridge ProWSyn                                  NaN   \n",
       "                                              SVC G_SMOTE                                    NaN   \n",
       "                                              MLP SMOTE_IPF                                  NaN   \n",
       "                                              Ridge LVQ_SMOTE                                NaN   \n",
       "                                              SVC SMOTE_IPF                                  NaN   \n",
       "                                              MLP G_SMOTE                                    NaN   \n",
       "                           Deep Learning      Bert base (2 epochs)                           NaN   \n",
       "                           Sbert Oversampling SVC ProWSyn                                    NaN   \n",
       "                           Sbert              Multi-layer Perceptron classifier              NaN   \n",
       "                           Sbert Oversampling SVC Assembled_SMOTE                            NaN   \n",
       "                                              SVC SMOTE_TomekLinks                           NaN   \n",
       "                                              MLP ProWSyn                                    NaN   \n",
       "                                              MLP polynom_fit_SMOTE                          NaN   \n",
       "                           Sbert Best         Support Vector Classification (best)           NaN   \n",
       "                           Sbert              Ridge Classifier                               NaN   \n",
       "                           Sbert Oversampling SVC LVQ_SMOTE                                  NaN   \n",
       "                           Sbert Best         Ridge Classifier (best)                        NaN   \n",
       "                           Sbert Oversampling SVC polynom_fit_SMOTE                          NaN   \n",
       "                           Sbert              Support Vector Classification                  NaN   \n",
       "                           Sbert Best         Multi-layer Perceptron classifier (best)       NaN   \n",
       "                                              AdaBoost classifier (best)                     NaN   \n",
       "                           Traditional Best   Dummy Classifier (best)                        NaN   \n",
       "                                              AdaBoost classifier (best)                     NaN   \n",
       "                           Sbert              AdaBoost classifier                            NaN   \n",
       "                           Sbert Oversampling Ridge CCR                                      NaN   \n",
       "                           Traditional Best   Random Forest classifier (best)                NaN   \n",
       "                           Sbert Best         Random Forest classifier (best)                NaN   \n",
       "                           Traditional Best   Bernoulli Naive Bayes classifier (best)        NaN   \n",
       "                                              Ridge Classifier (best)                        NaN   \n",
       "                                              Support Vector Classification (best)           NaN   \n",
       "                           Sbert              Random Forest classifier                       NaN   \n",
       "                           Traditional        Ridge Classifier                               NaN   \n",
       "                                              Bernoulli Naive Bayes classifier               NaN   \n",
       "                           Traditional Best   Multinomial Naive Bayes classifier (best)      NaN   \n",
       "                           Traditional        AdaBoost classifier                            NaN   \n",
       "                                              Random Forest classifier                       NaN   \n",
       "                           Sbert Oversampling MLP CCR                                        NaN   \n",
       "                           Deep Learning      Atalaya                                        NaN   \n",
       "                           Sbert Oversampling SVC CCR                                        NaN   \n",
       "                           Traditional        Multinomial Naive Bayes classifier             NaN   \n",
       "                                              Support Vector Classification                  NaN   \n",
       "                                              Dummy Classifier                               NaN   \n",
       "                                              Multi-layer Perceptron classifier              NaN   \n",
       "                           Traditional Best   Multi-layer Perceptron classifier (best)       NaN   \n",
       "Hateval2019 Task1 English  Deep Learning      Bert base                                  0.59415   \n",
       "                                              Bert Avarage                               0.59399   \n",
       "                           Bert Avarage       CLS layers                                 0.58977   \n",
       "                                              Entire layer                               0.58663   \n",
       "                                              Tokens                                     0.58653   \n",
       "                           Traditional        Multi-layer Perceptron classifier          0.51049   \n",
       "                           Traditional Best   Multi-layer Perceptron classifier (best)   0.50020   \n",
       "                           Traditional        Ridge Classifier                           0.48698   \n",
       "                           Traditional Best   Multinomial Naive Bayes classifier (best)  0.47901   \n",
       "                                              Ridge Classifier (best)                    0.47851   \n",
       "                           Traditional        Multinomial Naive Bayes classifier         0.47697   \n",
       "                           Deep Learning      Atalaya                                    0.47074   \n",
       "                           Traditional Best   Support Vector Classification (best)       0.44851   \n",
       "                           Traditional        Support Vector Classification              0.44543   \n",
       "                           Deep Learning      GPT2 base                                  0.43600   \n",
       "                           Traditional Best   Bernoulli Naive Bayes classifier (best)    0.43153   \n",
       "                           Traditional        AdaBoost classifier                        0.42943   \n",
       "                           Traditional Best   AdaBoost classifier (best)                 0.42540   \n",
       "                           Traditional        Bernoulli Naive Bayes classifier           0.41992   \n",
       "                                              Random Forest classifier                   0.39627   \n",
       "                           Traditional Best   Random Forest classifier (best)            0.39346   \n",
       "                           Traditional        Dummy Classifier                           0.36709   \n",
       "                  Spanish  Deep Learning      Bert Avarage                               0.74574   \n",
       "                                              Bert base                                  0.74132   \n",
       "                                              Atalaya                                    0.70826   \n",
       "                           Traditional Best   Multi-layer Perceptron classifier (best)   0.70015   \n",
       "                           Traditional        Ridge Classifier                           0.69866   \n",
       "                           Traditional Best   Ridge Classifier (best)                    0.69866   \n",
       "                           Traditional        Support Vector Classification              0.69784   \n",
       "                                              Multi-layer Perceptron classifier          0.69751   \n",
       "                           Traditional Best   Support Vector Classification (best)       0.69406   \n",
       "                                              Multinomial Naive Bayes classifier (best)  0.69320   \n",
       "                                              Bernoulli Naive Bayes classifier (best)    0.69093   \n",
       "                           Traditional        Random Forest classifier                   0.68993   \n",
       "                                              Multinomial Naive Bayes classifier         0.68504   \n",
       "                           Traditional Best   Random Forest classifier (best)            0.68362   \n",
       "                                              AdaBoost classifier (best)                 0.67729   \n",
       "                           Traditional        AdaBoost classifier                        0.66419   \n",
       "                                              Bernoulli Naive Bayes classifier           0.65404   \n",
       "                                              Dummy Classifier                           0.37008   \n",
       "\n",
       "                                                                                        Accuracy  \\\n",
       "                                                                                           Train   \n",
       "Task              Lenguage Group              Name                                                 \n",
       "Detoxis Task1     Spanish  Sbert Oversampling Ridge SMOBD                                0.77870   \n",
       "                                              MLP SMOTE_TomekLinks                       0.82238   \n",
       "                                              Ridge G_SMOTE                              0.78195   \n",
       "                           Deep Learning      Bert base (3 epochs)                       0.91336   \n",
       "                           Sbert Oversampling Ridge SMOTE_TomekLinks                     0.77690   \n",
       "                                              Ridge SMOTE_IPF                            0.77726   \n",
       "                           Deep Learning      Bert Avarage                               0.98736   \n",
       "                           Sbert Oversampling Ridge Assembled_SMOTE                      0.78195   \n",
       "                           Deep Learning      Bert base (4 epochs)                       0.97329   \n",
       "                           Sbert Oversampling Ridge polynom_fit_SMOTE                    0.78195   \n",
       "                                              MLP Assembled_SMOTE                        0.80253   \n",
       "                                              MLP SMOBD                                  0.96859   \n",
       "                                              SVC SMOBD                                  0.94043   \n",
       "                                              MLP LVQ_SMOTE                              0.80614   \n",
       "                                              Ridge ProWSyn                              0.78159   \n",
       "                                              SVC G_SMOTE                                0.94188   \n",
       "                                              MLP SMOTE_IPF                              0.92202   \n",
       "                                              Ridge LVQ_SMOTE                            0.78484   \n",
       "                                              SVC SMOTE_IPF                              0.94549   \n",
       "                                              MLP G_SMOTE                                0.95090   \n",
       "                           Deep Learning      Bert base (2 epochs)                       0.81480   \n",
       "                           Sbert Oversampling SVC ProWSyn                                0.94079   \n",
       "                           Sbert              Multi-layer Perceptron classifier          0.79747   \n",
       "                           Sbert Oversampling SVC Assembled_SMOTE                        0.94404   \n",
       "                                              SVC SMOTE_TomekLinks                       0.94296   \n",
       "                                              MLP ProWSyn                                0.95235   \n",
       "                                              MLP polynom_fit_SMOTE                      0.94765   \n",
       "                           Sbert Best         Support Vector Classification (best)       0.99856   \n",
       "                           Sbert              Ridge Classifier                           0.79422   \n",
       "                           Sbert Oversampling SVC LVQ_SMOTE                              0.91264   \n",
       "                           Sbert Best         Ridge Classifier (best)                    0.80144   \n",
       "                           Sbert Oversampling SVC polynom_fit_SMOTE                      0.92166   \n",
       "                           Sbert              Support Vector Classification              0.90072   \n",
       "                           Sbert Best         Multi-layer Perceptron classifier (best)   0.76462   \n",
       "                                              AdaBoost classifier (best)                 0.93141   \n",
       "                           Traditional Best   Dummy Classifier (best)                    0.32527   \n",
       "                                              AdaBoost classifier (best)                 0.32996   \n",
       "                           Sbert              AdaBoost classifier                        0.78989   \n",
       "                           Sbert Oversampling Ridge CCR                                  0.71986   \n",
       "                           Traditional Best   Random Forest classifier (best)            0.83357   \n",
       "                           Sbert Best         Random Forest classifier (best)            0.92130   \n",
       "                           Traditional Best   Bernoulli Naive Bayes classifier (best)    0.81877   \n",
       "                                              Ridge Classifier (best)                    0.97292   \n",
       "                                              Support Vector Classification (best)       0.92780   \n",
       "                           Sbert              Random Forest classifier                   0.99964   \n",
       "                           Traditional        Ridge Classifier                           0.90072   \n",
       "                                              Bernoulli Naive Bayes classifier           0.82347   \n",
       "                           Traditional Best   Multinomial Naive Bayes classifier (best)  0.87581   \n",
       "                           Traditional        AdaBoost classifier                        0.71119   \n",
       "                                              Random Forest classifier                   0.98592   \n",
       "                           Sbert Oversampling MLP CCR                                    0.69061   \n",
       "                           Deep Learning      Atalaya                                    0.74079   \n",
       "                           Sbert Oversampling SVC CCR                                    0.68123   \n",
       "                           Traditional        Multinomial Naive Bayes classifier         0.72491   \n",
       "                                              Support Vector Classification              0.92310   \n",
       "                                              Dummy Classifier                           0.67473   \n",
       "                                              Multi-layer Perceptron classifier          0.68087   \n",
       "                           Traditional Best   Multi-layer Perceptron classifier (best)   0.67473   \n",
       "Hateval2019 Task1 English  Deep Learning      Bert base                                  0.93156   \n",
       "                                              Bert Avarage                               0.94078   \n",
       "                           Bert Avarage       CLS layers                                 0.93311   \n",
       "                                              Entire layer                               0.94200   \n",
       "                                              Tokens                                     0.93744   \n",
       "                           Traditional        Multi-layer Perceptron classifier          0.79989   \n",
       "                           Traditional Best   Multi-layer Perceptron classifier (best)   0.82011   \n",
       "                           Traditional        Ridge Classifier                           0.88067   \n",
       "                           Traditional Best   Multinomial Naive Bayes classifier (best)  0.82344   \n",
       "                                              Ridge Classifier (best)                    0.84156   \n",
       "                           Traditional        Multinomial Naive Bayes classifier         0.82067   \n",
       "                           Deep Learning      Atalaya                                    0.90389   \n",
       "                           Traditional Best   Support Vector Classification (best)       0.95533   \n",
       "                           Traditional        Support Vector Classification              0.95678   \n",
       "                           Deep Learning      GPT2 base                                  0.80956   \n",
       "                           Traditional Best   Bernoulli Naive Bayes classifier (best)    0.81978   \n",
       "                           Traditional        AdaBoost classifier                        0.77878   \n",
       "                           Traditional Best   AdaBoost classifier (best)                 0.78522   \n",
       "                           Traditional        Bernoulli Naive Bayes classifier           0.82444   \n",
       "                                              Random Forest classifier                   0.99900   \n",
       "                           Traditional Best   Random Forest classifier (best)            0.99778   \n",
       "                           Traditional        Dummy Classifier                           0.57967   \n",
       "                  Spanish  Deep Learning      Bert Avarage                               0.98400   \n",
       "                                              Bert base                                  0.96022   \n",
       "                                              Atalaya                                    0.94800   \n",
       "                           Traditional Best   Multi-layer Perceptron classifier (best)   0.92867   \n",
       "                           Traditional        Ridge Classifier                           0.94378   \n",
       "                           Traditional Best   Ridge Classifier (best)                    0.91156   \n",
       "                           Traditional        Support Vector Classification              0.97644   \n",
       "                                              Multi-layer Perceptron classifier          0.90400   \n",
       "                           Traditional Best   Support Vector Classification (best)       0.92222   \n",
       "                                              Multinomial Naive Bayes classifier (best)  0.88933   \n",
       "                                              Bernoulli Naive Bayes classifier (best)    0.89289   \n",
       "                           Traditional        Random Forest classifier                   0.99778   \n",
       "                                              Multinomial Naive Bayes classifier         0.87000   \n",
       "                           Traditional Best   Random Forest classifier (best)            0.99578   \n",
       "                                              AdaBoost classifier (best)                 0.86133   \n",
       "                           Traditional        AdaBoost classifier                        0.78711   \n",
       "                                              Bernoulli Naive Bayes classifier           0.88022   \n",
       "                                              Dummy Classifier                           0.58733   \n",
       "\n",
       "                                                                                                  \\\n",
       "                                                                                             Dev   \n",
       "Task              Lenguage Group              Name                                                 \n",
       "Detoxis Task1     Spanish  Sbert Oversampling Ridge SMOBD                                0.74026   \n",
       "                                              MLP SMOTE_TomekLinks                       0.74747   \n",
       "                                              Ridge G_SMOTE                              0.73449   \n",
       "                           Deep Learning      Bert base (3 epochs)                       0.77778   \n",
       "                           Sbert Oversampling Ridge SMOTE_TomekLinks                     0.73304   \n",
       "                                              Ridge SMOTE_IPF                            0.73304   \n",
       "                           Deep Learning      Bert Avarage                               0.76190   \n",
       "                           Sbert Oversampling Ridge Assembled_SMOTE                      0.72727   \n",
       "                           Deep Learning      Bert base (4 epochs)                       0.76046   \n",
       "                           Sbert Oversampling Ridge polynom_fit_SMOTE                    0.72150   \n",
       "                                              MLP Assembled_SMOTE                        0.71573   \n",
       "                                              MLP SMOBD                                  0.74892   \n",
       "                                              SVC SMOBD                                  0.77201   \n",
       "                                              MLP LVQ_SMOTE                              0.74026   \n",
       "                                              Ridge ProWSyn                              0.70707   \n",
       "                                              SVC G_SMOTE                                0.77056   \n",
       "                                              MLP SMOTE_IPF                              0.73449   \n",
       "                                              Ridge LVQ_SMOTE                            0.75325   \n",
       "                                              SVC SMOTE_IPF                              0.76623   \n",
       "                                              MLP G_SMOTE                                0.74170   \n",
       "                           Deep Learning      Bert base (2 epochs)                       0.76479   \n",
       "                           Sbert Oversampling SVC ProWSyn                                0.76768   \n",
       "                           Sbert              Multi-layer Perceptron classifier          0.75902   \n",
       "                           Sbert Oversampling SVC Assembled_SMOTE                        0.76335   \n",
       "                                              SVC SMOTE_TomekLinks                       0.76190   \n",
       "                                              MLP ProWSyn                                0.72150   \n",
       "                                              MLP polynom_fit_SMOTE                      0.72294   \n",
       "                           Sbert Best         Support Vector Classification (best)       0.74892   \n",
       "                           Sbert              Ridge Classifier                           0.75325   \n",
       "                           Sbert Oversampling SVC LVQ_SMOTE                              0.76768   \n",
       "                           Sbert Best         Ridge Classifier (best)                    0.74459   \n",
       "                           Sbert Oversampling SVC polynom_fit_SMOTE                      0.76335   \n",
       "                           Sbert              Support Vector Classification              0.76190   \n",
       "                           Sbert Best         Multi-layer Perceptron classifier (best)   0.75180   \n",
       "                                              AdaBoost classifier (best)                 0.70851   \n",
       "                           Traditional Best   Dummy Classifier (best)                    0.35498   \n",
       "                                              AdaBoost classifier (best)                 0.35209   \n",
       "                           Sbert              AdaBoost classifier                        0.68975   \n",
       "                           Sbert Oversampling Ridge CCR                                  0.68687   \n",
       "                           Traditional Best   Random Forest classifier (best)            0.59019   \n",
       "                           Sbert Best         Random Forest classifier (best)            0.64791   \n",
       "                           Traditional Best   Bernoulli Naive Bayes classifier (best)    0.54113   \n",
       "                                              Ridge Classifier (best)                    0.58153   \n",
       "                                              Support Vector Classification (best)       0.53391   \n",
       "                           Sbert              Random Forest classifier                   0.70130   \n",
       "                           Traditional        Ridge Classifier                           0.61472   \n",
       "                                              Bernoulli Naive Bayes classifier           0.63348   \n",
       "                           Traditional Best   Multinomial Naive Bayes classifier (best)  0.62338   \n",
       "                           Traditional        AdaBoost classifier                        0.61905   \n",
       "                                              Random Forest classifier                   0.61905   \n",
       "                           Sbert Oversampling MLP CCR                                    0.65512   \n",
       "                           Deep Learning      Atalaya                                    0.64358   \n",
       "                           Sbert Oversampling SVC CCR                                    0.65079   \n",
       "                           Traditional        Multinomial Naive Bayes classifier         0.64646   \n",
       "                                              Support Vector Classification              0.64502   \n",
       "                                              Dummy Classifier                           0.64502   \n",
       "                                              Multi-layer Perceptron classifier          0.64214   \n",
       "                           Traditional Best   Multi-layer Perceptron classifier (best)   0.64502   \n",
       "Hateval2019 Task1 English  Deep Learning      Bert base                                  0.74900   \n",
       "                                              Bert Avarage                               0.75300   \n",
       "                           Bert Avarage       CLS layers                                 0.75300   \n",
       "                                              Entire layer                               0.75900   \n",
       "                                              Tokens                                     0.75000   \n",
       "                           Traditional        Multi-layer Perceptron classifier          0.72500   \n",
       "                           Traditional Best   Multi-layer Perceptron classifier (best)   0.73300   \n",
       "                           Traditional        Ridge Classifier                           0.71800   \n",
       "                           Traditional Best   Multinomial Naive Bayes classifier (best)  0.74200   \n",
       "                                              Ridge Classifier (best)                    0.74000   \n",
       "                           Traditional        Multinomial Naive Bayes classifier         0.74200   \n",
       "                           Deep Learning      Atalaya                                    0.74300   \n",
       "                           Traditional Best   Support Vector Classification (best)       0.74200   \n",
       "                           Traditional        Support Vector Classification              0.74200   \n",
       "                           Deep Learning      GPT2 base                                  0.73900   \n",
       "                           Traditional Best   Bernoulli Naive Bayes classifier (best)    0.74200   \n",
       "                           Traditional        AdaBoost classifier                        0.73600   \n",
       "                           Traditional Best   AdaBoost classifier (best)                 0.74000   \n",
       "                           Traditional        Bernoulli Naive Bayes classifier           0.74000   \n",
       "                                              Random Forest classifier                   0.75400   \n",
       "                           Traditional Best   Random Forest classifier (best)            0.74800   \n",
       "                           Traditional        Dummy Classifier                           0.57300   \n",
       "                  Spanish  Deep Learning      Bert Avarage                               0.83200   \n",
       "                                              Bert base                                  0.83400   \n",
       "                                              Atalaya                                    0.74200   \n",
       "                           Traditional Best   Multi-layer Perceptron classifier (best)   0.73800   \n",
       "                           Traditional        Ridge Classifier                           0.74600   \n",
       "                           Traditional Best   Ridge Classifier (best)                    0.75400   \n",
       "                           Traditional        Support Vector Classification              0.76000   \n",
       "                                              Multi-layer Perceptron classifier          0.75400   \n",
       "                           Traditional Best   Support Vector Classification (best)       0.75200   \n",
       "                                              Multinomial Naive Bayes classifier (best)  0.75000   \n",
       "                                              Bernoulli Naive Bayes classifier (best)    0.76600   \n",
       "                           Traditional        Random Forest classifier                   0.78200   \n",
       "                                              Multinomial Naive Bayes classifier         0.74800   \n",
       "                           Traditional Best   Random Forest classifier (best)            0.78000   \n",
       "                                              AdaBoost classifier (best)                 0.74400   \n",
       "                           Traditional        AdaBoost classifier                        0.76000   \n",
       "                                              Bernoulli Naive Bayes classifier           0.76800   \n",
       "                                              Dummy Classifier                           0.55600   \n",
       "\n",
       "                                                                                                  \n",
       "                                                                                            Test  \n",
       "Task              Lenguage Group              Name                                                \n",
       "Detoxis Task1     Spanish  Sbert Oversampling Ridge SMOBD                                    NaN  \n",
       "                                              MLP SMOTE_TomekLinks                           NaN  \n",
       "                                              Ridge G_SMOTE                                  NaN  \n",
       "                           Deep Learning      Bert base (3 epochs)                           NaN  \n",
       "                           Sbert Oversampling Ridge SMOTE_TomekLinks                         NaN  \n",
       "                                              Ridge SMOTE_IPF                                NaN  \n",
       "                           Deep Learning      Bert Avarage                                   NaN  \n",
       "                           Sbert Oversampling Ridge Assembled_SMOTE                          NaN  \n",
       "                           Deep Learning      Bert base (4 epochs)                           NaN  \n",
       "                           Sbert Oversampling Ridge polynom_fit_SMOTE                        NaN  \n",
       "                                              MLP Assembled_SMOTE                            NaN  \n",
       "                                              MLP SMOBD                                      NaN  \n",
       "                                              SVC SMOBD                                      NaN  \n",
       "                                              MLP LVQ_SMOTE                                  NaN  \n",
       "                                              Ridge ProWSyn                                  NaN  \n",
       "                                              SVC G_SMOTE                                    NaN  \n",
       "                                              MLP SMOTE_IPF                                  NaN  \n",
       "                                              Ridge LVQ_SMOTE                                NaN  \n",
       "                                              SVC SMOTE_IPF                                  NaN  \n",
       "                                              MLP G_SMOTE                                    NaN  \n",
       "                           Deep Learning      Bert base (2 epochs)                           NaN  \n",
       "                           Sbert Oversampling SVC ProWSyn                                    NaN  \n",
       "                           Sbert              Multi-layer Perceptron classifier              NaN  \n",
       "                           Sbert Oversampling SVC Assembled_SMOTE                            NaN  \n",
       "                                              SVC SMOTE_TomekLinks                           NaN  \n",
       "                                              MLP ProWSyn                                    NaN  \n",
       "                                              MLP polynom_fit_SMOTE                          NaN  \n",
       "                           Sbert Best         Support Vector Classification (best)           NaN  \n",
       "                           Sbert              Ridge Classifier                               NaN  \n",
       "                           Sbert Oversampling SVC LVQ_SMOTE                                  NaN  \n",
       "                           Sbert Best         Ridge Classifier (best)                        NaN  \n",
       "                           Sbert Oversampling SVC polynom_fit_SMOTE                          NaN  \n",
       "                           Sbert              Support Vector Classification                  NaN  \n",
       "                           Sbert Best         Multi-layer Perceptron classifier (best)       NaN  \n",
       "                                              AdaBoost classifier (best)                     NaN  \n",
       "                           Traditional Best   Dummy Classifier (best)                        NaN  \n",
       "                                              AdaBoost classifier (best)                     NaN  \n",
       "                           Sbert              AdaBoost classifier                            NaN  \n",
       "                           Sbert Oversampling Ridge CCR                                      NaN  \n",
       "                           Traditional Best   Random Forest classifier (best)                NaN  \n",
       "                           Sbert Best         Random Forest classifier (best)                NaN  \n",
       "                           Traditional Best   Bernoulli Naive Bayes classifier (best)        NaN  \n",
       "                                              Ridge Classifier (best)                        NaN  \n",
       "                                              Support Vector Classification (best)           NaN  \n",
       "                           Sbert              Random Forest classifier                       NaN  \n",
       "                           Traditional        Ridge Classifier                               NaN  \n",
       "                                              Bernoulli Naive Bayes classifier               NaN  \n",
       "                           Traditional Best   Multinomial Naive Bayes classifier (best)      NaN  \n",
       "                           Traditional        AdaBoost classifier                            NaN  \n",
       "                                              Random Forest classifier                       NaN  \n",
       "                           Sbert Oversampling MLP CCR                                        NaN  \n",
       "                           Deep Learning      Atalaya                                        NaN  \n",
       "                           Sbert Oversampling SVC CCR                                        NaN  \n",
       "                           Traditional        Multinomial Naive Bayes classifier             NaN  \n",
       "                                              Support Vector Classification                  NaN  \n",
       "                                              Dummy Classifier                               NaN  \n",
       "                                              Multi-layer Perceptron classifier              NaN  \n",
       "                           Traditional Best   Multi-layer Perceptron classifier (best)       NaN  \n",
       "Hateval2019 Task1 English  Deep Learning      Bert base                                  0.60533  \n",
       "                                              Bert Avarage                               0.60600  \n",
       "                           Bert Avarage       CLS layers                                 0.60267  \n",
       "                                              Entire layer                               0.59933  \n",
       "                                              Tokens                                     0.59900  \n",
       "                           Traditional        Multi-layer Perceptron classifier          0.52600  \n",
       "                           Traditional Best   Multi-layer Perceptron classifier (best)   0.52267  \n",
       "                           Traditional        Ridge Classifier                           0.51333  \n",
       "                           Traditional Best   Multinomial Naive Bayes classifier (best)  0.50633  \n",
       "                                              Ridge Classifier (best)                    0.50633  \n",
       "                           Traditional        Multinomial Naive Bayes classifier         0.50400  \n",
       "                           Deep Learning      Atalaya                                    0.50800  \n",
       "                           Traditional Best   Support Vector Classification (best)       0.48733  \n",
       "                           Traditional        Support Vector Classification              0.48467  \n",
       "                           Deep Learning      GPT2 base                                  0.49067  \n",
       "                           Traditional Best   Bernoulli Naive Bayes classifier (best)    0.48100  \n",
       "                           Traditional        AdaBoost classifier                        0.46800  \n",
       "                           Traditional Best   AdaBoost classifier (best)                 0.46667  \n",
       "                           Traditional        Bernoulli Naive Bayes classifier           0.47400  \n",
       "                                              Random Forest classifier                   0.45567  \n",
       "                           Traditional Best   Random Forest classifier (best)            0.45700  \n",
       "                           Traditional        Dummy Classifier                           0.58000  \n",
       "                  Spanish  Deep Learning      Bert Avarage                               0.74687  \n",
       "                                              Bert base                                  0.74250  \n",
       "                                              Atalaya                                    0.71125  \n",
       "                           Traditional Best   Multi-layer Perceptron classifier (best)   0.70813  \n",
       "                           Traditional        Ridge Classifier                           0.70375  \n",
       "                           Traditional Best   Ridge Classifier (best)                    0.70625  \n",
       "                           Traditional        Support Vector Classification              0.70875  \n",
       "                                              Multi-layer Perceptron classifier          0.70625  \n",
       "                           Traditional Best   Support Vector Classification (best)       0.69875  \n",
       "                                              Multinomial Naive Bayes classifier (best)  0.70625  \n",
       "                                              Bernoulli Naive Bayes classifier (best)    0.69437  \n",
       "                           Traditional        Random Forest classifier                   0.69750  \n",
       "                                              Multinomial Naive Bayes classifier         0.70375  \n",
       "                           Traditional Best   Random Forest classifier (best)            0.68812  \n",
       "                                              AdaBoost classifier (best)                 0.68437  \n",
       "                           Traditional        AdaBoost classifier                        0.67688  \n",
       "                                              Bernoulli Naive Bayes classifier           0.66000  \n",
       "                                              Dummy Classifier                           0.58750  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_columns2 = df_results_columns#.droplevel('Group')\n",
    "df_results_columns2 = df_results_columns2.sort_values(by=[\"Task\", \"Lenguage\", (\"F1\", dataset_types.test.title()), (\"F1\", dataset_types.development.title())], ascending=[True, True, False, False])\n",
    "df_results_columns2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4683b958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">F1</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Dev</th>\n",
       "      <th>Test</th>\n",
       "      <th>Train</th>\n",
       "      <th>Dev</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lenguage</th>\n",
       "      <th>Group</th>\n",
       "      <th>Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"58\" valign=\"top\">Spanish</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">Sbert Oversampling</th>\n",
       "      <th>Ridge SMOBD</th>\n",
       "      <td>0.69273</td>\n",
       "      <td>0.66038</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.77870</td>\n",
       "      <td>0.74026</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP SMOTE_TomekLinks</th>\n",
       "      <td>0.74348</td>\n",
       "      <td>0.66019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.82238</td>\n",
       "      <td>0.74747</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge G_SMOTE</th>\n",
       "      <td>0.69433</td>\n",
       "      <td>0.65672</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.78195</td>\n",
       "      <td>0.73449</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Deep Learning</th>\n",
       "      <th>Bert base (3 epochs)</th>\n",
       "      <td>0.85899</td>\n",
       "      <td>0.65471</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.91336</td>\n",
       "      <td>0.77778</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Sbert Oversampling</th>\n",
       "      <th>Ridge SMOTE_TomekLinks</th>\n",
       "      <td>0.68725</td>\n",
       "      <td>0.65291</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.77690</td>\n",
       "      <td>0.73304</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge SMOTE_IPF</th>\n",
       "      <td>0.68886</td>\n",
       "      <td>0.65028</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.77726</td>\n",
       "      <td>0.73304</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Deep Learning</th>\n",
       "      <th>Bert Avarage</th>\n",
       "      <td>0.98041</td>\n",
       "      <td>0.64819</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.98736</td>\n",
       "      <td>0.76190</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sbert Oversampling</th>\n",
       "      <th>Ridge Assembled_SMOTE</th>\n",
       "      <td>0.69830</td>\n",
       "      <td>0.64540</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.78195</td>\n",
       "      <td>0.72727</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Deep Learning</th>\n",
       "      <th>Bert base (4 epochs)</th>\n",
       "      <td>0.95833</td>\n",
       "      <td>0.64069</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.97329</td>\n",
       "      <td>0.76046</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">Sbert Oversampling</th>\n",
       "      <th>Ridge polynom_fit_SMOTE</th>\n",
       "      <td>0.69402</td>\n",
       "      <td>0.64060</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.78195</td>\n",
       "      <td>0.72150</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP Assembled_SMOTE</th>\n",
       "      <td>0.72934</td>\n",
       "      <td>0.63315</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.80253</td>\n",
       "      <td>0.71573</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP SMOBD</th>\n",
       "      <td>0.95233</td>\n",
       "      <td>0.62979</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.96859</td>\n",
       "      <td>0.74892</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC SMOBD</th>\n",
       "      <td>0.90523</td>\n",
       "      <td>0.62559</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.94043</td>\n",
       "      <td>0.77201</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP LVQ_SMOTE</th>\n",
       "      <td>0.69575</td>\n",
       "      <td>0.62343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.80614</td>\n",
       "      <td>0.74026</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge ProWSyn</th>\n",
       "      <td>0.69336</td>\n",
       "      <td>0.62197</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.78159</td>\n",
       "      <td>0.70707</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC G_SMOTE</th>\n",
       "      <td>0.90731</td>\n",
       "      <td>0.62053</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.94188</td>\n",
       "      <td>0.77056</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP SMOTE_IPF</th>\n",
       "      <td>0.88106</td>\n",
       "      <td>0.61983</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.92202</td>\n",
       "      <td>0.73449</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge LVQ_SMOTE</th>\n",
       "      <td>0.64858</td>\n",
       "      <td>0.61915</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.78484</td>\n",
       "      <td>0.75325</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC SMOTE_IPF</th>\n",
       "      <td>0.91327</td>\n",
       "      <td>0.61611</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.94549</td>\n",
       "      <td>0.76623</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP G_SMOTE</th>\n",
       "      <td>0.92385</td>\n",
       "      <td>0.61339</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.95090</td>\n",
       "      <td>0.74170</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Deep Learning</th>\n",
       "      <th>Bert base (2 epochs)</th>\n",
       "      <td>0.67094</td>\n",
       "      <td>0.61283</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.81480</td>\n",
       "      <td>0.76479</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sbert Oversampling</th>\n",
       "      <th>SVC ProWSyn</th>\n",
       "      <td>0.90376</td>\n",
       "      <td>0.61205</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.94079</td>\n",
       "      <td>0.76768</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sbert</th>\n",
       "      <th>Multi-layer Perceptron classifier</th>\n",
       "      <td>0.65392</td>\n",
       "      <td>0.61072</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.79747</td>\n",
       "      <td>0.75902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Sbert Oversampling</th>\n",
       "      <th>SVC Assembled_SMOTE</th>\n",
       "      <td>0.91097</td>\n",
       "      <td>0.60766</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.94404</td>\n",
       "      <td>0.76335</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC SMOTE_TomekLinks</th>\n",
       "      <td>0.90940</td>\n",
       "      <td>0.60432</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.94296</td>\n",
       "      <td>0.76190</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP ProWSyn</th>\n",
       "      <td>0.92675</td>\n",
       "      <td>0.60041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.95235</td>\n",
       "      <td>0.72150</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP polynom_fit_SMOTE</th>\n",
       "      <td>0.91958</td>\n",
       "      <td>0.60000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.94765</td>\n",
       "      <td>0.72294</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sbert Best</th>\n",
       "      <th>Support Vector Classification (best)</th>\n",
       "      <td>0.99778</td>\n",
       "      <td>0.59722</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.99856</td>\n",
       "      <td>0.74892</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sbert</th>\n",
       "      <th>Ridge Classifier</th>\n",
       "      <td>0.62939</td>\n",
       "      <td>0.57985</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.79422</td>\n",
       "      <td>0.75325</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sbert Oversampling</th>\n",
       "      <th>SVC LVQ_SMOTE</th>\n",
       "      <td>0.84950</td>\n",
       "      <td>0.57963</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.91264</td>\n",
       "      <td>0.76768</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sbert Best</th>\n",
       "      <th>Ridge Classifier (best)</th>\n",
       "      <td>0.65409</td>\n",
       "      <td>0.57957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.80144</td>\n",
       "      <td>0.74459</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sbert Oversampling</th>\n",
       "      <th>SVC polynom_fit_SMOTE</th>\n",
       "      <td>0.86547</td>\n",
       "      <td>0.56383</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.92166</td>\n",
       "      <td>0.76335</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sbert</th>\n",
       "      <th>Support Vector Classification</th>\n",
       "      <td>0.82315</td>\n",
       "      <td>0.56000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.90072</td>\n",
       "      <td>0.76190</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Sbert Best</th>\n",
       "      <th>Multi-layer Perceptron classifier (best)</th>\n",
       "      <td>0.54848</td>\n",
       "      <td>0.55208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.76462</td>\n",
       "      <td>0.75180</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost classifier (best)</th>\n",
       "      <td>0.88953</td>\n",
       "      <td>0.54505</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.93141</td>\n",
       "      <td>0.70851</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Traditional Best</th>\n",
       "      <th>Dummy Classifier (best)</th>\n",
       "      <td>0.49087</td>\n",
       "      <td>0.52396</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.32527</td>\n",
       "      <td>0.35498</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost classifier (best)</th>\n",
       "      <td>0.49262</td>\n",
       "      <td>0.52081</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.32996</td>\n",
       "      <td>0.35209</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sbert</th>\n",
       "      <th>AdaBoost classifier</th>\n",
       "      <td>0.64030</td>\n",
       "      <td>0.50575</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.78989</td>\n",
       "      <td>0.68975</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sbert Oversampling</th>\n",
       "      <th>Ridge CCR</th>\n",
       "      <td>0.39089</td>\n",
       "      <td>0.38527</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.71986</td>\n",
       "      <td>0.68687</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Traditional Best</th>\n",
       "      <th>Random Forest classifier (best)</th>\n",
       "      <td>0.72641</td>\n",
       "      <td>0.37168</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.83357</td>\n",
       "      <td>0.59019</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sbert Best</th>\n",
       "      <th>Random Forest classifier (best)</th>\n",
       "      <td>0.86962</td>\n",
       "      <td>0.36788</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.92130</td>\n",
       "      <td>0.64791</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Traditional Best</th>\n",
       "      <th>Bernoulli Naive Bayes classifier (best)</th>\n",
       "      <td>0.76141</td>\n",
       "      <td>0.36145</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.81877</td>\n",
       "      <td>0.54113</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Classifier (best)</th>\n",
       "      <td>0.95722</td>\n",
       "      <td>0.35841</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.97292</td>\n",
       "      <td>0.58153</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Classification (best)</th>\n",
       "      <td>0.88662</td>\n",
       "      <td>0.35529</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.92780</td>\n",
       "      <td>0.53391</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sbert</th>\n",
       "      <th>Random Forest classifier</th>\n",
       "      <td>0.99944</td>\n",
       "      <td>0.29352</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.99964</td>\n",
       "      <td>0.70130</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Traditional</th>\n",
       "      <th>Ridge Classifier</th>\n",
       "      <td>0.82495</td>\n",
       "      <td>0.26039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.90072</td>\n",
       "      <td>0.61472</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bernoulli Naive Bayes classifier</th>\n",
       "      <td>0.66345</td>\n",
       "      <td>0.21605</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.82347</td>\n",
       "      <td>0.63348</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Traditional Best</th>\n",
       "      <th>Multinomial Naive Bayes classifier (best)</th>\n",
       "      <td>0.77249</td>\n",
       "      <td>0.19692</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.87581</td>\n",
       "      <td>0.62338</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Traditional</th>\n",
       "      <th>AdaBoost classifier</th>\n",
       "      <td>0.30435</td>\n",
       "      <td>0.16981</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.71119</td>\n",
       "      <td>0.61905</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest classifier</th>\n",
       "      <td>0.97798</td>\n",
       "      <td>0.15385</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.98592</td>\n",
       "      <td>0.61905</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sbert Oversampling</th>\n",
       "      <th>MLP CCR</th>\n",
       "      <td>0.11922</td>\n",
       "      <td>0.09125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.69061</td>\n",
       "      <td>0.65512</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Deep Learning</th>\n",
       "      <th>Atalaya</th>\n",
       "      <td>0.34249</td>\n",
       "      <td>0.06792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.74079</td>\n",
       "      <td>0.64358</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sbert Oversampling</th>\n",
       "      <th>SVC CCR</th>\n",
       "      <td>0.04126</td>\n",
       "      <td>0.03200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.68123</td>\n",
       "      <td>0.65079</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Traditional</th>\n",
       "      <th>Multinomial Naive Bayes classifier</th>\n",
       "      <td>0.27011</td>\n",
       "      <td>0.03162</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.72491</td>\n",
       "      <td>0.64646</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Classification</th>\n",
       "      <td>0.86612</td>\n",
       "      <td>0.02381</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.92310</td>\n",
       "      <td>0.64502</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dummy Classifier</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.67473</td>\n",
       "      <td>0.64502</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multi-layer Perceptron classifier</th>\n",
       "      <td>0.03704</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.68087</td>\n",
       "      <td>0.64214</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Traditional Best</th>\n",
       "      <th>Multi-layer Perceptron classifier (best)</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.67473</td>\n",
       "      <td>0.64502</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            F1  \\\n",
       "                                                                         Train   \n",
       "Lenguage Group              Name                                                 \n",
       "Spanish  Sbert Oversampling Ridge SMOBD                                0.69273   \n",
       "                            MLP SMOTE_TomekLinks                       0.74348   \n",
       "                            Ridge G_SMOTE                              0.69433   \n",
       "         Deep Learning      Bert base (3 epochs)                       0.85899   \n",
       "         Sbert Oversampling Ridge SMOTE_TomekLinks                     0.68725   \n",
       "                            Ridge SMOTE_IPF                            0.68886   \n",
       "         Deep Learning      Bert Avarage                               0.98041   \n",
       "         Sbert Oversampling Ridge Assembled_SMOTE                      0.69830   \n",
       "         Deep Learning      Bert base (4 epochs)                       0.95833   \n",
       "         Sbert Oversampling Ridge polynom_fit_SMOTE                    0.69402   \n",
       "                            MLP Assembled_SMOTE                        0.72934   \n",
       "                            MLP SMOBD                                  0.95233   \n",
       "                            SVC SMOBD                                  0.90523   \n",
       "                            MLP LVQ_SMOTE                              0.69575   \n",
       "                            Ridge ProWSyn                              0.69336   \n",
       "                            SVC G_SMOTE                                0.90731   \n",
       "                            MLP SMOTE_IPF                              0.88106   \n",
       "                            Ridge LVQ_SMOTE                            0.64858   \n",
       "                            SVC SMOTE_IPF                              0.91327   \n",
       "                            MLP G_SMOTE                                0.92385   \n",
       "         Deep Learning      Bert base (2 epochs)                       0.67094   \n",
       "         Sbert Oversampling SVC ProWSyn                                0.90376   \n",
       "         Sbert              Multi-layer Perceptron classifier          0.65392   \n",
       "         Sbert Oversampling SVC Assembled_SMOTE                        0.91097   \n",
       "                            SVC SMOTE_TomekLinks                       0.90940   \n",
       "                            MLP ProWSyn                                0.92675   \n",
       "                            MLP polynom_fit_SMOTE                      0.91958   \n",
       "         Sbert Best         Support Vector Classification (best)       0.99778   \n",
       "         Sbert              Ridge Classifier                           0.62939   \n",
       "         Sbert Oversampling SVC LVQ_SMOTE                              0.84950   \n",
       "         Sbert Best         Ridge Classifier (best)                    0.65409   \n",
       "         Sbert Oversampling SVC polynom_fit_SMOTE                      0.86547   \n",
       "         Sbert              Support Vector Classification              0.82315   \n",
       "         Sbert Best         Multi-layer Perceptron classifier (best)   0.54848   \n",
       "                            AdaBoost classifier (best)                 0.88953   \n",
       "         Traditional Best   Dummy Classifier (best)                    0.49087   \n",
       "                            AdaBoost classifier (best)                 0.49262   \n",
       "         Sbert              AdaBoost classifier                        0.64030   \n",
       "         Sbert Oversampling Ridge CCR                                  0.39089   \n",
       "         Traditional Best   Random Forest classifier (best)            0.72641   \n",
       "         Sbert Best         Random Forest classifier (best)            0.86962   \n",
       "         Traditional Best   Bernoulli Naive Bayes classifier (best)    0.76141   \n",
       "                            Ridge Classifier (best)                    0.95722   \n",
       "                            Support Vector Classification (best)       0.88662   \n",
       "         Sbert              Random Forest classifier                   0.99944   \n",
       "         Traditional        Ridge Classifier                           0.82495   \n",
       "                            Bernoulli Naive Bayes classifier           0.66345   \n",
       "         Traditional Best   Multinomial Naive Bayes classifier (best)  0.77249   \n",
       "         Traditional        AdaBoost classifier                        0.30435   \n",
       "                            Random Forest classifier                   0.97798   \n",
       "         Sbert Oversampling MLP CCR                                    0.11922   \n",
       "         Deep Learning      Atalaya                                    0.34249   \n",
       "         Sbert Oversampling SVC CCR                                    0.04126   \n",
       "         Traditional        Multinomial Naive Bayes classifier         0.27011   \n",
       "                            Support Vector Classification              0.86612   \n",
       "                            Dummy Classifier                           0.00000   \n",
       "                            Multi-layer Perceptron classifier          0.03704   \n",
       "         Traditional Best   Multi-layer Perceptron classifier (best)   0.00000   \n",
       "\n",
       "                                                                                \\\n",
       "                                                                           Dev   \n",
       "Lenguage Group              Name                                                 \n",
       "Spanish  Sbert Oversampling Ridge SMOBD                                0.66038   \n",
       "                            MLP SMOTE_TomekLinks                       0.66019   \n",
       "                            Ridge G_SMOTE                              0.65672   \n",
       "         Deep Learning      Bert base (3 epochs)                       0.65471   \n",
       "         Sbert Oversampling Ridge SMOTE_TomekLinks                     0.65291   \n",
       "                            Ridge SMOTE_IPF                            0.65028   \n",
       "         Deep Learning      Bert Avarage                               0.64819   \n",
       "         Sbert Oversampling Ridge Assembled_SMOTE                      0.64540   \n",
       "         Deep Learning      Bert base (4 epochs)                       0.64069   \n",
       "         Sbert Oversampling Ridge polynom_fit_SMOTE                    0.64060   \n",
       "                            MLP Assembled_SMOTE                        0.63315   \n",
       "                            MLP SMOBD                                  0.62979   \n",
       "                            SVC SMOBD                                  0.62559   \n",
       "                            MLP LVQ_SMOTE                              0.62343   \n",
       "                            Ridge ProWSyn                              0.62197   \n",
       "                            SVC G_SMOTE                                0.62053   \n",
       "                            MLP SMOTE_IPF                              0.61983   \n",
       "                            Ridge LVQ_SMOTE                            0.61915   \n",
       "                            SVC SMOTE_IPF                              0.61611   \n",
       "                            MLP G_SMOTE                                0.61339   \n",
       "         Deep Learning      Bert base (2 epochs)                       0.61283   \n",
       "         Sbert Oversampling SVC ProWSyn                                0.61205   \n",
       "         Sbert              Multi-layer Perceptron classifier          0.61072   \n",
       "         Sbert Oversampling SVC Assembled_SMOTE                        0.60766   \n",
       "                            SVC SMOTE_TomekLinks                       0.60432   \n",
       "                            MLP ProWSyn                                0.60041   \n",
       "                            MLP polynom_fit_SMOTE                      0.60000   \n",
       "         Sbert Best         Support Vector Classification (best)       0.59722   \n",
       "         Sbert              Ridge Classifier                           0.57985   \n",
       "         Sbert Oversampling SVC LVQ_SMOTE                              0.57963   \n",
       "         Sbert Best         Ridge Classifier (best)                    0.57957   \n",
       "         Sbert Oversampling SVC polynom_fit_SMOTE                      0.56383   \n",
       "         Sbert              Support Vector Classification              0.56000   \n",
       "         Sbert Best         Multi-layer Perceptron classifier (best)   0.55208   \n",
       "                            AdaBoost classifier (best)                 0.54505   \n",
       "         Traditional Best   Dummy Classifier (best)                    0.52396   \n",
       "                            AdaBoost classifier (best)                 0.52081   \n",
       "         Sbert              AdaBoost classifier                        0.50575   \n",
       "         Sbert Oversampling Ridge CCR                                  0.38527   \n",
       "         Traditional Best   Random Forest classifier (best)            0.37168   \n",
       "         Sbert Best         Random Forest classifier (best)            0.36788   \n",
       "         Traditional Best   Bernoulli Naive Bayes classifier (best)    0.36145   \n",
       "                            Ridge Classifier (best)                    0.35841   \n",
       "                            Support Vector Classification (best)       0.35529   \n",
       "         Sbert              Random Forest classifier                   0.29352   \n",
       "         Traditional        Ridge Classifier                           0.26039   \n",
       "                            Bernoulli Naive Bayes classifier           0.21605   \n",
       "         Traditional Best   Multinomial Naive Bayes classifier (best)  0.19692   \n",
       "         Traditional        AdaBoost classifier                        0.16981   \n",
       "                            Random Forest classifier                   0.15385   \n",
       "         Sbert Oversampling MLP CCR                                    0.09125   \n",
       "         Deep Learning      Atalaya                                    0.06792   \n",
       "         Sbert Oversampling SVC CCR                                    0.03200   \n",
       "         Traditional        Multinomial Naive Bayes classifier         0.03162   \n",
       "                            Support Vector Classification              0.02381   \n",
       "                            Dummy Classifier                           0.00000   \n",
       "                            Multi-layer Perceptron classifier          0.00000   \n",
       "         Traditional Best   Multi-layer Perceptron classifier (best)   0.00000   \n",
       "\n",
       "                                                                            \\\n",
       "                                                                      Test   \n",
       "Lenguage Group              Name                                             \n",
       "Spanish  Sbert Oversampling Ridge SMOBD                                NaN   \n",
       "                            MLP SMOTE_TomekLinks                       NaN   \n",
       "                            Ridge G_SMOTE                              NaN   \n",
       "         Deep Learning      Bert base (3 epochs)                       NaN   \n",
       "         Sbert Oversampling Ridge SMOTE_TomekLinks                     NaN   \n",
       "                            Ridge SMOTE_IPF                            NaN   \n",
       "         Deep Learning      Bert Avarage                               NaN   \n",
       "         Sbert Oversampling Ridge Assembled_SMOTE                      NaN   \n",
       "         Deep Learning      Bert base (4 epochs)                       NaN   \n",
       "         Sbert Oversampling Ridge polynom_fit_SMOTE                    NaN   \n",
       "                            MLP Assembled_SMOTE                        NaN   \n",
       "                            MLP SMOBD                                  NaN   \n",
       "                            SVC SMOBD                                  NaN   \n",
       "                            MLP LVQ_SMOTE                              NaN   \n",
       "                            Ridge ProWSyn                              NaN   \n",
       "                            SVC G_SMOTE                                NaN   \n",
       "                            MLP SMOTE_IPF                              NaN   \n",
       "                            Ridge LVQ_SMOTE                            NaN   \n",
       "                            SVC SMOTE_IPF                              NaN   \n",
       "                            MLP G_SMOTE                                NaN   \n",
       "         Deep Learning      Bert base (2 epochs)                       NaN   \n",
       "         Sbert Oversampling SVC ProWSyn                                NaN   \n",
       "         Sbert              Multi-layer Perceptron classifier          NaN   \n",
       "         Sbert Oversampling SVC Assembled_SMOTE                        NaN   \n",
       "                            SVC SMOTE_TomekLinks                       NaN   \n",
       "                            MLP ProWSyn                                NaN   \n",
       "                            MLP polynom_fit_SMOTE                      NaN   \n",
       "         Sbert Best         Support Vector Classification (best)       NaN   \n",
       "         Sbert              Ridge Classifier                           NaN   \n",
       "         Sbert Oversampling SVC LVQ_SMOTE                              NaN   \n",
       "         Sbert Best         Ridge Classifier (best)                    NaN   \n",
       "         Sbert Oversampling SVC polynom_fit_SMOTE                      NaN   \n",
       "         Sbert              Support Vector Classification              NaN   \n",
       "         Sbert Best         Multi-layer Perceptron classifier (best)   NaN   \n",
       "                            AdaBoost classifier (best)                 NaN   \n",
       "         Traditional Best   Dummy Classifier (best)                    NaN   \n",
       "                            AdaBoost classifier (best)                 NaN   \n",
       "         Sbert              AdaBoost classifier                        NaN   \n",
       "         Sbert Oversampling Ridge CCR                                  NaN   \n",
       "         Traditional Best   Random Forest classifier (best)            NaN   \n",
       "         Sbert Best         Random Forest classifier (best)            NaN   \n",
       "         Traditional Best   Bernoulli Naive Bayes classifier (best)    NaN   \n",
       "                            Ridge Classifier (best)                    NaN   \n",
       "                            Support Vector Classification (best)       NaN   \n",
       "         Sbert              Random Forest classifier                   NaN   \n",
       "         Traditional        Ridge Classifier                           NaN   \n",
       "                            Bernoulli Naive Bayes classifier           NaN   \n",
       "         Traditional Best   Multinomial Naive Bayes classifier (best)  NaN   \n",
       "         Traditional        AdaBoost classifier                        NaN   \n",
       "                            Random Forest classifier                   NaN   \n",
       "         Sbert Oversampling MLP CCR                                    NaN   \n",
       "         Deep Learning      Atalaya                                    NaN   \n",
       "         Sbert Oversampling SVC CCR                                    NaN   \n",
       "         Traditional        Multinomial Naive Bayes classifier         NaN   \n",
       "                            Support Vector Classification              NaN   \n",
       "                            Dummy Classifier                           NaN   \n",
       "                            Multi-layer Perceptron classifier          NaN   \n",
       "         Traditional Best   Multi-layer Perceptron classifier (best)   NaN   \n",
       "\n",
       "                                                                      Accuracy  \\\n",
       "                                                                         Train   \n",
       "Lenguage Group              Name                                                 \n",
       "Spanish  Sbert Oversampling Ridge SMOBD                                0.77870   \n",
       "                            MLP SMOTE_TomekLinks                       0.82238   \n",
       "                            Ridge G_SMOTE                              0.78195   \n",
       "         Deep Learning      Bert base (3 epochs)                       0.91336   \n",
       "         Sbert Oversampling Ridge SMOTE_TomekLinks                     0.77690   \n",
       "                            Ridge SMOTE_IPF                            0.77726   \n",
       "         Deep Learning      Bert Avarage                               0.98736   \n",
       "         Sbert Oversampling Ridge Assembled_SMOTE                      0.78195   \n",
       "         Deep Learning      Bert base (4 epochs)                       0.97329   \n",
       "         Sbert Oversampling Ridge polynom_fit_SMOTE                    0.78195   \n",
       "                            MLP Assembled_SMOTE                        0.80253   \n",
       "                            MLP SMOBD                                  0.96859   \n",
       "                            SVC SMOBD                                  0.94043   \n",
       "                            MLP LVQ_SMOTE                              0.80614   \n",
       "                            Ridge ProWSyn                              0.78159   \n",
       "                            SVC G_SMOTE                                0.94188   \n",
       "                            MLP SMOTE_IPF                              0.92202   \n",
       "                            Ridge LVQ_SMOTE                            0.78484   \n",
       "                            SVC SMOTE_IPF                              0.94549   \n",
       "                            MLP G_SMOTE                                0.95090   \n",
       "         Deep Learning      Bert base (2 epochs)                       0.81480   \n",
       "         Sbert Oversampling SVC ProWSyn                                0.94079   \n",
       "         Sbert              Multi-layer Perceptron classifier          0.79747   \n",
       "         Sbert Oversampling SVC Assembled_SMOTE                        0.94404   \n",
       "                            SVC SMOTE_TomekLinks                       0.94296   \n",
       "                            MLP ProWSyn                                0.95235   \n",
       "                            MLP polynom_fit_SMOTE                      0.94765   \n",
       "         Sbert Best         Support Vector Classification (best)       0.99856   \n",
       "         Sbert              Ridge Classifier                           0.79422   \n",
       "         Sbert Oversampling SVC LVQ_SMOTE                              0.91264   \n",
       "         Sbert Best         Ridge Classifier (best)                    0.80144   \n",
       "         Sbert Oversampling SVC polynom_fit_SMOTE                      0.92166   \n",
       "         Sbert              Support Vector Classification              0.90072   \n",
       "         Sbert Best         Multi-layer Perceptron classifier (best)   0.76462   \n",
       "                            AdaBoost classifier (best)                 0.93141   \n",
       "         Traditional Best   Dummy Classifier (best)                    0.32527   \n",
       "                            AdaBoost classifier (best)                 0.32996   \n",
       "         Sbert              AdaBoost classifier                        0.78989   \n",
       "         Sbert Oversampling Ridge CCR                                  0.71986   \n",
       "         Traditional Best   Random Forest classifier (best)            0.83357   \n",
       "         Sbert Best         Random Forest classifier (best)            0.92130   \n",
       "         Traditional Best   Bernoulli Naive Bayes classifier (best)    0.81877   \n",
       "                            Ridge Classifier (best)                    0.97292   \n",
       "                            Support Vector Classification (best)       0.92780   \n",
       "         Sbert              Random Forest classifier                   0.99964   \n",
       "         Traditional        Ridge Classifier                           0.90072   \n",
       "                            Bernoulli Naive Bayes classifier           0.82347   \n",
       "         Traditional Best   Multinomial Naive Bayes classifier (best)  0.87581   \n",
       "         Traditional        AdaBoost classifier                        0.71119   \n",
       "                            Random Forest classifier                   0.98592   \n",
       "         Sbert Oversampling MLP CCR                                    0.69061   \n",
       "         Deep Learning      Atalaya                                    0.74079   \n",
       "         Sbert Oversampling SVC CCR                                    0.68123   \n",
       "         Traditional        Multinomial Naive Bayes classifier         0.72491   \n",
       "                            Support Vector Classification              0.92310   \n",
       "                            Dummy Classifier                           0.67473   \n",
       "                            Multi-layer Perceptron classifier          0.68087   \n",
       "         Traditional Best   Multi-layer Perceptron classifier (best)   0.67473   \n",
       "\n",
       "                                                                                \\\n",
       "                                                                           Dev   \n",
       "Lenguage Group              Name                                                 \n",
       "Spanish  Sbert Oversampling Ridge SMOBD                                0.74026   \n",
       "                            MLP SMOTE_TomekLinks                       0.74747   \n",
       "                            Ridge G_SMOTE                              0.73449   \n",
       "         Deep Learning      Bert base (3 epochs)                       0.77778   \n",
       "         Sbert Oversampling Ridge SMOTE_TomekLinks                     0.73304   \n",
       "                            Ridge SMOTE_IPF                            0.73304   \n",
       "         Deep Learning      Bert Avarage                               0.76190   \n",
       "         Sbert Oversampling Ridge Assembled_SMOTE                      0.72727   \n",
       "         Deep Learning      Bert base (4 epochs)                       0.76046   \n",
       "         Sbert Oversampling Ridge polynom_fit_SMOTE                    0.72150   \n",
       "                            MLP Assembled_SMOTE                        0.71573   \n",
       "                            MLP SMOBD                                  0.74892   \n",
       "                            SVC SMOBD                                  0.77201   \n",
       "                            MLP LVQ_SMOTE                              0.74026   \n",
       "                            Ridge ProWSyn                              0.70707   \n",
       "                            SVC G_SMOTE                                0.77056   \n",
       "                            MLP SMOTE_IPF                              0.73449   \n",
       "                            Ridge LVQ_SMOTE                            0.75325   \n",
       "                            SVC SMOTE_IPF                              0.76623   \n",
       "                            MLP G_SMOTE                                0.74170   \n",
       "         Deep Learning      Bert base (2 epochs)                       0.76479   \n",
       "         Sbert Oversampling SVC ProWSyn                                0.76768   \n",
       "         Sbert              Multi-layer Perceptron classifier          0.75902   \n",
       "         Sbert Oversampling SVC Assembled_SMOTE                        0.76335   \n",
       "                            SVC SMOTE_TomekLinks                       0.76190   \n",
       "                            MLP ProWSyn                                0.72150   \n",
       "                            MLP polynom_fit_SMOTE                      0.72294   \n",
       "         Sbert Best         Support Vector Classification (best)       0.74892   \n",
       "         Sbert              Ridge Classifier                           0.75325   \n",
       "         Sbert Oversampling SVC LVQ_SMOTE                              0.76768   \n",
       "         Sbert Best         Ridge Classifier (best)                    0.74459   \n",
       "         Sbert Oversampling SVC polynom_fit_SMOTE                      0.76335   \n",
       "         Sbert              Support Vector Classification              0.76190   \n",
       "         Sbert Best         Multi-layer Perceptron classifier (best)   0.75180   \n",
       "                            AdaBoost classifier (best)                 0.70851   \n",
       "         Traditional Best   Dummy Classifier (best)                    0.35498   \n",
       "                            AdaBoost classifier (best)                 0.35209   \n",
       "         Sbert              AdaBoost classifier                        0.68975   \n",
       "         Sbert Oversampling Ridge CCR                                  0.68687   \n",
       "         Traditional Best   Random Forest classifier (best)            0.59019   \n",
       "         Sbert Best         Random Forest classifier (best)            0.64791   \n",
       "         Traditional Best   Bernoulli Naive Bayes classifier (best)    0.54113   \n",
       "                            Ridge Classifier (best)                    0.58153   \n",
       "                            Support Vector Classification (best)       0.53391   \n",
       "         Sbert              Random Forest classifier                   0.70130   \n",
       "         Traditional        Ridge Classifier                           0.61472   \n",
       "                            Bernoulli Naive Bayes classifier           0.63348   \n",
       "         Traditional Best   Multinomial Naive Bayes classifier (best)  0.62338   \n",
       "         Traditional        AdaBoost classifier                        0.61905   \n",
       "                            Random Forest classifier                   0.61905   \n",
       "         Sbert Oversampling MLP CCR                                    0.65512   \n",
       "         Deep Learning      Atalaya                                    0.64358   \n",
       "         Sbert Oversampling SVC CCR                                    0.65079   \n",
       "         Traditional        Multinomial Naive Bayes classifier         0.64646   \n",
       "                            Support Vector Classification              0.64502   \n",
       "                            Dummy Classifier                           0.64502   \n",
       "                            Multi-layer Perceptron classifier          0.64214   \n",
       "         Traditional Best   Multi-layer Perceptron classifier (best)   0.64502   \n",
       "\n",
       "                                                                            \n",
       "                                                                      Test  \n",
       "Lenguage Group              Name                                            \n",
       "Spanish  Sbert Oversampling Ridge SMOBD                                NaN  \n",
       "                            MLP SMOTE_TomekLinks                       NaN  \n",
       "                            Ridge G_SMOTE                              NaN  \n",
       "         Deep Learning      Bert base (3 epochs)                       NaN  \n",
       "         Sbert Oversampling Ridge SMOTE_TomekLinks                     NaN  \n",
       "                            Ridge SMOTE_IPF                            NaN  \n",
       "         Deep Learning      Bert Avarage                               NaN  \n",
       "         Sbert Oversampling Ridge Assembled_SMOTE                      NaN  \n",
       "         Deep Learning      Bert base (4 epochs)                       NaN  \n",
       "         Sbert Oversampling Ridge polynom_fit_SMOTE                    NaN  \n",
       "                            MLP Assembled_SMOTE                        NaN  \n",
       "                            MLP SMOBD                                  NaN  \n",
       "                            SVC SMOBD                                  NaN  \n",
       "                            MLP LVQ_SMOTE                              NaN  \n",
       "                            Ridge ProWSyn                              NaN  \n",
       "                            SVC G_SMOTE                                NaN  \n",
       "                            MLP SMOTE_IPF                              NaN  \n",
       "                            Ridge LVQ_SMOTE                            NaN  \n",
       "                            SVC SMOTE_IPF                              NaN  \n",
       "                            MLP G_SMOTE                                NaN  \n",
       "         Deep Learning      Bert base (2 epochs)                       NaN  \n",
       "         Sbert Oversampling SVC ProWSyn                                NaN  \n",
       "         Sbert              Multi-layer Perceptron classifier          NaN  \n",
       "         Sbert Oversampling SVC Assembled_SMOTE                        NaN  \n",
       "                            SVC SMOTE_TomekLinks                       NaN  \n",
       "                            MLP ProWSyn                                NaN  \n",
       "                            MLP polynom_fit_SMOTE                      NaN  \n",
       "         Sbert Best         Support Vector Classification (best)       NaN  \n",
       "         Sbert              Ridge Classifier                           NaN  \n",
       "         Sbert Oversampling SVC LVQ_SMOTE                              NaN  \n",
       "         Sbert Best         Ridge Classifier (best)                    NaN  \n",
       "         Sbert Oversampling SVC polynom_fit_SMOTE                      NaN  \n",
       "         Sbert              Support Vector Classification              NaN  \n",
       "         Sbert Best         Multi-layer Perceptron classifier (best)   NaN  \n",
       "                            AdaBoost classifier (best)                 NaN  \n",
       "         Traditional Best   Dummy Classifier (best)                    NaN  \n",
       "                            AdaBoost classifier (best)                 NaN  \n",
       "         Sbert              AdaBoost classifier                        NaN  \n",
       "         Sbert Oversampling Ridge CCR                                  NaN  \n",
       "         Traditional Best   Random Forest classifier (best)            NaN  \n",
       "         Sbert Best         Random Forest classifier (best)            NaN  \n",
       "         Traditional Best   Bernoulli Naive Bayes classifier (best)    NaN  \n",
       "                            Ridge Classifier (best)                    NaN  \n",
       "                            Support Vector Classification (best)       NaN  \n",
       "         Sbert              Random Forest classifier                   NaN  \n",
       "         Traditional        Ridge Classifier                           NaN  \n",
       "                            Bernoulli Naive Bayes classifier           NaN  \n",
       "         Traditional Best   Multinomial Naive Bayes classifier (best)  NaN  \n",
       "         Traditional        AdaBoost classifier                        NaN  \n",
       "                            Random Forest classifier                   NaN  \n",
       "         Sbert Oversampling MLP CCR                                    NaN  \n",
       "         Deep Learning      Atalaya                                    NaN  \n",
       "         Sbert Oversampling SVC CCR                                    NaN  \n",
       "         Traditional        Multinomial Naive Bayes classifier         NaN  \n",
       "                            Support Vector Classification              NaN  \n",
       "                            Dummy Classifier                           NaN  \n",
       "                            Multi-layer Perceptron classifier          NaN  \n",
       "         Traditional Best   Multi-layer Perceptron classifier (best)   NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_columns2.loc[\"Detoxis Task1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ddeb55",
   "metadata": {},
   "source": [
    "Improvements:\n",
    "- Allow removal of all files with specific features or codition (not just path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7cd39fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-11-5d982af481a4>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-11-5d982af481a4>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    xsource\": [\u001b[0m\n\u001b[1;37m               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "xsource\": [\n",
    "    \"import smote_variants as sv\\n\",\n",
    "    \"\\n\",\n",
    "    \"#From https://smote-variants.readthedocs.io/en/latest/ranking.html\\n\",\n",
    "    \"oversamplers = [\\n\",\n",
    "    \"    sv.polynom_fit_SMOTE, sv.ProWSyn, sv.SMOTE_IPF, sv.Lee, sv.SMOBD, sv.G_SMOTE,\\n\",\n",
    "    \"    sv.CCR, sv.LVQ_SMOTE, sv.Assembled_SMOTE, sv.SMOTE_TomekLinks\\n\",\n",
    "    \"]\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
